---
apiVersion: v1
kind: ConfigMap
metadata:
  name: claude-agent-code
  namespace: ai-platform
data:
  # API wrapper that exposes Claude Agent SDK as HTTP endpoints
  main.py: |
    #!/usr/bin/env python3
    """
    Claude Agent API Wrapper

    Exposes Claude Code CLI capabilities via HTTP API for the LangGraph orchestrator.
    Uses subscription authentication (not API keys).
    """
    import asyncio
    import json
    import os
    import base64
    import subprocess
    import uuid
    from datetime import datetime
    from pathlib import Path
    from typing import Optional, List, Dict, Any
    from contextlib import asynccontextmanager

    from fastapi import FastAPI, HTTPException, BackgroundTasks
    from pydantic import BaseModel
    import httpx
    import redis.asyncio as redis

    # Redis configuration
    REDIS_URL = os.environ.get("REDIS_URL", "redis://redis:6379")
    TASK_QUEUE_KEY = "claude:tasks:queue"  # Sorted set with priority
    TASK_RESULTS_PREFIX = "claude:task:"   # Hash for each task
    TASK_TTL = 3600  # 1 hour TTL for results
    WORKER_ID = os.environ.get("HOSTNAME", str(uuid.uuid4())[:8])

    # Redis connection pool
    redis_pool: Optional[redis.Redis] = None

    # ============================================================================
    # Configuration
    # ============================================================================

    CLAUDE_HOME = Path(os.environ.get("HOME", "/home/agent")) / ".claude"
    CREDENTIALS_FILE = CLAUDE_HOME / ".credentials.json"

    # MCP Server endpoints (in-cluster)
    MCP_SERVERS = {
        "knowledge": os.getenv("KNOWLEDGE_MCP_URL", "http://knowledge-mcp:8000"),
        "infrastructure": os.getenv("INFRASTRUCTURE_MCP_URL", "http://infrastructure-mcp:8000"),
        "home-assistant": os.getenv("HOME_ASSISTANT_MCP_URL", "http://home-assistant-mcp:8000"),
        "arr-suite": os.getenv("ARR_SUITE_MCP_URL", "http://arr-suite-mcp:8000"),
    }

    # Knowledge MCP URL for event logging
    KNOWLEDGE_MCP_URL = os.getenv("KNOWLEDGE_MCP_URL", "http://knowledge-mcp:8000")

    # Priority levels (lower score = higher priority)
    PRIORITY_USER = 1      # User-initiated requests
    PRIORITY_CRITICAL = 2  # Critical alerts
    PRIORITY_WARNING = 3   # Warning alerts
    PRIORITY_LOW = 4       # Background tasks

    # ============================================================================
    # Event Logging (Forever Learning System)
    # ============================================================================

    async def log_to_knowledge(
        event_type: str,
        description: str,
        task_id: Optional[str] = None,
        task_data: Optional[dict] = None,
        result: Optional[str] = None,
        success: bool = True,
        latency_ms: Optional[float] = None
    ):
        """
        Log execution event to knowledge-mcp for the Forever Learning System.

        This allows the AI platform to learn from every interaction by tracking
        what worked, what failed, and why.
        """
        try:
            metadata = {
                "worker_id": WORKER_ID,
                "source": "claude-agent",
            }
            if task_id:
                metadata["task_id"] = task_id
            if task_data:
                metadata["model"] = task_data.get("model", "unknown")
                metadata["prompt_length"] = len(task_data.get("prompt", ""))
                metadata["timeout"] = task_data.get("timeout", 600)
            if result:
                metadata["response_length"] = len(result)
            if latency_ms:
                metadata["latency_ms"] = latency_ms

            async with httpx.AsyncClient(timeout=10.0) as client:
                resp = await client.post(
                    f"{KNOWLEDGE_MCP_URL}/api/log_event",
                    json={
                        "event_type": event_type,
                        "description": description[:500],  # Truncate for embedding
                        "source_agent": "claude-agent",
                        "metadata": metadata,
                        "resolution": "completed" if success else "failed"
                    }
                )
                if resp.status_code == 200:
                    data = resp.json()
                    print(f"[Learning] Logged event {data.get('event_id', 'unknown')}: {event_type}")
                else:
                    print(f"[Learning] Failed to log event: {resp.status_code}")
        except Exception as e:
            # Don't fail the main task if logging fails
            print(f"[Learning] Error logging event: {e}")

    # ============================================================================
    # Redis Task Queue Functions
    # ============================================================================

    async def get_redis() -> redis.Redis:
        """Get Redis connection."""
        global redis_pool
        if redis_pool is None:
            redis_pool = redis.from_url(REDIS_URL, decode_responses=True)
        return redis_pool

    async def enqueue_task(task_id: str, task_data: dict, priority: int = PRIORITY_LOW) -> bool:
        """Add task to priority queue."""
        r = await get_redis()
        task_key = f"{TASK_RESULTS_PREFIX}{task_id}"
        # Store task data
        task_data["status"] = "pending"
        task_data["created_at"] = datetime.utcnow().isoformat()
        task_data["worker"] = None
        await r.hset(task_key, mapping={k: json.dumps(v) if isinstance(v, (dict, list)) else str(v) for k, v in task_data.items()})
        await r.expire(task_key, TASK_TTL)
        # Add to priority queue (sorted set with priority as score)
        await r.zadd(TASK_QUEUE_KEY, {task_id: priority})
        return True

    async def dequeue_task() -> Optional[tuple]:
        """Get highest priority task from queue. Returns (task_id, task_data) or None."""
        r = await get_redis()
        # Atomically get and remove lowest score (highest priority) item
        result = await r.zpopmin(TASK_QUEUE_KEY, count=1)
        if not result:
            return None
        task_id, priority = result[0]
        # Get task data
        task_key = f"{TASK_RESULTS_PREFIX}{task_id}"
        task_data = await r.hgetall(task_key)
        if not task_data:
            return None
        # Mark as running
        await r.hset(task_key, "status", "running")
        await r.hset(task_key, "worker", WORKER_ID)
        await r.hset(task_key, "started_at", datetime.utcnow().isoformat())
        # Parse JSON fields
        for k in ["context", "allowed_tools"]:
            if k in task_data and task_data[k]:
                try:
                    task_data[k] = json.loads(task_data[k])
                except:
                    pass
        return task_id, task_data

    async def update_task_result(task_id: str, status: str, result: str = None, error: str = None):
        """Update task with result."""
        r = await get_redis()
        task_key = f"{TASK_RESULTS_PREFIX}{task_id}"
        updates = {
            "status": status,
            "completed_at": datetime.utcnow().isoformat()
        }
        if result is not None:
            updates["result"] = result
        if error is not None:
            updates["error"] = error
        await r.hset(task_key, mapping=updates)
        await r.expire(task_key, TASK_TTL)

    async def get_task_from_redis(task_id: str) -> Optional[dict]:
        """Get task status from Redis."""
        r = await get_redis()
        task_key = f"{TASK_RESULTS_PREFIX}{task_id}"
        data = await r.hgetall(task_key)
        return data if data else None

    async def get_queue_stats() -> dict:
        """Get queue statistics."""
        r = await get_redis()
        queue_length = await r.zcard(TASK_QUEUE_KEY)
        # Count tasks by status
        keys = await r.keys(f"{TASK_RESULTS_PREFIX}*")
        stats = {"pending": 0, "running": 0, "completed": 0, "failed": 0}
        for key in keys[:100]:  # Limit scan
            status = await r.hget(key, "status")
            if status in stats:
                stats[status] += 1
        return {"queue_length": queue_length, "tasks": stats, "worker_id": WORKER_ID}

    # ============================================================================
    # Models
    # ============================================================================

    class AgentRequest(BaseModel):
        prompt: str
        context: Optional[Dict[str, Any]] = None
        allowed_tools: Optional[List[str]] = None
        max_turns: int = 10
        working_directory: str = "/workspace"
        model: str = "opus"  # Default to Opus for complex tasks
        async_mode: bool = False  # If True, return task_id immediately
        timeout: int = 600  # Default 10 minutes, max for deep research

    class AgentResponse(BaseModel):
        success: bool
        result: Optional[str] = None
        error: Optional[str] = None
        tool_calls: List[Dict[str, Any]] = []
        tokens_used: Optional[int] = None
        task_id: Optional[str] = None  # For async tasks

    class TaskStatus(BaseModel):
        task_id: str
        status: str  # pending, running, completed, failed
        created_at: str
        completed_at: Optional[str] = None
        result: Optional[str] = None
        error: Optional[str] = None

    class HealthResponse(BaseModel):
        status: str
        claude_authenticated: bool
        mcp_servers: Dict[str, bool]

    # ============================================================================
    # Startup
    # ============================================================================

    async def setup_credentials():
        """Decode and write credentials from Infisical secret."""
        CLAUDE_HOME.mkdir(parents=True, exist_ok=True)

        # Read base64-encoded credentials from mounted secret
        creds_b64_file = Path("/secrets/claude/CREDENTIALS_JSON_B64")
        if creds_b64_file.exists():
            creds_b64 = creds_b64_file.read_text().strip()
            creds_json = base64.b64decode(creds_b64).decode('utf-8')
            CREDENTIALS_FILE.write_text(creds_json)
            os.chmod(CREDENTIALS_FILE, 0o600)
            print("✓ Claude credentials configured")
        else:
            print("⚠ No credentials file found at /secrets/claude/CREDENTIALS_JSON_B64")

    async def check_mcp_health() -> Dict[str, bool]:
        """Check connectivity to MCP servers."""
        results = {}
        async with httpx.AsyncClient(timeout=5.0) as client:
            for name, url in MCP_SERVERS.items():
                try:
                    resp = await client.get(f"{url}/health")
                    results[name] = resp.status_code == 200
                except Exception:
                    results[name] = False
        return results

    @asynccontextmanager
    async def lifespan(app: FastAPI):
        global worker_running, worker_task
        await setup_credentials()
        # Start worker loop
        worker_running = True
        worker_task = asyncio.create_task(worker_loop())
        yield
        # Shutdown worker
        worker_running = False
        if worker_task:
            worker_task.cancel()
            try:
                await worker_task
            except asyncio.CancelledError:
                pass
        # Close Redis connection
        if redis_pool:
            await redis_pool.close()

    app = FastAPI(
        title="Claude Agent API",
        description="HTTP API wrapper for Claude Code CLI with subscription auth",
        version="1.0.0",
        lifespan=lifespan
    )

    # ============================================================================
    # Endpoints
    # ============================================================================

    @app.get("/health", response_model=HealthResponse)
    async def health_check():
        """Check service health and dependencies."""
        claude_auth = CREDENTIALS_FILE.exists()
        mcp_health = await check_mcp_health()

        return HealthResponse(
            status="healthy" if claude_auth else "degraded",
            claude_authenticated=claude_auth,
            mcp_servers=mcp_health
        )

    def _run_claude_sync(cmd: List[str], cwd: str, env: dict, timeout: int) -> tuple:
        """Run Claude CLI synchronously (called from thread pool)."""
        try:
            result = subprocess.run(
                cmd,
                cwd=cwd,
                env=env,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            return (result.returncode, result.stdout, result.stderr)
        except subprocess.TimeoutExpired:
            return (-1, "", f"Agent execution timed out ({timeout}s limit)")
        except Exception as e:
            return (-1, "", str(e))

    async def execute_task(task_id: str, task_data: dict):
        """Execute a task from the queue."""
        prompt = task_data.get("prompt", "")
        model = task_data.get("model", "opus")
        working_dir = task_data.get("working_directory", "/workspace")
        timeout = int(task_data.get("timeout", 600))
        allowed_tools = task_data.get("allowed_tools")
        if isinstance(allowed_tools, str):
            try:
                allowed_tools = json.loads(allowed_tools)
            except:
                allowed_tools = None

        # Build claude command
        cmd = [
            "claude",
            "--print",
            "--dangerously-skip-permissions",
            "--model", model,
        ]
        if allowed_tools:
            # Pass allowed tools as space-separated list
            cmd.extend(["--allowedTools"] + allowed_tools)
        # Use -- to separate options from prompt (required when using --allowedTools)
        cmd.append("--")
        cmd.append(prompt)

        env = os.environ.copy()
        env["HOME"] = os.environ.get("HOME", "/home/agent")
        env["CLAUDE_CODE_ENTRYPOINT"] = "agent-api"

        # Track timing for learning system
        start_time = datetime.utcnow()

        try:
            returncode, stdout, stderr = await asyncio.to_thread(
                _run_claude_sync, cmd, working_dir, env, timeout
            )

            # Calculate latency
            latency_ms = (datetime.utcnow() - start_time).total_seconds() * 1000

            if returncode == 0:
                await update_task_result(task_id, "completed", result=stdout)
                # Log success to learning system
                await log_to_knowledge(
                    event_type="agent.chat.complete",
                    description=f"Task {task_id}: {prompt[:200]}",
                    task_id=task_id,
                    task_data=task_data,
                    result=stdout,
                    success=True,
                    latency_ms=latency_ms
                )
            else:
                await update_task_result(task_id, "failed", result=stdout, error=stderr or "Unknown error")
                # Log failure to learning system
                await log_to_knowledge(
                    event_type="agent.error",
                    description=f"Task {task_id} failed: {stderr[:200] if stderr else 'Unknown error'}",
                    task_id=task_id,
                    task_data=task_data,
                    result=stdout,
                    success=False,
                    latency_ms=latency_ms
                )
        except Exception as e:
            latency_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            await update_task_result(task_id, "failed", error=str(e))
            # Log exception to learning system
            await log_to_knowledge(
                event_type="agent.error",
                description=f"Task {task_id} exception: {str(e)[:200]}",
                task_id=task_id,
                task_data=task_data,
                success=False,
                latency_ms=latency_ms
            )

    # Worker state
    worker_running = False
    worker_task: Optional[asyncio.Task] = None

    async def worker_loop():
        """Background worker that processes tasks from Redis queue."""
        global worker_running
        print(f"[Worker {WORKER_ID}] Starting worker loop...")
        while worker_running:
            try:
                task = await dequeue_task()
                if task:
                    task_id, task_data = task
                    print(f"[Worker {WORKER_ID}] Processing task {task_id}")
                    await execute_task(task_id, task_data)
                    print(f"[Worker {WORKER_ID}] Completed task {task_id}")
                else:
                    # No tasks, wait before polling again
                    await asyncio.sleep(1)
            except Exception as e:
                print(f"[Worker {WORKER_ID}] Error in worker loop: {e}")
                await asyncio.sleep(5)
        print(f"[Worker {WORKER_ID}] Worker loop stopped")

    @app.post("/agent/run", response_model=AgentResponse)
    async def run_agent(request: AgentRequest, background_tasks: BackgroundTasks):
        """
        Execute a Claude agent task.

        This invokes Claude Code CLI as a subprocess with the given prompt.
        The agent has access to MCP tools and can perform agentic tasks.

        If async_mode=True, queues task in Redis and returns task_id immediately.
        Poll /task/{task_id} for status and results.
        """
        try:
            # Async mode - queue in Redis
            if request.async_mode:
                task_id = str(uuid.uuid4())
                task_data = {
                    "prompt": request.prompt,
                    "model": request.model,
                    "working_directory": request.working_directory,
                    "timeout": request.timeout,
                    "allowed_tools": json.dumps(request.allowed_tools) if request.allowed_tools else "",
                    "context": json.dumps(request.context) if request.context else "",
                }
                # Default priority - can be overridden via separate queue endpoint
                await enqueue_task(task_id, task_data, priority=PRIORITY_LOW)
                return AgentResponse(
                    success=True,
                    task_id=task_id,
                    result=f"Task queued - poll /task/{task_id} for status"
                )

            # Sync mode - execute directly (bypasses queue)
            sync_task_id = str(uuid.uuid4())[:8]  # Short ID for sync tasks
            cmd = [
                "claude",
                "--print",
                "--dangerously-skip-permissions",
                "--model", request.model,
            ]
            if request.allowed_tools:
                # Pass allowed tools as space-separated list
                cmd.extend(["--allowedTools"] + request.allowed_tools)
            # Use -- to separate options from prompt (required when using --allowedTools)
            cmd.append("--")
            cmd.append(request.prompt)

            env = os.environ.copy()
            env["HOME"] = os.environ.get("HOME", "/home/agent")
            env["CLAUDE_CODE_ENTRYPOINT"] = "agent-api"

            # Track timing for learning system
            start_time = datetime.utcnow()
            task_data = {
                "prompt": request.prompt,
                "model": request.model,
                "timeout": request.timeout,
            }

            returncode, stdout, stderr = await asyncio.to_thread(
                _run_claude_sync, cmd, request.working_directory, env, request.timeout
            )

            # Calculate latency
            latency_ms = (datetime.utcnow() - start_time).total_seconds() * 1000

            if returncode == 0:
                # Log success to learning system (fire and forget)
                asyncio.create_task(log_to_knowledge(
                    event_type="agent.chat.complete",
                    description=f"Sync task {sync_task_id}: {request.prompt[:200]}",
                    task_id=sync_task_id,
                    task_data=task_data,
                    result=stdout,
                    success=True,
                    latency_ms=latency_ms
                ))
                return AgentResponse(
                    success=True,
                    result=stdout,
                    tool_calls=[]
                )
            else:
                # Log failure to learning system
                asyncio.create_task(log_to_knowledge(
                    event_type="agent.error",
                    description=f"Sync task {sync_task_id} failed: {stderr[:200] if stderr else 'Unknown error'}",
                    task_id=sync_task_id,
                    task_data=task_data,
                    result=stdout,
                    success=False,
                    latency_ms=latency_ms
                ))
                return AgentResponse(
                    success=False,
                    error=stderr or "Unknown error",
                    result=stdout
                )

        except Exception as e:
            # Log exception (can't easily get timing here)
            asyncio.create_task(log_to_knowledge(
                event_type="agent.error",
                description=f"Sync task exception: {str(e)[:200]}",
                success=False
            ))
            return AgentResponse(
                success=False,
                error=str(e)
            )

    @app.get("/task/{task_id}", response_model=TaskStatus)
    async def get_task_status_endpoint(task_id: str):
        """Get status and result of an async task from Redis."""
        task = await get_task_from_redis(task_id)
        if not task:
            raise HTTPException(status_code=404, detail="Task not found")
        return TaskStatus(
            task_id=task_id,
            status=task.get("status", "unknown"),
            created_at=task.get("created_at", ""),
            completed_at=task.get("completed_at"),
            result=task.get("result"),
            error=task.get("error")
        )

    @app.get("/tasks")
    async def list_tasks():
        """List recent tasks from Redis (for debugging)."""
        stats = await get_queue_stats()
        return stats

    class QueueRequest(BaseModel):
        """Request to queue a task with priority."""
        prompt: str
        priority: int = PRIORITY_LOW  # 1=user, 2=critical, 3=warning, 4=low
        model: str = "opus"
        working_directory: str = "/workspace"
        timeout: int = 600
        allowed_tools: Optional[List[str]] = None
        context: Optional[Dict[str, Any]] = None

    @app.post("/queue/submit")
    async def submit_to_queue(request: QueueRequest):
        """
        Submit a task to the priority queue.

        Priority levels:
        - 1: User-initiated (highest)
        - 2: Critical alerts
        - 3: Warning alerts
        - 4: Low priority/background (default)
        """
        task_id = str(uuid.uuid4())
        task_data = {
            "prompt": request.prompt,
            "model": request.model,
            "working_directory": request.working_directory,
            "timeout": request.timeout,
            "allowed_tools": json.dumps(request.allowed_tools) if request.allowed_tools else "",
            "context": json.dumps(request.context) if request.context else "",
        }
        await enqueue_task(task_id, task_data, priority=request.priority)
        stats = await get_queue_stats()
        return {
            "task_id": task_id,
            "priority": request.priority,
            "queue_position": stats["queue_length"],
            "message": f"Task queued - poll /task/{task_id} for status"
        }

    @app.get("/queue/stats")
    async def queue_statistics():
        """Get current queue statistics."""
        return await get_queue_stats()

    @app.post("/agent/query")
    async def query_agent(prompt: str, context: Optional[Dict[str, Any]] = None):
        """
        Simple query endpoint for quick questions.
        Wraps run_agent with defaults for query-style interactions.
        """
        request = AgentRequest(
            prompt=prompt,
            context=context,
            max_turns=3,
            allowed_tools=["Read", "Glob", "Grep", "WebSearch", "WebFetch"]
        )
        return await run_agent(request)

    @app.get("/mcp/servers")
    async def list_mcp_servers():
        """List available MCP servers and their status."""
        return {
            "servers": MCP_SERVERS,
            "health": await check_mcp_health()
        }

  init.sh: |
    #!/bin/bash
    set -e

    echo "=== Claude Agent Initialization ==="

    # Create .claude directory
    mkdir -p /root/.claude

    # Decode credentials from secret
    if [ -f /secrets/claude/CREDENTIALS_JSON_B64 ]; then
        echo "Decoding Claude credentials..."
        base64 -d /secrets/claude/CREDENTIALS_JSON_B64 > /root/.claude/.credentials.json
        chmod 600 /root/.claude/.credentials.json
        echo "✓ Credentials configured"
    else
        echo "⚠ Warning: No credentials found"
    fi

    # Verify Claude Code is installed
    if command -v claude &> /dev/null; then
        echo "✓ Claude Code CLI available"
        claude --version || true
    else
        echo "✗ Claude Code CLI not found"
        exit 1
    fi

    echo "=== Starting API Server ==="
    exec uvicorn main:app --host 0.0.0.0 --port 8000

  requirements.txt: |
    fastapi>=0.109.0
    uvicorn[standard]>=0.27.0
    httpx>=0.26.0
    pydantic>=2.5.0
    redis>=5.0.0
