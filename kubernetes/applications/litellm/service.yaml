apiVersion: v1
kind: Service
metadata:
  name: litellm
  namespace: ai-platform
  labels:
    app: litellm
    component: inference-proxy
spec:
  type: NodePort
  ports:
  - port: 4000
    targetPort: 4000
    nodePort: 31400
    protocol: TCP
    name: http
  selector:
    app: litellm
