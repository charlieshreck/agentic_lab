apiVersion: v1
kind: ConfigMap
metadata:
  name: litellm-config
  namespace: ai-platform
  labels:
    app: litellm
data:
  config.yaml: |
    # LiteLLM Proxy Configuration
    # See: https://docs.litellm.ai/docs/proxy/configs

    model_list:
      # Local Ollama models
      - model_name: local/qwen2.5:7b
        litellm_params:
          model: ollama/qwen2.5:7b
          api_base: http://ollama:11434

      - model_name: local/qwen2.5:14b
        litellm_params:
          model: ollama/qwen2.5:14b
          api_base: http://ollama:11434

      - model_name: local/nomic-embed-text
        litellm_params:
          model: ollama/nomic-embed-text
          api_base: http://ollama:11434

      # Embedding model alias
      - model_name: embeddings
        litellm_params:
          model: ollama/nomic-embed-text
          api_base: http://ollama:11434

    # Router settings
    router_settings:
      routing_strategy: simple-shuffle
      num_retries: 2
      timeout: 120

    # General settings
    general_settings:
      master_key: null
      drop_params: true
