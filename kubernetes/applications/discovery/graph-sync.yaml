apiVersion: batch/v1
kind: CronJob
metadata:
  name: graph-sync
  namespace: ai-platform
  labels:
    app: graph-sync
    component: discovery
spec:
  schedule: "15 */4 * * *"  # Every 4 hours, 15 min after discovery
  concurrencyPolicy: Forbid  # Prevent overlapping runs
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      backoffLimit: 2
      activeDeadlineSeconds: 600  # 10 minute timeout (multi-cluster)
      template:
        metadata:
          labels:
            app: graph-sync
        spec:
          restartPolicy: Never
          hostAliases:
          - ip: "10.30.0.90"
            hostnames:
            - gatus.monit.kernow.io
          containers:
          - name: graph-sync
            image: python:3.11-slim
            env:
            - name: NEO4J_URL
              value: "http://neo4j:7474"
            - name: NEO4J_USER
              value: "neo4j"
            - name: NEO4J_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: neo4j-credentials
                  key: NEO4J_PASSWORD
            # Consolidated MCP endpoints (cluster-internal)
            - name: INFRASTRUCTURE_MCP_URL
              value: "http://infrastructure-mcp:8000"
            - name: KNOWLEDGE_MCP_URL
              value: "http://knowledge-mcp:8000"
            - name: OBSERVABILITY_MCP_URL
              value: "http://observability-mcp:8000"
            - name: HOME_MCP_URL
              value: "http://home-mcp:8000"
            - name: GATUS_URL
              value: "http://gatus.monit.kernow.io"
            - name: MEDIA_MCP_URL
              value: "http://media-mcp:8000"
            resources:
              requests:
                memory: "128Mi"
                cpu: "100m"
              limits:
                memory: "256Mi"
                cpu: "500m"
            command:
            - python
            - -c
            - |
              import os
              import json
              import asyncio
              import logging
              from datetime import datetime, timedelta
              from base64 import b64encode
              from urllib.request import Request, urlopen
              from urllib.error import URLError, HTTPError

              logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
              logger = logging.getLogger(__name__)

              # Configuration
              NEO4J_URL = os.environ.get("NEO4J_URL", "http://neo4j:7474")
              NEO4J_USER = os.environ.get("NEO4J_USER", "neo4j")
              NEO4J_PASSWORD = os.environ.get("NEO4J_PASSWORD", "")  # Don't strip - Neo4j was initialized with newline

              # Consolidated MCP endpoints
              MCP_SERVERS = {
                  "infrastructure": os.environ.get("INFRASTRUCTURE_MCP_URL", "http://infrastructure-mcp:8000"),
                  "knowledge": os.environ.get("KNOWLEDGE_MCP_URL", "http://knowledge-mcp:8000"),
                  "observability": os.environ.get("OBSERVABILITY_MCP_URL", "http://observability-mcp:8000"),
                  "home": os.environ.get("HOME_MCP_URL", "http://home-mcp:8000"),
                  "media": os.environ.get("MEDIA_MCP_URL", "http://media-mcp:8000"),
              }

              # Multi-cluster configuration
              K8S_CLUSTERS = ["agentic", "prod", "monit"]

              # Direct API access (cross-cluster)
              GATUS_URL = os.environ.get("GATUS_URL", "http://gatus.monit.kernow.io")

              def _extract_nested(value, default=0):
                  """Extract value from nested TrueNAS-style dicts like {"parsed": 123, "rawvalue": "123"}."""
                  if isinstance(value, dict):
                      return value.get("parsed", value.get("value", default))
                  return value if value is not None else default

              def neo4j_query(cypher: str, params: dict = None) -> dict:
                  """Execute Cypher query via Neo4j HTTP API."""
                  url = f"{NEO4J_URL}/db/neo4j/tx/commit"
                  auth = b64encode(f"{NEO4J_USER}:{NEO4J_PASSWORD}".encode()).decode()

                  body = {
                      "statements": [{
                          "statement": cypher,
                          "parameters": params or {}
                      }]
                  }

                  req = Request(
                      url,
                      data=json.dumps(body).encode(),
                      headers={
                          "Content-Type": "application/json",
                          "Authorization": f"Basic {auth}"
                      },
                      method="POST"
                  )

                  try:
                      with urlopen(req, timeout=30) as resp:
                          return json.loads(resp.read().decode())
                  except (URLError, HTTPError) as e:
                      logger.error(f"Neo4j query failed: {e}")
                      return {"errors": [str(e)]}

              def call_mcp_tool(server: str, tool_name: str, arguments: dict = None) -> dict:
                  """Call MCP tool via JSON-RPC with SSE response parsing."""
                  url = f"{MCP_SERVERS.get(server, '')}/mcp"

                  body = {
                      "jsonrpc": "2.0",
                      "id": 1,
                      "method": "tools/call",
                      "params": {
                          "name": tool_name,
                          "arguments": arguments or {}
                      }
                  }

                  req = Request(
                      url,
                      data=json.dumps(body).encode(),
                      headers={
                          "Content-Type": "application/json",
                          "Accept": "application/json, text/event-stream"
                      },
                      method="POST"
                  )

                  try:
                      with urlopen(req, timeout=30) as resp:
                          raw = resp.read().decode()
                          # Parse SSE format: "event: message\ndata: {...}"
                          for line in raw.split('\n'):
                              if line.startswith('data: '):
                                  result = json.loads(line[6:])  # Skip "data: " prefix
                                  if "result" in result and "content" in result["result"]:
                                      content = result["result"]["content"]
                                      if content and len(content) > 0:
                                          text = content[0].get("text", "{}")
                                          return json.loads(text) if text.startswith(('{', '[')) else {"text": text}
                                  return result.get("result", {})
                          # Fallback: try parsing as plain JSON (non-SSE response)
                          try:
                              result = json.loads(raw)
                              if "result" in result and "content" in result["result"]:
                                  content = result["result"]["content"]
                                  if content and len(content) > 0:
                                      text = content[0].get("text", "{}")
                                      return json.loads(text) if text.startswith(('{', '[')) else {"text": text}
                              return result.get("result", {})
                          except json.JSONDecodeError:
                              pass
                          return {}
                  except (URLError, HTTPError) as e:
                      logger.warning(f"MCP call {server}/{tool_name} failed: {e}")
                      return {}
                  except json.JSONDecodeError as e:
                      logger.warning(f"MCP call {server}/{tool_name} JSON parse failed: {e}")
                      return {}

              def extract_list(response, *keys):
                  """Extract a list from MCP tool response, handling various formats."""
                  if isinstance(response, list):
                      return response
                  if isinstance(response, dict):
                      # Try 'result' key first (common MCP tool wrapper)
                      if "result" in response and isinstance(response["result"], list):
                          return response["result"]
                      # Try specified keys
                      for key in keys:
                          if key in response and isinstance(response[key], list):
                              return response[key]
                  return []

              def call_rest_api(base_url: str, endpoint: str) -> dict:
                  """Call REST API endpoint directly."""
                  url = f"{base_url}{endpoint}"
                  req = Request(url, headers={"Accept": "application/json"}, method="GET")
                  try:
                      with urlopen(req, timeout=30) as resp:
                          return json.loads(resp.read().decode())
                  except (URLError, HTTPError) as e:
                      logger.warning(f"REST call {url} failed: {e}")
                      return {}
                  except json.JSONDecodeError as e:
                      logger.warning(f"REST call {url} JSON parse failed: {e}")
                      return {}

              def sync_proxmox_vms():
                  """Sync VMs from Proxmox to Neo4j."""
                  logger.info("Syncing Proxmox VMs...")

                  # Get VMs list via consolidated infrastructure-mcp
                  vms_response = call_mcp_tool("infrastructure", "proxmox_list_vms", {"params": {"response_format": "json"}})
                  vms = extract_list(vms_response, "vms")

                  if not vms:
                      logger.warning("No VMs returned from Proxmox MCP")
                      return 0

                  count = 0
                  for vm in vms:
                      vmid = vm.get("vmid")
                      name = vm.get("name", f"vm-{vmid}")
                      status = vm.get("status", "unknown")
                      node = vm.get("node", "unknown")

                      # Extract resource metrics from Proxmox response
                      cpu_percent = round(vm.get("cpu", 0) * 100, 1)
                      cpus = vm.get("maxcpu", vm.get("cpus", 0))
                      mem_used = vm.get("mem", 0)
                      mem_total = vm.get("maxmem", 0)
                      memory_used_gb = round(mem_used / (1024**3), 2) if mem_used else 0
                      memory_total_gb = round(mem_total / (1024**3), 2) if mem_total else 0
                      memory_percent = round((mem_used / mem_total) * 100, 1) if mem_total else 0
                      uptime_days = round(vm.get("uptime", 0) / 86400, 2)
                      netin_gb = round(vm.get("netin", 0) / (1024**3), 2)
                      netout_gb = round(vm.get("netout", 0) / (1024**3), 2)
                      disk_max_gb = round(vm.get("maxdisk", 0) / (1024**3), 2)

                      # Create VM node
                      cypher = """
                      MERGE (v:VM {vmid: $vmid})
                      SET v.name = $name,
                          v.status = $status,
                          v.node = $node,
                          v.type = $type,
                          v.cpu_percent = $cpu_percent,
                          v.cpus = $cpus,
                          v.memory_used_gb = $memory_used_gb,
                          v.memory_total_gb = $memory_total_gb,
                          v.memory_percent = $memory_percent,
                          v.uptime_days = $uptime_days,
                          v.netin_gb = $netin_gb,
                          v.netout_gb = $netout_gb,
                          v.disk_max_gb = $disk_max_gb,
                          v.last_seen = datetime(),
                          v.source = 'proxmox'
                      WITH v
                      MERGE (h:Host {hostname: $node})
                      SET h.type = 'hypervisor'
                      MERGE (h)-[:HOSTS]->(v)
                      RETURN v.vmid
                      """

                      result = neo4j_query(cypher, {
                          "vmid": str(vmid),
                          "name": name,
                          "status": status,
                          "node": node,
                          "type": vm.get("type", "qemu"),
                          "cpu_percent": cpu_percent,
                          "cpus": cpus,
                          "memory_used_gb": memory_used_gb,
                          "memory_total_gb": memory_total_gb,
                          "memory_percent": memory_percent,
                          "uptime_days": uptime_days,
                          "netin_gb": netin_gb,
                          "netout_gb": netout_gb,
                          "disk_max_gb": disk_max_gb
                      })

                      if not result.get("errors"):
                          count += 1

                  logger.info(f"Synced {count} VMs from Proxmox")
                  return count

              def sync_unifi_devices():
                  """Sync UniFi network devices to Neo4j."""
                  logger.info("Syncing UniFi devices...")

                  # Get devices (APs, switches) via consolidated home-mcp
                  devices_response = call_mcp_tool("home", "unifi_list_devices")
                  devices = extract_list(devices_response, "devices", "result")

                  count = 0
                  for device in devices:
                      mac = device.get("mac", "").lower()
                      if not mac:
                          continue

                      name = device.get("name", device.get("hostname", f"device-{mac}"))
                      device_type = device.get("type", "unknown")
                      model = device.get("model", "unknown")
                      ip = device.get("ip", "")

                      # Determine node label based on type
                      label = "AccessPoint" if device_type in ["uap", "ap"] else "Switch" if device_type in ["usw", "sw"] else "NetworkDevice"

                      cypher = f"""
                      MERGE (d:{label} {{mac: $mac}})
                      SET d.name = $name,
                          d.model = $model,
                          d.ip = $ip,
                          d.status = $status,
                          d.last_seen = datetime(),
                          d.source = 'unifi'
                      RETURN d.mac
                      """

                      result = neo4j_query(cypher, {
                          "mac": mac,
                          "name": name,
                          "model": model,
                          "ip": ip,
                          "status": device.get("state", "unknown")
                      })

                      if not result.get("errors"):
                          count += 1

                  # Get clients and their AP connections via consolidated home-mcp
                  clients_response = call_mcp_tool("home", "unifi_list_clients")
                  clients = extract_list(clients_response, "clients", "result")

                  for client in clients:
                      mac = client.get("mac", "").lower()
                      ap_mac = client.get("ap_mac", "").lower()

                      if mac and ap_mac:
                          # Create CONNECTED_VIA relationship
                          cypher = """
                          MATCH (h:Host {mac: $mac})
                          MATCH (ap:AccessPoint {mac: $ap_mac})
                          MERGE (h)-[r:CONNECTED_VIA]->(ap)
                          SET r.signal = $signal,
                              r.channel = $channel,
                              r.last_seen = datetime()
                          RETURN type(r)
                          """

                          neo4j_query(cypher, {
                              "mac": mac,
                              "ap_mac": ap_mac,
                              "signal": client.get("signal", 0),
                              "channel": client.get("channel", 0)
                          })

                  logger.info(f"Synced {count} UniFi devices, processed {len(clients)} client connections")
                  return count

              def sync_truenas_storage():
                  """Sync TrueNAS storage to Neo4j."""
                  logger.info("Syncing TrueNAS storage...")

                  # Get pools via consolidated infrastructure-mcp
                  pools_response = call_mcp_tool("infrastructure", "truenas_list_pools", {"params": {"instance": "hdd", "response_format": "json"}})
                  pools = extract_list(pools_response, "pools", "result")

                  count = 0
                  for pool in pools:
                      name = pool.get("name")
                      if not name:
                          continue

                      # Extract pool size from topology (TrueNAS nests it in vdev stats)
                      pool_size = 0
                      pool_used = 0
                      topology = pool.get("topology", {})
                      for vdev_type in ["data", "cache", "log", "spare", "special", "dedup"]:
                          for vdev in topology.get(vdev_type, []):
                              stats = vdev.get("stats", {})
                              pool_size += stats.get("size", 0)
                              pool_used += stats.get("allocated", 0)
                      # Fallback to top-level if topology parsing yields nothing
                      if pool_size == 0:
                          pool_size = _extract_nested(pool.get("size", 0))
                      if pool_used == 0:
                          pool_used = _extract_nested(pool.get("used", 0))

                      # Normalize ZFS status to lifecycle status
                      raw_status = pool.get("status", "unknown").lower()
                      pool_status = {"online": "healthy", "degraded": "degraded", "faulted": "unhealthy"}.get(raw_status, raw_status)

                      cypher = """
                      MERGE (p:StoragePool {name: $name})
                      SET p.status = $status,
                          p.size = $size,
                          p.used = $used,
                          p.size_gb = $size_gb,
                          p.used_gb = $used_gb,
                          p.last_seen = datetime(),
                          p.source = 'truenas'
                      RETURN p.name
                      """

                      result = neo4j_query(cypher, {
                          "name": name,
                          "status": pool_status,
                          "size": pool_size,
                          "used": pool_used,
                          "size_gb": round(pool_size / (1024**3), 2) if pool_size else 0,
                          "used_gb": round(pool_used / (1024**3), 2) if pool_used else 0
                      })

                      if not result.get("errors"):
                          count += 1

                  # Get datasets via consolidated infrastructure-mcp
                  datasets_response = call_mcp_tool("infrastructure", "truenas_list_datasets", {"params": {"instance": "hdd", "response_format": "json"}})
                  datasets = extract_list(datasets_response, "datasets", "result")

                  for dataset in datasets:
                      name = dataset.get("name", "")
                      pool_name = name.split("/")[0] if "/" in name else name

                      # Handle nested TrueNAS response format: {"parsed": bytes, "rawvalue": "..."}
                      used = _extract_nested(dataset.get("used", 0))
                      available = _extract_nested(dataset.get("available", 0))
                      dataset_status = "online" if available > 0 else "full"

                      cypher = """
                      MERGE (d:Dataset {name: $name})
                      SET d.mountpoint = $mountpoint,
                          d.used = $used,
                          d.available = $available,
                          d.used_gb = $used_gb,
                          d.available_gb = $available_gb,
                          d.status = $status,
                          d.last_seen = datetime(),
                          d.source = 'truenas'
                      WITH d
                      MATCH (p:StoragePool {name: $pool_name})
                      MERGE (p)-[:CONTAINS]->(d)
                      RETURN d.name
                      """

                      neo4j_query(cypher, {
                          "name": name,
                          "pool_name": pool_name,
                          "mountpoint": dataset.get("mountpoint", ""),
                          "used": used,
                          "available": available,
                          "used_gb": round(used / (1024**3), 2) if used else 0,
                          "available_gb": round(available / (1024**3), 2) if available else 0,
                          "status": dataset_status
                      })

                  # Get shares via consolidated infrastructure-mcp
                  shares_response = call_mcp_tool("infrastructure", "truenas_list_shares", {"params": {"instance": "hdd", "response_format": "json"}})
                  # Shares may return {nfs: [], smb: []} dict, {result: []} wrapper, or flat list
                  if isinstance(shares_response, list):
                      shares = shares_response
                  elif isinstance(shares_response, dict):
                      if "result" in shares_response and isinstance(shares_response["result"], list):
                          shares = shares_response["result"]
                      else:
                          nfs_shares = shares_response.get("nfs", [])
                          smb_shares = shares_response.get("smb", [])
                          shares = nfs_shares + smb_shares
                  else:
                      shares = []

                  for share in shares:
                      path = share.get("path", "")
                      name = share.get("name", path.split("/")[-1] if path else "unknown")
                      enabled = share.get("enabled", True)
                      share_status = "online" if enabled else "offline"

                      cypher = """
                      MERGE (s:Share {path: $path})
                      SET s.name = $name,
                          s.type = $type,
                          s.enabled = $enabled,
                          s.status = $status,
                          s.last_seen = datetime(),
                          s.source = 'truenas'
                      RETURN s.path
                      """

                      neo4j_query(cypher, {
                          "path": path,
                          "name": name,
                          "type": share.get("type", "nfs"),
                          "enabled": enabled,
                          "status": share_status
                      })

                  logger.info(f"Synced {count} storage pools, {len(datasets)} datasets, {len(shares)} shares")
                  return count

              def sync_kubernetes_deployments():
                  """Sync Kubernetes deployments from all clusters to Neo4j. Returns deploy_status lookup dict."""
                  logger.info("Syncing Kubernetes deployments (multi-cluster)...")

                  deploy_status = {}
                  total_count = 0

                  for cluster in K8S_CLUSTERS:
                      try:
                          deploys_response = call_mcp_tool("infrastructure", "kubectl_get_deployments", {"all_namespaces": True, "cluster": cluster})
                          deploys = extract_list(deploys_response, "deployments", "result")

                          count = 0
                          for d in deploys:
                              name = d.get("name")
                              namespace = d.get("namespace")
                              if not name or not namespace:
                                  continue

                              replicas = d.get("replicas", 0)
                              ready = d.get("ready", 0)
                              available = d.get("available", 0)

                              # Derive status
                              if replicas == 0:
                                  status = "scaled-down"
                              elif ready >= replicas:
                                  status = "healthy"
                              elif ready > 0:
                                  status = "degraded"
                              else:
                                  status = "unhealthy"

                              # Store for Service enrichment (keyed by cluster too)
                              deploy_status[(name, namespace, cluster)] = {
                                  "status": status,
                                  "replicas": replicas,
                                  "ready": ready,
                                  "available": available
                              }

                              selector = d.get("selector", "")

                              cypher = """
                              MERGE (dep:Deployment {name: $name, namespace: $namespace, cluster: $cluster})
                              SET dep.replicas = $replicas,
                                  dep.ready_replicas = $ready,
                                  dep.available_replicas = $available,
                                  dep.status = $status,
                                  dep.selector = $selector,
                                  dep.last_seen = datetime(),
                                  dep.source = 'kubernetes'
                              RETURN dep.name
                              """

                              result = neo4j_query(cypher, {
                                  "name": name,
                                  "namespace": namespace,
                                  "cluster": cluster,
                                  "replicas": replicas,
                                  "ready": ready,
                                  "available": available,
                                  "status": status,
                                  "selector": selector
                              })

                              if not result.get("errors"):
                                  count += 1

                              # Create BACKED_BY relationship (Service→Deployment) by name+namespace match
                              rel_cypher = """
                              MATCH (s:Service {name: $name, namespace: $namespace, cluster: $cluster})
                              MATCH (dep:Deployment {name: $name, namespace: $namespace, cluster: $cluster})
                              MERGE (s)-[:BACKED_BY]->(dep)
                              RETURN s.name
                              """
                              neo4j_query(rel_cypher, {"name": name, "namespace": namespace, "cluster": cluster})

                          total_count += count
                          logger.info(f"  {cluster}: {count} deployments")
                      except Exception as e:
                          logger.error(f"  {cluster}: deployment sync failed: {e}")
                          continue

                  logger.info(f"Synced {total_count} deployments across {len(K8S_CLUSTERS)} clusters")
                  return deploy_status

              def sync_kubernetes_services(deploy_status=None):
                  """Sync Kubernetes services and pods from all clusters to Neo4j."""
                  logger.info("Syncing Kubernetes services (multi-cluster)...")

                  total_svc = 0
                  total_pods = 0

                  for cluster in K8S_CLUSTERS:
                      try:
                          # Get services
                          services_response = call_mcp_tool("infrastructure", "kubectl_get_services", {"all_namespaces": True, "cluster": cluster})
                          services = extract_list(services_response, "services", "result")

                          count = 0
                          for svc in services:
                              name = svc.get("name")
                              namespace = svc.get("namespace")
                              if not name or not namespace:
                                  continue

                              svc_type = svc.get("type", "ClusterIP")
                              cluster_ip = svc.get("cluster_ip", "")

                              # Format ports
                              ports_list = svc.get("ports", [])
                              ports_str = ", ".join(
                                  f"{p.get('port', '')}:{p.get('target', '')}" +
                                  (f" (NP:{p['nodePort']})" if p.get('nodePort') else "")
                                  for p in ports_list
                              ) if ports_list else ""

                              # Derive status from matching deployment (now keyed by cluster)
                              deploy_info = (deploy_status or {}).get((name, namespace, cluster))
                              if deploy_info:
                                  svc_status = deploy_info["status"]
                                  replicas_str = f"{deploy_info['ready']}/{deploy_info['replicas']}"
                              else:
                                  svc_status = "active" if svc_type in ("ClusterIP", "NodePort", "LoadBalancer") else "unknown"
                                  replicas_str = ""

                              # Detect cross-cluster bridge services (no selector = proxy to external)
                              is_bridge = svc_type == "ClusterIP" and not svc.get("selector")

                              cypher = """
                              MERGE (s:Service {name: $name, namespace: $namespace, cluster: $cluster})
                              SET s.service_type = $service_type,
                                  s.cluster_ip = $cluster_ip,
                                  s.ports = $ports,
                                  s.status = $status,
                                  s.replicas = $replicas,
                                  s.is_bridge = $is_bridge,
                                  s.last_seen = datetime(),
                                  s.source = 'kubernetes'
                              RETURN s.name
                              """

                              result = neo4j_query(cypher, {
                                  "name": name,
                                  "namespace": namespace,
                                  "cluster": cluster,
                                  "service_type": svc_type,
                                  "cluster_ip": cluster_ip,
                                  "ports": ports_str,
                                  "status": svc_status,
                                  "replicas": replicas_str,
                                  "is_bridge": is_bridge
                              })

                              if not result.get("errors"):
                                  count += 1

                          total_svc += count

                          # Get pods
                          pods_response = call_mcp_tool("infrastructure", "kubectl_get_pods", {"all_namespaces": True, "cluster": cluster})
                          pods = extract_list(pods_response, "pods", "result")

                          pod_count = 0
                          for pod in pods:
                              name = pod.get("name")
                              namespace = pod.get("namespace")
                              if not name or not namespace:
                                  continue

                              node_name = pod.get("node", "unknown")
                              phase = pod.get("status", "unknown")
                              ready = pod.get("ready", False)
                              restart_count = pod.get("restarts", 0)

                              # Skip completed job pods — they clutter the graph
                              if phase == "Succeeded":
                                  continue

                              # Derive pod status
                              if phase == "Running" and ready:
                                  pod_status = "healthy"
                              elif phase == "Running" and not ready:
                                  pod_status = "degraded"
                              elif phase == "Succeeded":
                                  pod_status = "completed"
                              elif phase in ("Failed", "Unknown"):
                                  pod_status = "unhealthy"
                              else:
                                  pod_status = phase.lower() if phase else "unknown"

                              cypher = """
                              MERGE (p:Pod {name: $name, namespace: $namespace, cluster: $cluster})
                              SET p.node = $node,
                                  p.phase = $phase,
                                  p.status = $status,
                                  p.ready = $ready,
                                  p.restart_count = $restart_count,
                                  p.last_seen = datetime(),
                                  p.source = 'kubernetes'
                              WITH p
                              MERGE (h:Host {hostname: $node})
                              SET h.cluster = $cluster
                              MERGE (p)-[:SCHEDULED_ON]->(h)
                              RETURN p.name
                              """

                              result = neo4j_query(cypher, {
                                  "name": name,
                                  "namespace": namespace,
                                  "cluster": cluster,
                                  "node": node_name,
                                  "phase": phase,
                                  "status": pod_status,
                                  "ready": ready,
                                  "restart_count": restart_count
                              })

                              if not result.get("errors"):
                                  pod_count += 1

                          total_pods += pod_count
                          logger.info(f"  {cluster}: {count} services, {pod_count} pods")
                      except Exception as e:
                          logger.error(f"  {cluster}: service/pod sync failed: {e}")
                          continue

                  logger.info(f"Synced {total_svc} services, {total_pods} pods across {len(K8S_CLUSTERS)} clusters")
                  return total_svc

              def sync_kubernetes_ingresses():
                  """Sync Kubernetes ingresses from all clusters to Neo4j."""
                  logger.info("Syncing Kubernetes ingresses (multi-cluster)...")

                  total_count = 0

                  for cluster in K8S_CLUSTERS:
                      try:
                          ingresses_response = call_mcp_tool("infrastructure", "kubectl_get_ingresses", {"all_namespaces": True, "cluster": cluster})
                          ingresses = extract_list(ingresses_response, "ingresses", "result")

                          count = 0
                          for ing in ingresses:
                              name = ing.get("name")
                              namespace = ing.get("namespace")
                              if not name or not namespace:
                                  continue

                              ingress_class = ing.get("class", "")
                              has_tls = ing.get("tls", False)
                              hosts_data = ing.get("hosts", [])

                              # Build hosts and paths strings
                              all_hosts = []
                              all_paths = []
                              backend_services = []
                              for h in hosts_data:
                                  host = h.get("host", "*")
                                  all_hosts.append(host)
                                  for p in h.get("paths", []):
                                      path = p.get("path", "/") if isinstance(p, dict) else p
                                      svc_name = p.get("service", "") if isinstance(p, dict) else ""
                                      port = p.get("port", "") if isinstance(p, dict) else ""
                                      all_paths.append(f"{host}{path} -> {svc_name}:{port}" if svc_name else f"{host}{path}")
                                      if svc_name:
                                          backend_services.append((svc_name, namespace))

                              # Derive status from backends
                              ing_status = "active" if backend_services else "inactive"

                              cypher = """
                              MERGE (i:Ingress {name: $name, namespace: $namespace, cluster: $cluster})
                              SET i.ingress_class = $ingress_class,
                                  i.hosts = $hosts,
                                  i.paths = $paths,
                                  i.tls = $tls,
                                  i.status = $status,
                                  i.last_seen = datetime(),
                                  i.source = 'kubernetes'
                              RETURN i.name
                              """

                              result = neo4j_query(cypher, {
                                  "name": name,
                                  "namespace": namespace,
                                  "cluster": cluster,
                                  "ingress_class": ingress_class,
                                  "hosts": ", ".join(all_hosts),
                                  "paths": "; ".join(all_paths),
                                  "tls": has_tls,
                                  "status": ing_status
                              })

                              if not result.get("errors"):
                                  count += 1

                              # Create ROUTES_TO relationships to backend services
                              for svc_name, svc_ns in backend_services:
                                  rel_cypher = """
                                  MATCH (i:Ingress {name: $ing_name, namespace: $namespace, cluster: $cluster})
                                  MATCH (s:Service {name: $svc_name, namespace: $namespace, cluster: $cluster})
                                  MERGE (i)-[:ROUTES_TO]->(s)
                                  RETURN s.name
                                  """
                                  neo4j_query(rel_cypher, {
                                      "ing_name": name,
                                      "svc_name": svc_name,
                                      "namespace": svc_ns,
                                      "cluster": cluster
                                  })

                          total_count += count
                          logger.info(f"  {cluster}: {count} ingresses")
                      except Exception as e:
                          logger.error(f"  {cluster}: ingress sync failed: {e}")
                          continue

                  logger.info(f"Synced {total_count} ingresses across {len(K8S_CLUSTERS)} clusters")
                  return total_count

              def sync_kubernetes_nodes():
                  """Sync Kubernetes node info from all clusters to Host nodes."""
                  logger.info("Syncing Kubernetes nodes (multi-cluster)...")

                  total_count = 0

                  for cluster in K8S_CLUSTERS:
                      try:
                          nodes_response = call_mcp_tool("infrastructure", "kubectl_get_nodes", {"cluster": cluster})
                          nodes = extract_list(nodes_response, "nodes", "result")

                          count = 0
                          for node in nodes:
                              hostname = node.get("name", "")
                              if not hostname:
                                  continue

                              k8s_ready = node.get("ready", False)
                              k8s_version = node.get("version", "unknown")
                              k8s_os = node.get("os", "unknown")
                              conditions = node.get("conditions", {})
                              conditions_str = ", ".join(f"{k}={v}" for k, v in conditions.items()) if isinstance(conditions, dict) else ""

                              # Derive role from hostname pattern
                              if "control" in hostname.lower() or "master" in hostname.lower() or "cp" in hostname.lower():
                                  k8s_role = "control-plane"
                              else:
                                  k8s_role = "worker"

                              # Derive status from readiness
                              host_status = "healthy" if k8s_ready else "unhealthy"

                              cypher = """
                              MERGE (h:Host {hostname: $hostname})
                              SET h.k8s_version = $k8s_version,
                                  h.k8s_os = $k8s_os,
                                  h.k8s_ready = $k8s_ready,
                                  h.k8s_conditions = $k8s_conditions,
                                  h.k8s_role = $k8s_role,
                                  h.cluster = $cluster,
                                  h.status = $status,
                                  h.last_seen = datetime()
                              RETURN h.hostname
                              """

                              result = neo4j_query(cypher, {
                                  "hostname": hostname,
                                  "k8s_version": k8s_version,
                                  "k8s_os": k8s_os,
                                  "k8s_ready": k8s_ready,
                                  "k8s_conditions": conditions_str,
                                  "k8s_role": k8s_role,
                                  "cluster": cluster,
                                  "status": host_status
                              })

                              if not result.get("errors"):
                                  count += 1

                          total_count += count
                          logger.info(f"  {cluster}: {count} nodes")
                      except Exception as e:
                          logger.error(f"  {cluster}: node sync failed: {e}")
                          continue

                  logger.info(f"Synced {total_count} nodes across {len(K8S_CLUSTERS)} clusters")
                  return total_count

              def sync_runbooks():
                  """Sync runbooks to Neo4j with rich relationship enrichment."""
                  logger.info("Syncing runbook relationships...")

                  # Pre-fetch known entities from graph for text matching
                  svc_result = neo4j_query("MATCH (s:Service) RETURN s.name as name, s.namespace as ns")
                  known_services = {}
                  for row in svc_result.get("results", [{}])[0].get("data", []):
                      svc_name = row["row"][0]
                      if svc_name and len(svc_name) > 3:
                          known_services[svc_name.lower()] = svc_name

                  host_result = neo4j_query("MATCH (h:Host) RETURN h.hostname as hostname")
                  known_hosts = set()
                  for row in host_result.get("results", [{}])[0].get("data", []):
                      hostname = row["row"][0]
                      if hostname and len(hostname) > 3:
                          known_hosts.add(hostname.lower())

                  alert_result = neo4j_query("MATCH (a:Alert) RETURN a.name as name")
                  known_alerts = set()
                  for row in alert_result.get("results", [{}])[0].get("data", []):
                      alert_name = row["row"][0]
                      if alert_name:
                          known_alerts.add(alert_name)

                  logger.info(f"  Pre-fetched {len(known_services)} services, {len(known_hosts)} hosts, {len(known_alerts)} alerts for matching")

                  # Get runbooks from knowledge MCP REST API
                  runbooks_response = call_rest_api(MCP_SERVERS["knowledge"], "/api/runbooks?limit=100")
                  runbooks = runbooks_response.get("runbooks", [])

                  count = 0
                  rel_count = 0
                  for runbook_entry in runbooks:
                      qdrant_id = runbook_entry.get("id", "")
                      title = runbook_entry.get("title", "")
                      trigger_pattern = runbook_entry.get("trigger_pattern", "")

                      if not title:
                          continue

                      # Derive domain from path if not set
                      path = runbook_entry.get("path", "")
                      domain = runbook_entry.get("domain", "")
                      if not domain and path:
                          path_parts = path.replace("\\", "/").split("/")
                          try:
                              rb_idx = path_parts.index("runbooks")
                              if rb_idx + 1 < len(path_parts) - 1:
                                  domain = path_parts[rb_idx + 1]
                          except ValueError:
                              domain = path_parts[0] if len(path_parts) > 1 else ""

                      solution = runbook_entry.get("solution", "")
                      solution_preview = solution[:200] if solution else ""
                      has_content = bool(solution)

                      # Create runbook node
                      cypher = """
                      MERGE (r:RunbookDocument {qdrant_id: $qdrant_id})
                      SET r.title = $title,
                          r.path = $path,
                          r.domain = $domain,
                          r.automation_level = $automation_level,
                          r.trigger_pattern = $trigger_pattern,
                          r.solution_preview = $solution_preview,
                          r.has_content = $has_content,
                          r.last_seen = datetime(),
                          r.source = 'knowledge'
                      RETURN r.title
                      """

                      result = neo4j_query(cypher, {
                          "qdrant_id": qdrant_id,
                          "title": title,
                          "path": path,
                          "domain": domain,
                          "automation_level": runbook_entry.get("automation_level", "manual"),
                          "trigger_pattern": trigger_pattern,
                          "solution_preview": solution_preview,
                          "has_content": has_content
                      })

                      if not result.get("errors"):
                          count += 1

                      # --- Relationship enrichment ---
                      solution_lower = (solution + " " + title).lower()

                      # A. RESOLVES→Alert: trigger_pattern match + fuzzy title match
                      if trigger_pattern and not trigger_pattern.startswith("*"):
                          neo4j_query("""
                          MATCH (r:RunbookDocument {qdrant_id: $qdrant_id})
                          MERGE (a:Alert {name: $alert_name})
                          MERGE (r)-[:RESOLVES]->(a)
                          """, {"qdrant_id": qdrant_id, "alert_name": trigger_pattern})
                          rel_count += 1

                      # Fuzzy title→alert match
                      title_normalized = title.lower().replace(" ", "").replace("-", "").replace("_", "")
                      for alert_name in known_alerts:
                          alert_normalized = alert_name.lower().replace(" ", "").replace("-", "").replace("_", "")
                          if title_normalized == alert_normalized or alert_name.lower() in solution_lower:
                              neo4j_query("""
                              MATCH (r:RunbookDocument {qdrant_id: $qdrant_id})
                              MATCH (a:Alert {name: $alert_name})
                              MERGE (r)-[:RESOLVES]->(a)
                              """, {"qdrant_id": qdrant_id, "alert_name": alert_name})
                              rel_count += 1

                      # B. TROUBLESHOOTS→Service: text match service names in solution
                      for svc_lower, svc_name in known_services.items():
                          if svc_lower in solution_lower:
                              neo4j_query("""
                              MATCH (r:RunbookDocument {qdrant_id: $qdrant_id})
                              MATCH (s:Service {name: $svc_name})
                              MERGE (r)-[:TROUBLESHOOTS]->(s)
                              """, {"qdrant_id": qdrant_id, "svc_name": svc_name})
                              rel_count += 1

                      # C. APPLIES_TO→Host: text match hostnames in solution
                      for hostname_lower in known_hosts:
                          if hostname_lower in solution_lower:
                              neo4j_query("""
                              MATCH (r:RunbookDocument {qdrant_id: $qdrant_id})
                              MATCH (h:Host {hostname: $hostname})
                              MERGE (r)-[:APPLIES_TO]->(h)
                              """, {"qdrant_id": qdrant_id, "hostname": hostname_lower})
                              rel_count += 1

                      # D. COVERS_NAMESPACE removed — too noisy, linked every service in namespace
                      # Runbook→Service connections are handled by TROUBLESHOOTS (text match)
                      # and RESOLVES (alert match) which are more precise

                  logger.info(f"Synced {count} runbooks, {rel_count} relationships created")
                  return count

              def sync_coroot_services():
                  """Sync service health from Coroot to Neo4j."""
                  logger.info("Syncing Coroot service health...")

                  # Get overview from consolidated observability-mcp
                  overview_response = call_mcp_tool("observability", "coroot_get_infrastructure_overview")
                  overview = overview_response

                  if not overview or not isinstance(overview, dict) or "error" in overview:
                      logger.warning(f"Coroot overview unavailable: {overview.get('error', 'no data') if isinstance(overview, dict) else 'unexpected format'}")
                      return 0

                  # Coroot cluster ID mapping
                  COROOT_CLUSTER_IDS = {"jd756uxv", "qorspfs5", "loka6zue"}

                  count = 0
                  anomalous_services = []
                  services = overview.get("services", {})
                  for service_key, service_data in services.items():
                      # Parse namespace/service from Coroot id
                      # 4-part format: "cluster_id:namespace:Kind:name"
                      # 2-part format: "namespace:service"
                      coroot_id = service_data.get("id", service_key)
                      parts = coroot_id.split(":")
                      if len(parts) == 4:
                          # 4-part Coroot ID — extract namespace and name only
                          _, namespace, kind, name = parts
                          # Skip Talos system services (not K8s workloads)
                          if namespace == "_" or kind == "Unknown":
                              continue
                      elif len(parts) == 2:
                          namespace = parts[0]
                          name = parts[1]
                      elif "/" in service_key:
                          sparts = service_key.split("/", 1)
                          namespace = sparts[0]
                          name = sparts[1]
                      else:
                          namespace = "unknown"
                          name = service_key

                      # Skip port-number-only names and FQDN names
                      if name.isdigit() or "." in name:
                          continue
                      # Skip if namespace is a Coroot cluster hash
                      if namespace in COROOT_CLUSTER_IDS:
                          continue

                      health = service_data.get("health", "unknown")
                      anomaly_count = service_data.get("anomalies", 0)

                      # Map health to status
                      health_to_status = {
                          "ok": "healthy",
                          "warning": "warning",
                          "critical": "critical",
                          "error": "critical"
                      }
                      status = health_to_status.get(health, "unknown")

                      # Track anomalous services for dependency sync
                      if anomaly_count > 0:
                          anomalous_services.append(coroot_id)

                      # Update existing service (don't create new ones from Coroot data)
                      cypher = """
                      MATCH (s:Service {name: $name, namespace: $namespace})
                      SET s.health = $health,
                          s.coroot_id = $coroot_id,
                          s.anomaly_count = $anomaly_count,
                          s.last_health_check = datetime()
                      RETURN s.name
                      """

                      result = neo4j_query(cypher, {
                          "name": name,
                          "namespace": namespace,
                          "health": health,
                          "coroot_id": coroot_id,
                          "anomaly_count": anomaly_count
                      })

                      if not result.get("errors"):
                          count += 1

                  # Get alerts from consolidated observability-mcp
                  alerts_response = call_mcp_tool("observability", "coroot_get_alerts")
                  alerts = extract_list(alerts_response, "alerts", "result")

                  for alert in alerts:
                      alert_name = alert.get("name", alert.get("alertname", "unknown"))
                      service = alert.get("service", "")
                      status = alert.get("status", "unknown")
                      severity = alert.get("severity", alert.get("labels", {}).get("severity", "info"))

                      cypher = """
                      MERGE (a:Alert {name: $alert_name})
                      SET a.status = $status,
                          a.severity = $severity,
                          a.service = $service,
                          a.last_seen = datetime(),
                          a.source = 'coroot'
                      RETURN a.name
                      """

                      neo4j_query(cypher, {
                          "alert_name": alert_name,
                          "status": status,
                          "severity": severity,
                          "service": service
                      })

                  logger.info(f"Synced {count} services from Coroot, {len(alerts)} alerts")
                  return count, anomalous_services

              def sync_coroot_service_map():
                  """Sync global service dependency map from Coroot (replaces per-service API)."""
                  logger.info("Syncing Coroot service dependency map...")

                  # Map Coroot cluster IDs to our cluster names
                  COROOT_CLUSTER_MAP = {"jd756uxv": "prod", "qorspfs5": "agentic", "loka6zue": "monit"}

                  def parse_coroot_id(app_id):
                      """Parse Coroot 4-part ID into (cluster, namespace, kind, name)."""
                      parts = app_id.split(":")
                      if len(parts) == 4:
                          cluster_id, namespace, kind, name = parts
                          return COROOT_CLUSTER_MAP.get(cluster_id, cluster_id), namespace, kind, name
                      elif len(parts) == 2:
                          return "unknown", parts[0], "Service", parts[1]
                      return None, None, None, None

                  map_response = call_mcp_tool("observability", "coroot_get_service_map")
                  if not map_response or isinstance(map_response, dict) and "error" in map_response:
                      logger.warning(f"Coroot service map unavailable: {map_response}")
                      return 0

                  # Parse response — MCP may return JSON string or dict
                  if isinstance(map_response, str):
                      try:
                          map_response = json.loads(map_response)
                      except (json.JSONDecodeError, TypeError):
                          logger.warning(f"Coroot service map returned non-JSON: {str(map_response)[:200]}")
                          return 0

                  if not isinstance(map_response, dict):
                      logger.warning(f"Coroot service map unexpected type: {type(map_response)}")
                      return 0

                  # Navigate to map data (structure: {data: {nodes: [...]}})
                  data = map_response.get("data", map_response)
                  if not isinstance(data, dict):
                      data = map_response
                  nodes = data.get("nodes", data.get("map", []))
                  if nodes is None:
                      nodes = []
                  if isinstance(nodes, dict):
                      nodes = list(nodes.values())

                  logger.info(f"  Coroot map: {len(nodes)} nodes, type={type(nodes).__name__}, sample keys={list(nodes[0].keys()) if nodes and isinstance(nodes[0], dict) else 'N/A'}")

                  dep_count = 0
                  for node in nodes:
                      if not isinstance(node, dict):
                          continue
                      app_id = node.get("id", node.get("app_id", ""))
                      if not app_id:
                          continue

                      src_cluster, src_ns, src_kind, src_name = parse_coroot_id(app_id)
                      if not src_name:
                          continue

                      # Process upstreams (services this node depends on)
                      for upstream in (node.get("upstreams") or []):
                          up_id = upstream if isinstance(upstream, str) else upstream.get("id", "")
                          up_cluster, up_ns, up_kind, up_name = parse_coroot_id(up_id)
                          if not up_name:
                              continue

                          cypher = """
                          MERGE (s1:Service {name: $src_name, namespace: $src_ns})
                          MERGE (s2:Service {name: $up_name, namespace: $up_ns})
                          MERGE (s1)-[r:DEPENDS_ON]->(s2)
                          SET r.last_seen = datetime(), r.source = 'coroot'
                          RETURN s2.name
                          """
                          result = neo4j_query(cypher, {
                              "src_name": src_name, "src_ns": src_ns,
                              "up_name": up_name, "up_ns": up_ns
                          })
                          if not result.get("errors"):
                              dep_count += 1

                      # Process downstreams (services that depend on this node)
                      for downstream in (node.get("downstreams") or []):
                          down_id = downstream if isinstance(downstream, str) else downstream.get("id", "")
                          down_cluster, down_ns, down_kind, down_name = parse_coroot_id(down_id)
                          if not down_name:
                              continue

                          cypher = """
                          MERGE (s1:Service {name: $down_name, namespace: $down_ns})
                          MERGE (s2:Service {name: $src_name, namespace: $src_ns})
                          MERGE (s1)-[r:DEPENDS_ON]->(s2)
                          SET r.last_seen = datetime(), r.source = 'coroot'
                          RETURN s1.name
                          """
                          result = neo4j_query(cypher, {
                              "src_name": src_name, "src_ns": src_ns,
                              "down_name": down_name, "down_ns": down_ns
                          })
                          if not result.get("errors"):
                              dep_count += 1

                  logger.info(f"Synced {dep_count} service dependencies from Coroot service map")
                  return dep_count

              def sync_gatus_health():
                  """Sync endpoint health from Gatus to Neo4j."""
                  logger.info("Syncing Gatus endpoint health...")

                  # Get endpoint statuses directly from Gatus API
                  response = call_rest_api(GATUS_URL, "/api/v1/endpoints/statuses")

                  if not response or isinstance(response, dict) and "error" in response:
                      logger.warning(f"Gatus unavailable: {response}")
                      return 0

                  count = 0
                  linked = 0
                  endpoints = response if isinstance(response, list) else []

                  for endpoint in endpoints:
                      name = endpoint.get("name", "unknown")
                      group = endpoint.get("group", "default")
                      key = endpoint.get("key", f"{group}_{name}")

                      # Get latest result
                      results = endpoint.get("results", [])
                      latest = results[-1] if results else {}
                      success = latest.get("success", False)
                      status_code = latest.get("status", 0)
                      response_time = latest.get("duration", 0) / 1000000  # Convert ns to ms

                      # Calculate uptime from recent results
                      uptime = 0
                      if results:
                          successful = sum(1 for r in results if r.get("success", False))
                          uptime = round((successful / len(results)) * 100, 2)

                      # Derive status from success + uptime
                      if success and uptime >= 99:
                          monitor_status = "healthy"
                      elif success:
                          monitor_status = "degraded"
                      else:
                          monitor_status = "unhealthy"

                      cypher = """
                      MERGE (e:UptimeMonitor {key: $key})
                      SET e.name = $name,
                          e.group = $group,
                          e.healthy = $healthy,
                          e.status_code = $status_code,
                          e.response_time_ms = $response_time,
                          e.uptime_percent = $uptime,
                          e.status = $status,
                          e.last_check = datetime(),
                          e.source = 'gatus'
                      RETURN e.key
                      """

                      result = neo4j_query(cypher, {
                          "key": key,
                          "name": name,
                          "group": group,
                          "healthy": success,
                          "status_code": status_code,
                          "response_time": response_time,
                          "uptime": uptime,
                          "status": monitor_status
                      })

                      if not result.get("errors"):
                          count += 1

                      # Link UptimeMonitor→Service: try exact match, then fuzzy
                      clean_name = name.lower().strip().replace(" ", "-")
                      if len(clean_name) > 3:
                          # Strategy 1: Exact name match
                          cypher_exact = """
                          MATCH (e:UptimeMonitor {key: $key})
                          MATCH (s:Service)
                          WHERE toLower(s.name) = $clean_name
                          MERGE (e)-[:MONITORS]->(s)
                          RETURN s.name as matched
                          """
                          link_result = neo4j_query(cypher_exact, {"key": key, "clean_name": clean_name})
                          matched = link_result.get("results", [{}])[0].get("data", [])

                          # Strategy 2: Tightened fuzzy match if no exact hit
                          # Excludes MCP servers (infra, not monitored targets) and
                          # requires similar length to prevent false substring matches
                          if not matched:
                              cypher_fuzzy = """
                              MATCH (e:UptimeMonitor {key: $key})
                              MATCH (s:Service)
                              WHERE (toLower(s.name) CONTAINS $clean_name OR $clean_name CONTAINS toLower(s.name))
                                AND size(s.name) > 3
                                AND NOT toLower(s.name) ENDS WITH '-mcp'
                                AND toFloat(size(s.name)) / toFloat(size($clean_name)) > 0.5
                                AND toFloat(size(s.name)) / toFloat(size($clean_name)) < 2.0
                              WITH e, s LIMIT 1
                              MERGE (e)-[:MONITORS]->(s)
                              RETURN s.name as matched
                              """
                              link_result = neo4j_query(cypher_fuzzy, {"key": key, "clean_name": clean_name})
                              matched = link_result.get("results", [{}])[0].get("data", [])

                          if matched:
                              linked += 1

                  logger.info(f"Synced {count} endpoints from Gatus, {linked} linked to services")
                  return count

              def sync_ha_areas():
                  """Sync area/location data from Home Assistant to Neo4j.

                  Graceful degradation: If HA-MCP fails, log warning and continue.
                  Discovery/graph-sync should not fail due to HA being unavailable.
                  """
                  logger.info("Syncing Home Assistant areas...")

                  # Get entities from HA via consolidated home-mcp
                  try:
                      entities_response = call_mcp_tool("home", "list_entities")
                      if not entities_response:
                          logger.warning("Home-MCP unavailable or returned empty response, skipping area sync")
                          return 0
                  except Exception as e:
                      logger.warning(f"Home-MCP unavailable, skipping area sync: {e}")
                      return 0

                  entities = extract_list(entities_response, "entities", "result")
                  if not entities:
                      logger.info("No entities returned from HA, skipping area sync")
                      return 0

                  synced_count = 0
                  for entity in entities:
                      area = entity.get("area", entity.get("area_id", ""))
                      # Try to extract IP from entity_id or attributes
                      entity_id = entity.get("entity_id", "")
                      attributes = entity.get("attributes", {})
                      ip = attributes.get("ip", attributes.get("ip_address", ""))

                      # Skip if no area or no IP to match
                      if not area or not ip:
                          continue

                      try:
                          # Update Neo4j Host node with location and create Location relationship
                          cypher = """
                          MATCH (h:Host {ip: $ip})
                          SET h.location = $area
                          WITH h
                          MERGE (loc:Location {name: $area})
                          MERGE (h)-[:LOCATED_IN]->(loc)
                          RETURN h.ip
                          """
                          result = neo4j_query(cypher, {"ip": ip, "area": area})

                          if result.get("results") and result["results"][0].get("data"):
                              synced_count += 1
                              logger.debug(f"Synced location '{area}' for {ip}")
                      except Exception as e:
                          logger.warning(f"Failed to sync area for {ip}: {e}")
                          continue

                  logger.info(f"HA area sync complete: {synced_count} entities updated")
                  return synced_count

              # =========================================================================
              # New sync functions (Project 11)
              # =========================================================================

              def sync_argocd_apps():
                  """Sync ArgoCD applications from prod cluster to Neo4j (GitOps chain)."""
                  logger.info("Syncing ArgoCD applications...")

                  apps_response = call_mcp_tool("infrastructure", "argocd_get_applications")
                  apps = extract_list(apps_response, "applications", "result")

                  count = 0
                  for app in apps:
                      name = app.get("name")
                      if not name:
                          continue

                      project = app.get("project", "default")
                      sync_status = app.get("sync_status", "unknown")
                      health = app.get("health", "unknown")
                      repo = app.get("repo", "")
                      path = app.get("path", "")

                      # Map health+sync to lifecycle status
                      if health == "Healthy" and sync_status == "Synced":
                          app_status = "healthy"
                      elif health == "Degraded":
                          app_status = "degraded"
                      elif sync_status == "OutOfSync":
                          app_status = "out-of-sync"
                      elif health == "Missing":
                          app_status = "unhealthy"
                      else:
                          app_status = health.lower() if health else "unknown"

                      # Derive target cluster from destination path
                      if "agentic" in (path or ""):
                          target_cluster = "agentic"
                      elif "monit" in (path or ""):
                          target_cluster = "monit"
                      else:
                          target_cluster = "prod"

                      cypher = """
                      MERGE (a:ArgoApp {name: $name})
                      SET a.project = $project,
                          a.sync_status = $sync_status,
                          a.health = $health,
                          a.repo = $repo,
                          a.path = $path,
                          a.target_cluster = $target_cluster,
                          a.status = $status,
                          a.last_seen = datetime(),
                          a.source = 'argocd'
                      RETURN a.name
                      """

                      result = neo4j_query(cypher, {
                          "name": name,
                          "project": project,
                          "sync_status": sync_status,
                          "health": health,
                          "repo": repo,
                          "path": path,
                          "target_cluster": target_cluster,
                          "status": app_status
                      })

                      if not result.get("errors"):
                          count += 1

                      # Link ArgoApp→Service by name match in target cluster
                      neo4j_query("""
                      MATCH (a:ArgoApp {name: $name})
                      MATCH (s:Service {name: $name, cluster: $target_cluster})
                      MERGE (a)-[:DEPLOYS]->(s)
                      """, {"name": name, "target_cluster": target_cluster})

                      # Also try path-derived name (e.g. "kubernetes/applications/qdrant" → "qdrant")
                      if path:
                          app_from_path = path.rstrip("/").split("/")[-1]
                          if app_from_path and app_from_path != name:
                              neo4j_query("""
                              MATCH (a:ArgoApp {name: $argo_name})
                              MATCH (s:Service {name: $svc_name})
                              WHERE NOT (a)-[:DEPLOYS]->(s)
                              MERGE (a)-[:DEPLOYS]->(s)
                              """, {"argo_name": name, "svc_name": app_from_path})

                  logger.info(f"Synced {count} ArgoCD applications")
                  return count

              def sync_kubernetes_pvcs():
                  """Sync PVCs from all clusters to Neo4j."""
                  logger.info("Syncing Kubernetes PVCs (multi-cluster)...")

                  total_count = 0
                  for cluster in K8S_CLUSTERS:
                      try:
                          pvcs_response = call_mcp_tool("infrastructure", "kubectl_get_pvcs", {"all_namespaces": True, "cluster": cluster})
                          pvcs = extract_list(pvcs_response, "pvcs", "result")

                          count = 0
                          for pvc in pvcs:
                              name = pvc.get("name")
                              namespace = pvc.get("namespace")
                              if not name or not namespace:
                                  continue

                              phase = pvc.get("status", "unknown").lower()
                              capacity = pvc.get("capacity", "")
                              storage_class = pvc.get("storage_class", "")
                              volume_name = pvc.get("volume_name", "")

                              pvc_status = {"bound": "healthy", "pending": "pending", "lost": "unhealthy"}.get(phase, phase)

                              cypher = """
                              MERGE (pvc:PersistentVolumeClaim {name: $name, namespace: $namespace, cluster: $cluster})
                              SET pvc.status = $status,
                                  pvc.capacity = $capacity,
                                  pvc.storage_class = $storage_class,
                                  pvc.volume_name = $volume_name,
                                  pvc.last_seen = datetime(),
                                  pvc.source = 'kubernetes'
                              RETURN pvc.name
                              """

                              result = neo4j_query(cypher, {
                                  "name": name,
                                  "namespace": namespace,
                                  "cluster": cluster,
                                  "status": pvc_status,
                                  "capacity": capacity,
                                  "storage_class": storage_class,
                                  "volume_name": volume_name
                              })

                              if not result.get("errors"):
                                  count += 1

                          total_count += count
                          logger.info(f"  {cluster}: {count} PVCs")
                      except Exception as e:
                          logger.error(f"  {cluster}: PVC sync failed: {e}")
                          continue

                  logger.info(f"Synced {total_count} PVCs across {len(K8S_CLUSTERS)} clusters")
                  return total_count

              def sync_dns_topology():
                  """Sync DNS topology from AdGuard rewrites and Unbound overrides."""
                  logger.info("Syncing DNS topology...")

                  count = 0

                  # AdGuard rewrites
                  try:
                      rewrites_response = call_mcp_tool("infrastructure", "get_adguard_rewrites")
                      rewrites = extract_list(rewrites_response, "rewrites", "result")

                      for rewrite in rewrites:
                          domain = rewrite.get("domain", "")
                          answer = rewrite.get("answer", "")
                          if not domain:
                              continue

                          cypher = """
                          MERGE (d:DNSRecord {domain: $domain})
                          SET d.hostname = $domain,
                              d.answer = $answer,
                              d.record_type = 'rewrite',
                              d.source = 'adguard',
                              d.status = 'active',
                              d.last_seen = datetime()
                          RETURN d.domain
                          """
                          result = neo4j_query(cypher, {"domain": domain, "answer": answer})
                          if not result.get("errors"):
                              count += 1

                          # Link to Host if answer is an IP
                          if answer and answer[0].isdigit():
                              neo4j_query("""
                              MATCH (d:DNSRecord {domain: $domain})
                              MATCH (h:Host {ip: $ip})
                              MERGE (d)-[:RESOLVES_TO]->(h)
                              """, {"domain": domain, "ip": answer})

                          # Link to Service by subdomain match
                          subdomain = domain.split(".")[0] if "." in domain else domain
                          if len(subdomain) > 3:
                              neo4j_query("""
                              MATCH (d:DNSRecord {domain: $domain})
                              MATCH (s:Service)
                              WHERE toLower(s.name) = toLower($subdomain)
                              MERGE (d)-[:RESOLVES_TO]->(s)
                              """, {"domain": domain, "subdomain": subdomain})

                      logger.info(f"  AdGuard: {count} DNS rewrites")
                  except Exception as e:
                      logger.error(f"  AdGuard DNS sync failed: {e}")

                  # Unbound overrides
                  unbound_count = 0
                  try:
                      overrides_response = call_mcp_tool("infrastructure", "get_unbound_overrides")
                      overrides = extract_list(overrides_response, "overrides", "result")

                      for override in overrides:
                          domain = override.get("domain", override.get("host", ""))
                          target = override.get("server", override.get("ip", override.get("target", "")))
                          if not domain:
                              continue

                          cypher = """
                          MERGE (d:DNSRecord {domain: $domain})
                          SET d.hostname = $domain,
                              d.answer = $target,
                              d.record_type = 'override',
                              d.source = 'unbound',
                              d.status = 'active',
                              d.last_seen = datetime()
                          RETURN d.domain
                          """
                          result = neo4j_query(cypher, {"domain": domain, "target": target})
                          if not result.get("errors"):
                              unbound_count += 1

                          # Link to Host if target is an IP
                          if target and target[0].isdigit():
                              neo4j_query("""
                              MATCH (d:DNSRecord {domain: $domain})
                              MATCH (h:Host {ip: $ip})
                              MERGE (d)-[:RESOLVES_TO]->(h)
                              """, {"domain": domain, "ip": target})

                      logger.info(f"  Unbound: {unbound_count} DNS overrides")
                  except Exception as e:
                      logger.error(f"  Unbound DNS sync failed: {e}")

                  total = count + unbound_count
                  logger.info(f"Synced {total} DNS records total")
                  return total

              def sync_keep_alerts():
                  """Sync Keep alert aggregation to Neo4j."""
                  logger.info("Syncing Keep alerts...")

                  alerts_response = call_mcp_tool("observability", "keep_list_alerts")
                  if not alerts_response or isinstance(alerts_response, dict) and "error" in alerts_response:
                      logger.warning(f"Keep unavailable: {alerts_response}")
                      return 0

                  alerts = extract_list(alerts_response, "alerts", "result")

                  count = 0
                  for alert in alerts:
                      name = alert.get("name", alert.get("fingerprint", "unknown"))
                      status = alert.get("status", "unknown")
                      severity = alert.get("severity", "info")
                      source = alert.get("source", [])
                      source_str = ", ".join(source) if isinstance(source, list) else str(source)
                      description = alert.get("description", "")

                      alert_status = {"firing": "firing", "resolved": "resolved", "acknowledged": "acknowledged"}.get(status, status)

                      cypher = """
                      MERGE (a:Alert {name: $name})
                      SET a.status = $alert_status,
                          a.severity = $severity,
                          a.alert_source = $source,
                          a.description = $description,
                          a.keep_status = $keep_status,
                          a.last_seen = datetime()
                      RETURN a.name
                      """

                      result = neo4j_query(cypher, {
                          "name": name,
                          "alert_status": alert_status,
                          "severity": severity,
                          "source": source_str,
                          "description": description[:500] if description else "",
                          "keep_status": status
                      })

                      if not result.get("errors"):
                          count += 1

                      # Link Alert→Service if alert has service label
                      svc = alert.get("service", "")
                      if not svc and isinstance(alert.get("labels"), dict):
                          svc = alert["labels"].get("service", "")
                      if svc:
                          neo4j_query("""
                          MATCH (a:Alert {name: $name})
                          MATCH (s:Service {name: $svc})
                          MERGE (a)-[:AFFECTS]->(s)
                          """, {"name": name, "svc": svc})

                  logger.info(f"Synced {count} alerts from Keep")
                  return count

              def sync_grafana_dashboards():
                  """Sync Grafana dashboards to Neo4j."""
                  logger.info("Syncing Grafana dashboards...")

                  dashboards_response = call_mcp_tool("observability", "grafana_list_dashboards")
                  if not dashboards_response or isinstance(dashboards_response, dict) and "error" in dashboards_response:
                      logger.warning(f"Grafana unavailable: {dashboards_response}")
                      return 0

                  dashboards = extract_list(dashboards_response, "dashboards", "result")

                  count = 0
                  for dash in dashboards:
                      title = dash.get("title", "")
                      uid = dash.get("uid", "")
                      if not title or not uid:
                          continue

                      folder = dash.get("folderTitle", dash.get("folder", ""))
                      tags = dash.get("tags", [])
                      tags_str = ", ".join(tags) if isinstance(tags, list) else str(tags)
                      url = dash.get("url", "")

                      cypher = """
                      MERGE (d:Dashboard {uid: $uid})
                      SET d.title = $title,
                          d.folder = $folder,
                          d.tags = $tags,
                          d.url = $url,
                          d.status = 'active',
                          d.last_seen = datetime(),
                          d.source = 'grafana'
                      RETURN d.uid
                      """

                      result = neo4j_query(cypher, {
                          "uid": uid,
                          "title": title,
                          "folder": folder,
                          "tags": tags_str,
                          "url": url
                      })

                      if not result.get("errors"):
                          count += 1

                      # Link Dashboard→Service by tag matching
                      for tag in (tags if isinstance(tags, list) else []):
                          if len(tag) > 3:
                              neo4j_query("""
                              MATCH (d:Dashboard {uid: $uid})
                              MATCH (s:Service)
                              WHERE toLower(s.name) = toLower($tag)
                              MERGE (d)-[:VISUALIZES]->(s)
                              """, {"uid": uid, "tag": tag})

                  logger.info(f"Synced {count} Grafana dashboards")
                  return count

              def _extract_count(result):
                  """Extract count from Neo4j query result."""
                  try:
                      return result["results"][0]["data"][0]["row"][0]
                  except (KeyError, IndexError, TypeError):
                      return 0

              def run_lifecycle_management():
                  """Update entity lifecycle status for ALL node types."""
                  logger.info("Running lifecycle management...")

                  # Node types and their stale/archive/delete thresholds
                  lifecycle_config = {
                      "Host": {"stale": "PT8H", "offline": "P2D", "archive": "P14D"},
                      "VM": {"stale": "PT8H", "offline": "P2D", "archive": "P14D"},
                      "Pod": {"delete_after": "P1D"},
                      "Service": {"stale": "PT12H", "offline": "P3D", "delete_after": "P7D"},
                      "Alert": {"delete_after": "P7D"},
                      "UptimeMonitor": {"stale": "PT12H", "delete_after": "P7D"},
                      "RunbookDocument": {"stale": "P1D", "delete_after": "P7D"},
                      "SmartDevice": {"stale": "P1D", "offline": "P7D", "delete_after": "P30D"},
                      "NAS": {"stale": "PT8H", "offline": "P2D"},
                      "Share": {"stale": "P1D", "delete_after": "P14D"},
                      "AccessPoint": {"stale": "PT8H", "offline": "P2D", "archive": "P14D"},
                      "Switch": {"stale": "PT8H", "offline": "P2D", "archive": "P14D"},
                      "Deployment": {"stale": "PT12H", "offline": "P3D", "delete_after": "P7D"},
                      "Ingress": {"stale": "PT12H", "offline": "P3D", "delete_after": "P7D"},
                      "StoragePool": {"stale": "PT8H", "offline": "P2D"},
                      "Dataset": {"stale": "PT8H", "offline": "P2D"},
                      "ArgoApp": {"stale": "PT12H", "delete_after": "P7D"},
                      "PersistentVolumeClaim": {"stale": "PT12H", "delete_after": "P7D"},
                      "DNSRecord": {"stale": "P1D", "delete_after": "P14D"},
                      "Dashboard": {"stale": "P1D", "delete_after": "P14D"},
                  }

                  total_stale = 0
                  total_offline = 0
                  total_deleted = 0
                  total_archived = 0

                  for label, thresholds in lifecycle_config.items():
                      # Mark stale
                      if "stale" in thresholds:
                          result = neo4j_query(f"""
                              MATCH (n:{label})
                              WHERE n.last_seen < datetime() - duration('{thresholds["stale"]}')
                                AND (n.status IS NULL OR n.status IN ['online', 'healthy', 'degraded', 'warning', 'unknown', 'running', 'completed', 'pending', 'scaled-down'])
                              SET n.status = 'stale'
                              RETURN count(n) as cnt
                          """)
                          cnt = _extract_count(result)
                          total_stale += cnt

                      # Mark offline
                      if "offline" in thresholds:
                          result = neo4j_query(f"""
                              MATCH (n:{label} {{status: 'stale'}})
                              WHERE n.last_seen < datetime() - duration('{thresholds["offline"]}')
                              SET n.status = 'offline'
                              RETURN count(n) as cnt
                          """)
                          cnt = _extract_count(result)
                          total_offline += cnt

                      # Delete old nodes
                      if "delete_after" in thresholds:
                          result = neo4j_query(f"""
                              MATCH (n:{label})
                              WHERE n.last_seen < datetime() - duration('{thresholds["delete_after"]}')
                              DETACH DELETE n
                              RETURN count(n) as cnt
                          """)
                          cnt = _extract_count(result)
                          total_deleted += cnt
                          if cnt > 0:
                              logger.info(f"  Deleted {cnt} stale {label} nodes")

                      # Archive (relabel) long-offline
                      if "archive" in thresholds:
                          result = neo4j_query(f"""
                              MATCH (n:{label} {{status: 'offline'}})
                              WHERE n.last_seen < datetime() - duration('{thresholds["archive"]}')
                              SET n:Archived{label}
                              REMOVE n:{label}
                              RETURN count(n) as cnt
                          """)
                          cnt = _extract_count(result)
                          total_archived += cnt
                          if cnt > 0:
                              logger.info(f"  Archived {cnt} {label} nodes")

                  # Clean up orphan nodes with no relationships
                  for label in ["Location", "Network"]:
                      result = neo4j_query(f"""
                          MATCH (n:{label})
                          WHERE NOT (n)--()
                          DELETE n
                          RETURN count(n) as cnt
                      """)
                      cnt = _extract_count(result)
                      if cnt > 0:
                          logger.info(f"  Deleted {cnt} orphan {label} nodes")
                          total_deleted += cnt

                  logger.info(f"Lifecycle: {total_stale} stale, {total_offline} offline, {total_deleted} deleted, {total_archived} archived")

              def main():
                  logger.info("Starting graph-sync job")
                  start_time = datetime.now()

                  # Verify Neo4j connection
                  test_result = neo4j_query("RETURN 1 as test")
                  if test_result.get("errors"):
                      logger.error(f"Neo4j connection failed: {test_result}")
                      return 1

                  logger.info("Neo4j connection verified")

                  # Sync from each source
                  results = {}
                  deploy_status = {}
                  anomalous_services = []

                  try:
                      results["proxmox_vms"] = sync_proxmox_vms()
                  except Exception as e:
                      logger.error(f"Proxmox sync failed: {e}")
                      results["proxmox_vms"] = 0

                  try:
                      results["unifi_devices"] = sync_unifi_devices()
                  except Exception as e:
                      logger.error(f"UniFi sync failed: {e}")
                      results["unifi_devices"] = 0

                  try:
                      results["truenas_storage"] = sync_truenas_storage()
                  except Exception as e:
                      logger.error(f"TrueNAS sync failed: {e}")
                      results["truenas_storage"] = 0

                  # Deployments MUST run before services (provides deploy_status lookup)
                  try:
                      deploy_status = sync_kubernetes_deployments()
                      results["deployments"] = len(deploy_status)
                  except Exception as e:
                      logger.error(f"Kubernetes deployments sync failed: {e}")
                      results["deployments"] = 0

                  try:
                      results["kubernetes"] = sync_kubernetes_services(deploy_status)
                  except Exception as e:
                      logger.error(f"Kubernetes sync failed: {e}")
                      results["kubernetes"] = 0

                  try:
                      results["ingresses"] = sync_kubernetes_ingresses()
                  except Exception as e:
                      logger.error(f"Kubernetes ingresses sync failed: {e}")
                      results["ingresses"] = 0

                  try:
                      results["k8s_nodes"] = sync_kubernetes_nodes()
                  except Exception as e:
                      logger.error(f"Kubernetes nodes sync failed: {e}")
                      results["k8s_nodes"] = 0

                  try:
                      results["runbooks"] = sync_runbooks()
                  except Exception as e:
                      logger.error(f"Runbooks sync failed: {e}")
                      results["runbooks"] = 0

                  try:
                      coroot_count, anomalous_services = sync_coroot_services()
                      results["coroot_services"] = coroot_count
                  except Exception as e:
                      logger.error(f"Coroot sync failed: {e}")
                      results["coroot_services"] = 0

                  try:
                      results["coroot_service_map"] = sync_coroot_service_map()
                  except Exception as e:
                      logger.error(f"Coroot service map sync failed: {e}")
                      results["coroot_service_map"] = 0

                  try:
                      results["gatus_health"] = sync_gatus_health()
                  except Exception as e:
                      logger.error(f"Gatus sync failed: {e}")
                      results["gatus_health"] = 0

                  try:
                      results["ha_areas"] = sync_ha_areas()
                  except Exception as e:
                      logger.error(f"HA area sync failed: {e}")
                      results["ha_areas"] = 0

                  try:
                      results["argocd_apps"] = sync_argocd_apps()
                  except Exception as e:
                      logger.error(f"ArgoCD apps sync failed: {e}")
                      results["argocd_apps"] = 0

                  try:
                      results["pvcs"] = sync_kubernetes_pvcs()
                  except Exception as e:
                      logger.error(f"Kubernetes PVCs sync failed: {e}")
                      results["pvcs"] = 0

                  try:
                      results["dns_topology"] = sync_dns_topology()
                  except Exception as e:
                      logger.error(f"DNS topology sync failed: {e}")
                      results["dns_topology"] = 0

                  try:
                      results["keep_alerts"] = sync_keep_alerts()
                  except Exception as e:
                      logger.error(f"Keep alerts sync failed: {e}")
                      results["keep_alerts"] = 0

                  try:
                      results["grafana_dashboards"] = sync_grafana_dashboards()
                  except Exception as e:
                      logger.error(f"Grafana dashboards sync failed: {e}")
                      results["grafana_dashboards"] = 0

                  # Run lifecycle management
                  try:
                      run_lifecycle_management()
                  except Exception as e:
                      logger.error(f"Lifecycle management failed: {e}")

                  elapsed = (datetime.now() - start_time).total_seconds()
                  logger.info(f"Graph sync completed in {elapsed:.1f}s: {results}")
                  return 0

              if __name__ == "__main__":
                  exit(main())
