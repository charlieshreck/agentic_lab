apiVersion: batch/v1
kind: CronJob
metadata:
  name: graph-sync
  namespace: ai-platform
  labels:
    app: graph-sync
    component: discovery
spec:
  schedule: "15 */4 * * *"  # Every 4 hours, 15 min after discovery
  concurrencyPolicy: Forbid  # Prevent overlapping runs
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      backoffLimit: 2
      activeDeadlineSeconds: 240  # 4 minute timeout
      template:
        metadata:
          labels:
            app: graph-sync
        spec:
          restartPolicy: Never
          containers:
          - name: graph-sync
            image: python:3.11-slim
            env:
            - name: NEO4J_URL
              value: "http://neo4j:7474"
            - name: NEO4J_USER
              value: "neo4j"
            - name: NEO4J_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: neo4j-credentials
                  key: NEO4J_PASSWORD
            # Consolidated MCP endpoints (cluster-internal)
            - name: INFRASTRUCTURE_MCP_URL
              value: "http://infrastructure-mcp:8000"
            - name: KNOWLEDGE_MCP_URL
              value: "http://knowledge-mcp:8000"
            - name: OBSERVABILITY_MCP_URL
              value: "http://observability-mcp:8000"
            - name: HOME_MCP_URL
              value: "http://home-mcp:8000"
            - name: GATUS_URL
              value: "http://gatus.monit.kernow.io"
            resources:
              requests:
                memory: "128Mi"
                cpu: "100m"
              limits:
                memory: "256Mi"
                cpu: "500m"
            command:
            - python
            - -c
            - |
              import os
              import json
              import asyncio
              import logging
              from datetime import datetime, timedelta
              from base64 import b64encode
              from urllib.request import Request, urlopen
              from urllib.error import URLError, HTTPError

              logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
              logger = logging.getLogger(__name__)

              # Configuration
              NEO4J_URL = os.environ.get("NEO4J_URL", "http://neo4j:7474")
              NEO4J_USER = os.environ.get("NEO4J_USER", "neo4j")
              NEO4J_PASSWORD = os.environ.get("NEO4J_PASSWORD", "")  # Don't strip - Neo4j was initialized with newline

              # Consolidated MCP endpoints
              MCP_SERVERS = {
                  "infrastructure": os.environ.get("INFRASTRUCTURE_MCP_URL", "http://infrastructure-mcp:8000"),
                  "knowledge": os.environ.get("KNOWLEDGE_MCP_URL", "http://knowledge-mcp:8000"),
                  "observability": os.environ.get("OBSERVABILITY_MCP_URL", "http://observability-mcp:8000"),
                  "home": os.environ.get("HOME_MCP_URL", "http://home-mcp:8000"),
              }

              # Direct API access (cross-cluster)
              GATUS_URL = os.environ.get("GATUS_URL", "http://gatus.monit.kernow.io")

              def neo4j_query(cypher: str, params: dict = None) -> dict:
                  """Execute Cypher query via Neo4j HTTP API."""
                  url = f"{NEO4J_URL}/db/neo4j/tx/commit"
                  auth = b64encode(f"{NEO4J_USER}:{NEO4J_PASSWORD}".encode()).decode()

                  body = {
                      "statements": [{
                          "statement": cypher,
                          "parameters": params or {}
                      }]
                  }

                  req = Request(
                      url,
                      data=json.dumps(body).encode(),
                      headers={
                          "Content-Type": "application/json",
                          "Authorization": f"Basic {auth}"
                      },
                      method="POST"
                  )

                  try:
                      with urlopen(req, timeout=30) as resp:
                          return json.loads(resp.read().decode())
                  except (URLError, HTTPError) as e:
                      logger.error(f"Neo4j query failed: {e}")
                      return {"errors": [str(e)]}

              def call_mcp_tool(server: str, tool_name: str, arguments: dict = None) -> dict:
                  """Call MCP tool via JSON-RPC with SSE response parsing."""
                  url = f"{MCP_SERVERS.get(server, '')}/mcp"

                  body = {
                      "jsonrpc": "2.0",
                      "id": 1,
                      "method": "tools/call",
                      "params": {
                          "name": tool_name,
                          "arguments": arguments or {}
                      }
                  }

                  req = Request(
                      url,
                      data=json.dumps(body).encode(),
                      headers={
                          "Content-Type": "application/json",
                          "Accept": "application/json, text/event-stream"
                      },
                      method="POST"
                  )

                  try:
                      with urlopen(req, timeout=30) as resp:
                          raw = resp.read().decode()
                          # Parse SSE format: "event: message\ndata: {...}"
                          for line in raw.split('\n'):
                              if line.startswith('data: '):
                                  result = json.loads(line[6:])  # Skip "data: " prefix
                                  if "result" in result and "content" in result["result"]:
                                      content = result["result"]["content"]
                                      if content and len(content) > 0:
                                          text = content[0].get("text", "{}")
                                          return json.loads(text) if text.startswith(('{', '[')) else {"text": text}
                                  return result.get("result", {})
                          # Fallback: try parsing as plain JSON (non-SSE response)
                          try:
                              result = json.loads(raw)
                              if "result" in result and "content" in result["result"]:
                                  content = result["result"]["content"]
                                  if content and len(content) > 0:
                                      text = content[0].get("text", "{}")
                                      return json.loads(text) if text.startswith(('{', '[')) else {"text": text}
                              return result.get("result", {})
                          except json.JSONDecodeError:
                              pass
                          return {}
                  except (URLError, HTTPError) as e:
                      logger.warning(f"MCP call {server}/{tool_name} failed: {e}")
                      return {}
                  except json.JSONDecodeError as e:
                      logger.warning(f"MCP call {server}/{tool_name} JSON parse failed: {e}")
                      return {}

              def extract_list(response, *keys):
                  """Extract a list from MCP tool response, handling various formats."""
                  if isinstance(response, list):
                      return response
                  if isinstance(response, dict):
                      # Try 'result' key first (common MCP tool wrapper)
                      if "result" in response and isinstance(response["result"], list):
                          return response["result"]
                      # Try specified keys
                      for key in keys:
                          if key in response and isinstance(response[key], list):
                              return response[key]
                  return []

              def call_rest_api(base_url: str, endpoint: str) -> dict:
                  """Call REST API endpoint directly."""
                  url = f"{base_url}{endpoint}"
                  req = Request(url, headers={"Accept": "application/json"}, method="GET")
                  try:
                      with urlopen(req, timeout=30) as resp:
                          return json.loads(resp.read().decode())
                  except (URLError, HTTPError) as e:
                      logger.warning(f"REST call {url} failed: {e}")
                      return {}
                  except json.JSONDecodeError as e:
                      logger.warning(f"REST call {url} JSON parse failed: {e}")
                      return {}

              def sync_proxmox_vms():
                  """Sync VMs from Proxmox to Neo4j."""
                  logger.info("Syncing Proxmox VMs...")

                  # Get VMs list via consolidated infrastructure-mcp
                  vms_response = call_mcp_tool("infrastructure", "proxmox_list_vms", {"params": {"response_format": "json"}})
                  vms = extract_list(vms_response, "vms")

                  if not vms:
                      logger.warning("No VMs returned from Proxmox MCP")
                      return 0

                  count = 0
                  for vm in vms:
                      vmid = vm.get("vmid")
                      name = vm.get("name", f"vm-{vmid}")
                      status = vm.get("status", "unknown")
                      node = vm.get("node", "unknown")

                      # Extract resource metrics from Proxmox response
                      cpu_percent = round(vm.get("cpu", 0) * 100, 1)
                      cpus = vm.get("maxcpu", vm.get("cpus", 0))
                      mem_used = vm.get("mem", 0)
                      mem_total = vm.get("maxmem", 0)
                      memory_used_gb = round(mem_used / (1024**3), 2) if mem_used else 0
                      memory_total_gb = round(mem_total / (1024**3), 2) if mem_total else 0
                      memory_percent = round((mem_used / mem_total) * 100, 1) if mem_total else 0
                      uptime_days = round(vm.get("uptime", 0) / 86400, 2)
                      netin_gb = round(vm.get("netin", 0) / (1024**3), 2)
                      netout_gb = round(vm.get("netout", 0) / (1024**3), 2)
                      disk_max_gb = round(vm.get("maxdisk", 0) / (1024**3), 2)

                      # Create VM node
                      cypher = """
                      MERGE (v:VM {vmid: $vmid})
                      SET v.name = $name,
                          v.status = $status,
                          v.node = $node,
                          v.type = $type,
                          v.cpu_percent = $cpu_percent,
                          v.cpus = $cpus,
                          v.memory_used_gb = $memory_used_gb,
                          v.memory_total_gb = $memory_total_gb,
                          v.memory_percent = $memory_percent,
                          v.uptime_days = $uptime_days,
                          v.netin_gb = $netin_gb,
                          v.netout_gb = $netout_gb,
                          v.disk_max_gb = $disk_max_gb,
                          v.last_seen = datetime(),
                          v.source = 'proxmox'
                      WITH v
                      MERGE (h:Host {hostname: $node})
                      SET h.type = 'hypervisor'
                      MERGE (h)-[:HOSTS]->(v)
                      RETURN v.vmid
                      """

                      result = neo4j_query(cypher, {
                          "vmid": str(vmid),
                          "name": name,
                          "status": status,
                          "node": node,
                          "type": vm.get("type", "qemu"),
                          "cpu_percent": cpu_percent,
                          "cpus": cpus,
                          "memory_used_gb": memory_used_gb,
                          "memory_total_gb": memory_total_gb,
                          "memory_percent": memory_percent,
                          "uptime_days": uptime_days,
                          "netin_gb": netin_gb,
                          "netout_gb": netout_gb,
                          "disk_max_gb": disk_max_gb
                      })

                      if not result.get("errors"):
                          count += 1

                  logger.info(f"Synced {count} VMs from Proxmox")
                  return count

              def sync_unifi_devices():
                  """Sync UniFi network devices to Neo4j."""
                  logger.info("Syncing UniFi devices...")

                  # Get devices (APs, switches) via consolidated home-mcp
                  devices_response = call_mcp_tool("home", "unifi_list_devices")
                  devices = extract_list(devices_response, "devices", "result")

                  count = 0
                  for device in devices:
                      mac = device.get("mac", "").lower()
                      if not mac:
                          continue

                      name = device.get("name", device.get("hostname", f"device-{mac}"))
                      device_type = device.get("type", "unknown")
                      model = device.get("model", "unknown")
                      ip = device.get("ip", "")

                      # Determine node label based on type
                      label = "AccessPoint" if device_type in ["uap", "ap"] else "Switch" if device_type in ["usw", "sw"] else "NetworkDevice"

                      cypher = f"""
                      MERGE (d:{label} {{mac: $mac}})
                      SET d.name = $name,
                          d.model = $model,
                          d.ip = $ip,
                          d.status = $status,
                          d.last_seen = datetime(),
                          d.source = 'unifi'
                      RETURN d.mac
                      """

                      result = neo4j_query(cypher, {
                          "mac": mac,
                          "name": name,
                          "model": model,
                          "ip": ip,
                          "status": device.get("state", "unknown")
                      })

                      if not result.get("errors"):
                          count += 1

                  # Get clients and their AP connections via consolidated home-mcp
                  clients_response = call_mcp_tool("home", "unifi_list_clients")
                  clients = extract_list(clients_response, "clients", "result")

                  for client in clients:
                      mac = client.get("mac", "").lower()
                      ap_mac = client.get("ap_mac", "").lower()

                      if mac and ap_mac:
                          # Create CONNECTED_VIA relationship
                          cypher = """
                          MATCH (h:Host {mac: $mac})
                          MATCH (ap:AccessPoint {mac: $ap_mac})
                          MERGE (h)-[r:CONNECTED_VIA]->(ap)
                          SET r.signal = $signal,
                              r.channel = $channel,
                              r.last_seen = datetime()
                          RETURN type(r)
                          """

                          neo4j_query(cypher, {
                              "mac": mac,
                              "ap_mac": ap_mac,
                              "signal": client.get("signal", 0),
                              "channel": client.get("channel", 0)
                          })

                  logger.info(f"Synced {count} UniFi devices, processed {len(clients)} client connections")
                  return count

              def sync_truenas_storage():
                  """Sync TrueNAS storage to Neo4j."""
                  logger.info("Syncing TrueNAS storage...")

                  # Get pools via consolidated infrastructure-mcp
                  pools_response = call_mcp_tool("infrastructure", "truenas_list_pools", {"params": {"instance": "hdd", "response_format": "json"}})
                  pools = extract_list(pools_response, "pools", "result")

                  count = 0
                  for pool in pools:
                      name = pool.get("name")
                      if not name:
                          continue

                      cypher = """
                      MERGE (p:StoragePool {name: $name})
                      SET p.status = $status,
                          p.size = $size,
                          p.used = $used,
                          p.last_seen = datetime(),
                          p.source = 'truenas'
                      RETURN p.name
                      """

                      result = neo4j_query(cypher, {
                          "name": name,
                          "status": pool.get("status", "unknown"),
                          "size": pool.get("size", 0),
                          "used": pool.get("used", 0)
                      })

                      if not result.get("errors"):
                          count += 1

                  # Get datasets via consolidated infrastructure-mcp
                  datasets_response = call_mcp_tool("infrastructure", "truenas_list_datasets", {"params": {"instance": "hdd", "response_format": "json"}})
                  datasets = extract_list(datasets_response, "datasets", "result")

                  for dataset in datasets:
                      name = dataset.get("name", "")
                      pool_name = name.split("/")[0] if "/" in name else name

                      cypher = """
                      MERGE (d:Dataset {name: $name})
                      SET d.mountpoint = $mountpoint,
                          d.used = $used,
                          d.available = $available,
                          d.last_seen = datetime(),
                          d.source = 'truenas'
                      WITH d
                      MATCH (p:StoragePool {name: $pool_name})
                      MERGE (p)-[:CONTAINS]->(d)
                      RETURN d.name
                      """

                      neo4j_query(cypher, {
                          "name": name,
                          "pool_name": pool_name,
                          "mountpoint": dataset.get("mountpoint", ""),
                          "used": dataset.get("used", 0),
                          "available": dataset.get("available", 0)
                      })

                  # Get shares via consolidated infrastructure-mcp
                  shares_response = call_mcp_tool("infrastructure", "truenas_list_shares", {"params": {"instance": "hdd", "response_format": "json"}})
                  # Shares may return {nfs: [], smb: []} dict, {result: []} wrapper, or flat list
                  if isinstance(shares_response, list):
                      shares = shares_response
                  elif isinstance(shares_response, dict):
                      if "result" in shares_response and isinstance(shares_response["result"], list):
                          shares = shares_response["result"]
                      else:
                          nfs_shares = shares_response.get("nfs", [])
                          smb_shares = shares_response.get("smb", [])
                          shares = nfs_shares + smb_shares
                  else:
                      shares = []

                  for share in shares:
                      path = share.get("path", "")
                      name = share.get("name", path.split("/")[-1] if path else "unknown")

                      cypher = """
                      MERGE (s:Share {path: $path})
                      SET s.name = $name,
                          s.type = $type,
                          s.enabled = $enabled,
                          s.last_seen = datetime(),
                          s.source = 'truenas'
                      RETURN s.path
                      """

                      neo4j_query(cypher, {
                          "path": path,
                          "name": name,
                          "type": share.get("type", "nfs"),
                          "enabled": share.get("enabled", True)
                      })

                  logger.info(f"Synced {count} storage pools, {len(datasets)} datasets, {len(shares)} shares")
                  return count

              def sync_kubernetes_deployments():
                  """Sync Kubernetes deployments to Neo4j. Returns deploy_status lookup dict."""
                  logger.info("Syncing Kubernetes deployments...")
                  cluster = "agentic"

                  deploys_response = call_mcp_tool("infrastructure", "kubectl_get_deployments", {"all_namespaces": True})
                  deploys = extract_list(deploys_response, "deployments", "result")

                  deploy_status = {}
                  count = 0
                  for d in deploys:
                      name = d.get("name")
                      namespace = d.get("namespace")
                      if not name or not namespace:
                          continue

                      replicas = d.get("replicas", 0)
                      ready = d.get("ready", 0)
                      available = d.get("available", 0)

                      # Derive status
                      if replicas == 0:
                          status = "scaled-down"
                      elif ready >= replicas:
                          status = "healthy"
                      elif ready > 0:
                          status = "degraded"
                      else:
                          status = "unhealthy"

                      # Store for Service enrichment
                      deploy_status[(name, namespace)] = {
                          "status": status,
                          "replicas": replicas,
                          "ready": ready,
                          "available": available
                      }

                      # Extract selector for transparency
                      selector = d.get("selector", "")

                      cypher = """
                      MERGE (dep:Deployment {name: $name, namespace: $namespace, cluster: $cluster})
                      SET dep.replicas = $replicas,
                          dep.ready_replicas = $ready,
                          dep.available_replicas = $available,
                          dep.status = $status,
                          dep.selector = $selector,
                          dep.last_seen = datetime(),
                          dep.source = 'kubernetes'
                      RETURN dep.name
                      """

                      result = neo4j_query(cypher, {
                          "name": name,
                          "namespace": namespace,
                          "cluster": cluster,
                          "replicas": replicas,
                          "ready": ready,
                          "available": available,
                          "status": status,
                          "selector": selector
                      })

                      if not result.get("errors"):
                          count += 1

                      # Create BACKED_BY relationship (Serviceâ†’Deployment) by name+namespace heuristic
                      rel_cypher = """
                      MATCH (s:Service {name: $name, namespace: $namespace, cluster: $cluster})
                      MATCH (dep:Deployment {name: $name, namespace: $namespace, cluster: $cluster})
                      MERGE (s)-[:BACKED_BY]->(dep)
                      RETURN s.name
                      """
                      neo4j_query(rel_cypher, {"name": name, "namespace": namespace, "cluster": cluster})

                  logger.info(f"Synced {count} deployments from agentic cluster")
                  return deploy_status

              def sync_kubernetes_services(deploy_status=None):
                  """Sync Kubernetes services to Neo4j.

                  Note: infrastructure-mcp only has access to the agentic cluster.
                  Prod cluster services are covered by Coroot's service discovery.
                  """
                  logger.info("Syncing Kubernetes services...")
                  cluster = "agentic"

                  # Get services via consolidated infrastructure-mcp
                  services_response = call_mcp_tool("infrastructure", "kubectl_get_services", {"all_namespaces": True})
                  services = extract_list(services_response, "services", "result")

                  count = 0
                  for svc in services:
                      name = svc.get("name")
                      namespace = svc.get("namespace")

                      if not name or not namespace:
                          continue

                      svc_type = svc.get("type", "ClusterIP")
                      cluster_ip = svc.get("cluster_ip", "")

                      # Format ports as "port:targetPort" strings
                      ports_list = svc.get("ports", [])
                      ports_str = ", ".join(
                          f"{p.get('port', '')}:{p.get('target', '')}" +
                          (f" (NP:{p['nodePort']})" if p.get('nodePort') else "")
                          for p in ports_list
                      ) if ports_list else ""

                      # Derive status from matching deployment
                      deploy_info = (deploy_status or {}).get((name, namespace))
                      if deploy_info:
                          svc_status = deploy_info["status"]
                          replicas_str = f"{deploy_info['ready']}/{deploy_info['replicas']}"
                      else:
                          svc_status = "unknown"
                          replicas_str = ""

                      cypher = """
                      MERGE (s:Service {name: $name, namespace: $namespace, cluster: $cluster})
                      SET s.service_type = $service_type,
                          s.cluster_ip = $cluster_ip,
                          s.ports = $ports,
                          s.status = $status,
                          s.replicas = $replicas,
                          s.last_seen = datetime(),
                          s.source = 'kubernetes'
                      RETURN s.name
                      """

                      result = neo4j_query(cypher, {
                          "name": name,
                          "namespace": namespace,
                          "cluster": cluster,
                          "service_type": svc_type,
                          "cluster_ip": cluster_ip,
                          "ports": ports_str,
                          "status": svc_status,
                          "replicas": replicas_str
                      })

                      if not result.get("errors"):
                          count += 1

                  # Get pods via consolidated infrastructure-mcp
                  pods_response = call_mcp_tool("infrastructure", "kubectl_get_pods", {"all_namespaces": True})
                  pods = extract_list(pods_response, "pods", "result")

                  pod_count = 0
                  for pod in pods:
                      name = pod.get("name")
                      namespace = pod.get("namespace")

                      if not name or not namespace:
                          continue

                      node_name = pod.get("node", "unknown")
                      phase = pod.get("status", "unknown")
                      ready = pod.get("ready", False)
                      restart_count = pod.get("restarts", 0)

                      # Derive pod status from phase + ready
                      if phase == "Running" and ready:
                          pod_status = "healthy"
                      elif phase == "Running" and not ready:
                          pod_status = "degraded"
                      elif phase == "Succeeded":
                          pod_status = "completed"
                      elif phase in ("Failed", "Unknown"):
                          pod_status = "unhealthy"
                      else:
                          pod_status = phase.lower() if phase else "unknown"

                      cypher = """
                      MERGE (p:Pod {name: $name, namespace: $namespace, cluster: $cluster})
                      SET p.node = $node,
                          p.phase = $phase,
                          p.status = $status,
                          p.ready = $ready,
                          p.restart_count = $restart_count,
                          p.last_seen = datetime(),
                          p.source = 'kubernetes'
                      WITH p
                      MERGE (h:Host {hostname: $node})
                      MERGE (p)-[:SCHEDULED_ON]->(h)
                      RETURN p.name
                      """

                      result = neo4j_query(cypher, {
                          "name": name,
                          "namespace": namespace,
                          "cluster": cluster,
                          "node": node_name,
                          "phase": phase,
                          "status": pod_status,
                          "ready": ready,
                          "restart_count": restart_count
                      })

                      if not result.get("errors"):
                          pod_count += 1

                  logger.info(f"Synced {count} services, {pod_count} pods from agentic cluster")
                  return count

              def sync_kubernetes_ingresses():
                  """Sync Kubernetes ingresses to Neo4j."""
                  logger.info("Syncing Kubernetes ingresses...")
                  cluster = "agentic"

                  ingresses_response = call_mcp_tool("infrastructure", "kubectl_get_ingresses", {"all_namespaces": True})
                  ingresses = extract_list(ingresses_response, "ingresses", "result")

                  count = 0
                  for ing in ingresses:
                      name = ing.get("name")
                      namespace = ing.get("namespace")
                      if not name or not namespace:
                          continue

                      ingress_class = ing.get("class", "")
                      has_tls = ing.get("tls", False)
                      hosts_data = ing.get("hosts", [])

                      # Build hosts and paths strings
                      all_hosts = []
                      all_paths = []
                      backend_services = []
                      for h in hosts_data:
                          host = h.get("host", "*")
                          all_hosts.append(host)
                          for p in h.get("paths", []):
                              path = p.get("path", "/") if isinstance(p, dict) else p
                              svc_name = p.get("service", "") if isinstance(p, dict) else ""
                              port = p.get("port", "") if isinstance(p, dict) else ""
                              all_paths.append(f"{host}{path} -> {svc_name}:{port}" if svc_name else f"{host}{path}")
                              if svc_name:
                                  backend_services.append((svc_name, namespace))

                      cypher = """
                      MERGE (i:Ingress {name: $name, namespace: $namespace, cluster: $cluster})
                      SET i.ingress_class = $ingress_class,
                          i.hosts = $hosts,
                          i.paths = $paths,
                          i.tls = $tls,
                          i.last_seen = datetime(),
                          i.source = 'kubernetes'
                      RETURN i.name
                      """

                      result = neo4j_query(cypher, {
                          "name": name,
                          "namespace": namespace,
                          "cluster": cluster,
                          "ingress_class": ingress_class,
                          "hosts": ", ".join(all_hosts),
                          "paths": "; ".join(all_paths),
                          "tls": has_tls
                      })

                      if not result.get("errors"):
                          count += 1

                      # Create ROUTES_TO relationships to backend services
                      for svc_name, svc_ns in backend_services:
                          rel_cypher = """
                          MATCH (i:Ingress {name: $ing_name, namespace: $namespace, cluster: $cluster})
                          MATCH (s:Service {name: $svc_name, namespace: $namespace, cluster: $cluster})
                          MERGE (i)-[:ROUTES_TO]->(s)
                          RETURN s.name
                          """
                          neo4j_query(rel_cypher, {
                              "ing_name": name,
                              "svc_name": svc_name,
                              "namespace": svc_ns,
                              "cluster": cluster
                          })

                  logger.info(f"Synced {count} ingresses from agentic cluster")
                  return count

              def sync_kubernetes_nodes():
                  """Sync Kubernetes node info to existing Host nodes."""
                  logger.info("Syncing Kubernetes nodes...")

                  nodes_response = call_mcp_tool("infrastructure", "kubectl_get_nodes")
                  nodes = extract_list(nodes_response, "nodes", "result")

                  count = 0
                  for node in nodes:
                      hostname = node.get("name", "")
                      if not hostname:
                          continue

                      k8s_ready = node.get("ready", False)
                      k8s_version = node.get("version", "unknown")
                      k8s_os = node.get("os", "unknown")
                      conditions = node.get("conditions", {})
                      conditions_str = ", ".join(f"{k}={v}" for k, v in conditions.items()) if isinstance(conditions, dict) else ""

                      # Derive role from hostname pattern
                      if "control" in hostname.lower() or "master" in hostname.lower() or "cp" in hostname.lower():
                          k8s_role = "control-plane"
                      else:
                          k8s_role = "worker"

                      cypher = """
                      MERGE (h:Host {hostname: $hostname})
                      SET h.k8s_version = $k8s_version,
                          h.k8s_os = $k8s_os,
                          h.k8s_ready = $k8s_ready,
                          h.k8s_conditions = $k8s_conditions,
                          h.k8s_role = $k8s_role,
                          h.last_seen = datetime()
                      RETURN h.hostname
                      """

                      result = neo4j_query(cypher, {
                          "hostname": hostname,
                          "k8s_version": k8s_version,
                          "k8s_os": k8s_os,
                          "k8s_ready": k8s_ready,
                          "k8s_conditions": conditions_str,
                          "k8s_role": k8s_role
                      })

                      if not result.get("errors"):
                          count += 1

                  logger.info(f"Synced {count} Kubernetes nodes")
                  return count

              def sync_runbooks():
                  """Link runbooks to alerts in Neo4j."""
                  logger.info("Syncing runbook relationships...")

                  # Get runbooks from knowledge MCP REST API
                  runbooks_response = call_rest_api(MCP_SERVERS["knowledge"], "/api/runbooks?limit=100")
                  runbooks = runbooks_response.get("runbooks", [])

                  count = 0
                  for runbook_entry in runbooks:
                      # /api/runbooks returns flattened: {id, title, trigger_pattern, solution, automation_level, path, domain}
                      qdrant_id = runbook_entry.get("id", "")
                      title = runbook_entry.get("title", "")
                      trigger_pattern = runbook_entry.get("trigger_pattern", "")

                      if not title:
                          continue

                      # Derive domain from path if not set
                      path = runbook_entry.get("path", "")
                      domain = runbook_entry.get("domain", "")
                      if not domain and path:
                          # Extract directory after "runbooks/" e.g. "runbooks/infrastructure/foo.md" -> "infrastructure"
                          path_parts = path.replace("\\", "/").split("/")
                          try:
                              rb_idx = path_parts.index("runbooks")
                              if rb_idx + 1 < len(path_parts) - 1:
                                  domain = path_parts[rb_idx + 1]
                          except ValueError:
                              # No "runbooks" in path, use first directory
                              domain = path_parts[0] if len(path_parts) > 1 else ""

                      # Extract solution preview and content flag
                      solution = runbook_entry.get("solution", "")
                      solution_preview = solution[:200] if solution else ""
                      has_content = bool(solution)

                      # Create runbook node
                      cypher = """
                      MERGE (r:RunbookDocument {qdrant_id: $qdrant_id})
                      SET r.title = $title,
                          r.path = $path,
                          r.domain = $domain,
                          r.automation_level = $automation_level,
                          r.trigger_pattern = $trigger_pattern,
                          r.solution_preview = $solution_preview,
                          r.has_content = $has_content,
                          r.last_seen = datetime(),
                          r.source = 'knowledge'
                      RETURN r.title
                      """

                      result = neo4j_query(cypher, {
                          "qdrant_id": qdrant_id,
                          "title": title,
                          "path": path,
                          "domain": domain,
                          "automation_level": runbook_entry.get("automation_level", "manual"),
                          "trigger_pattern": trigger_pattern,
                          "solution_preview": solution_preview,
                          "has_content": has_content
                      })

                      if not result.get("errors"):
                          count += 1

                      # If trigger_pattern looks like an alert name, create RESOLVES relationship
                      if trigger_pattern and not trigger_pattern.startswith("*"):
                          alert_cypher = """
                          MATCH (r:RunbookDocument {qdrant_id: $qdrant_id})
                          MERGE (a:Alert {name: $alert_name})
                          MERGE (r)-[:RESOLVES]->(a)
                          RETURN a.name
                          """

                          neo4j_query(alert_cypher, {
                              "qdrant_id": qdrant_id,
                              "alert_name": trigger_pattern
                          })

                  logger.info(f"Synced {count} runbooks")
                  return count

              def sync_coroot_services():
                  """Sync service health from Coroot to Neo4j."""
                  logger.info("Syncing Coroot service health...")

                  # Get overview from consolidated observability-mcp
                  overview_response = call_mcp_tool("observability", "coroot_get_infrastructure_overview")
                  overview = overview_response

                  if not overview or not isinstance(overview, dict) or "error" in overview:
                      logger.warning(f"Coroot overview unavailable: {overview.get('error', 'no data') if isinstance(overview, dict) else 'unexpected format'}")
                      return 0

                  count = 0
                  anomalous_services = []
                  services = overview.get("services", {})
                  for service_key, service_data in services.items():
                      # Parse namespace/service from Coroot id (format: "namespace:service")
                      # Also try "/" separator as fallback
                      coroot_id = service_data.get("id", service_key)
                      if ":" in coroot_id:
                          parts = coroot_id.split(":", 1)
                          namespace = parts[0]
                          name = parts[1]
                      elif "/" in service_key:
                          parts = service_key.split("/", 1)
                          namespace = parts[0]
                          name = parts[1]
                      else:
                          namespace = "unknown"
                          name = service_key

                      health = service_data.get("health", "unknown")
                      anomaly_count = service_data.get("anomalies", 0)

                      # Map health to status
                      health_to_status = {
                          "ok": "healthy",
                          "warning": "warning",
                          "critical": "critical",
                          "error": "critical"
                      }
                      status = health_to_status.get(health, "unknown")

                      # Track anomalous services for dependency sync
                      if anomaly_count > 0:
                          anomalous_services.append(coroot_id)

                      cypher = """
                      MERGE (s:Service {name: $name, namespace: $namespace})
                      SET s.health = $health,
                          s.status = $status,
                          s.coroot_id = $coroot_id,
                          s.anomaly_count = $anomaly_count,
                          s.last_health_check = datetime(),
                          s.source = 'coroot'
                      RETURN s.name
                      """

                      result = neo4j_query(cypher, {
                          "name": name,
                          "namespace": namespace,
                          "health": health,
                          "status": status,
                          "coroot_id": coroot_id,
                          "anomaly_count": anomaly_count
                      })

                      if not result.get("errors"):
                          count += 1

                  # Get alerts from consolidated observability-mcp
                  alerts_response = call_mcp_tool("observability", "coroot_get_alerts")
                  alerts = extract_list(alerts_response, "alerts", "result")

                  for alert in alerts:
                      alert_name = alert.get("name", alert.get("alertname", "unknown"))
                      service = alert.get("service", "")
                      status = alert.get("status", "unknown")
                      severity = alert.get("severity", alert.get("labels", {}).get("severity", "info"))

                      cypher = """
                      MERGE (a:Alert {name: $alert_name})
                      SET a.status = $status,
                          a.severity = $severity,
                          a.service = $service,
                          a.last_seen = datetime(),
                          a.source = 'coroot'
                      RETURN a.name
                      """

                      neo4j_query(cypher, {
                          "alert_name": alert_name,
                          "status": status,
                          "severity": severity,
                          "service": service
                      })

                  logger.info(f"Synced {count} services from Coroot, {len(alerts)} alerts")
                  return count, anomalous_services

              def sync_coroot_dependencies(anomalous_services):
                  """Sync service dependencies from Coroot for anomalous services."""
                  if not anomalous_services:
                      logger.info("No anomalous services, skipping dependency sync")
                      return 0

                  logger.info(f"Syncing Coroot dependencies for {len(anomalous_services)} anomalous services...")

                  dep_count = 0
                  for service_id in anomalous_services[:20]:  # Cap at 20 to limit API calls
                      try:
                          deps_response = call_mcp_tool("observability", "coroot_get_service_dependencies", {"app_id": service_id})
                          if not deps_response or isinstance(deps_response, dict) and "error" in deps_response:
                              continue

                          # Parse the service name from the id
                          if ":" in service_id:
                              parts = service_id.split(":", 1)
                              src_namespace = parts[0]
                              src_name = parts[1]
                          else:
                              src_namespace = "unknown"
                              src_name = service_id

                          # Extract dependencies (upstream and downstream)
                          deps = deps_response if isinstance(deps_response, list) else deps_response.get("dependencies", [])
                          if isinstance(deps_response, dict) and "map" in deps_response:
                              deps = deps_response["map"]

                          if isinstance(deps, list):
                              for dep in deps:
                                  dep_id = dep.get("id", dep.get("name", ""))
                                  if not dep_id:
                                      continue

                                  if ":" in dep_id:
                                      dep_parts = dep_id.split(":", 1)
                                      dep_namespace = dep_parts[0]
                                      dep_name = dep_parts[1]
                                  else:
                                      dep_namespace = "unknown"
                                      dep_name = dep_id

                                  protocol = dep.get("protocol", "")
                                  direction = dep.get("direction", "")

                                  # Create DEPENDS_ON relationship
                                  if direction == "upstream" or not direction:
                                      cypher = """
                                      MERGE (s1:Service {name: $src_name, namespace: $src_namespace})
                                      MERGE (s2:Service {name: $dep_name, namespace: $dep_namespace})
                                      MERGE (s1)-[r:DEPENDS_ON]->(s2)
                                      SET r.protocol = $protocol,
                                          r.last_seen = datetime()
                                      RETURN s2.name
                                      """
                                  else:
                                      cypher = """
                                      MERGE (s1:Service {name: $dep_name, namespace: $dep_namespace})
                                      MERGE (s2:Service {name: $src_name, namespace: $src_namespace})
                                      MERGE (s1)-[r:DEPENDS_ON]->(s2)
                                      SET r.protocol = $protocol,
                                          r.last_seen = datetime()
                                      RETURN s2.name
                                      """

                                  result = neo4j_query(cypher, {
                                      "src_name": src_name,
                                      "src_namespace": src_namespace,
                                      "dep_name": dep_name,
                                      "dep_namespace": dep_namespace,
                                      "protocol": protocol
                                  })

                                  if not result.get("errors"):
                                      dep_count += 1
                      except Exception as e:
                          logger.warning(f"Failed to get dependencies for {service_id}: {e}")
                          continue

                  logger.info(f"Synced {dep_count} service dependencies from Coroot")
                  return dep_count

              def sync_gatus_health():
                  """Sync endpoint health from Gatus to Neo4j."""
                  logger.info("Syncing Gatus endpoint health...")

                  # Get endpoint statuses directly from Gatus API
                  response = call_rest_api(GATUS_URL, "/api/v1/endpoints/statuses")

                  if not response or isinstance(response, dict) and "error" in response:
                      logger.warning(f"Gatus unavailable: {response}")
                      return 0

                  count = 0
                  endpoints = response if isinstance(response, list) else []

                  for endpoint in endpoints:
                      name = endpoint.get("name", "unknown")
                      group = endpoint.get("group", "default")
                      key = endpoint.get("key", f"{group}_{name}")

                      # Get latest result
                      results = endpoint.get("results", [])
                      latest = results[-1] if results else {}
                      success = latest.get("success", False)
                      status_code = latest.get("status", 0)
                      response_time = latest.get("duration", 0) / 1000000  # Convert ns to ms
                      timestamp = latest.get("timestamp", "")

                      # Calculate uptime from recent results
                      uptime = 0
                      if results:
                          successful = sum(1 for r in results if r.get("success", False))
                          uptime = round((successful / len(results)) * 100, 2)

                      cypher = """
                      MERGE (e:UptimeMonitor {key: $key})
                      SET e.name = $name,
                          e.group = $group,
                          e.healthy = $healthy,
                          e.status_code = $status_code,
                          e.response_time_ms = $response_time,
                          e.uptime_percent = $uptime,
                          e.last_check = datetime(),
                          e.source = 'gatus'
                      RETURN e.key
                      """

                      result = neo4j_query(cypher, {
                          "key": key,
                          "name": name,
                          "group": group,
                          "healthy": success,
                          "status_code": status_code,
                          "response_time": response_time,
                          "uptime": uptime
                      })

                      if not result.get("errors"):
                          count += 1

                      # Try to link to related Service
                      if group in ["Apps", "Media", "Home Automation", "Monitoring", "Notes"]:
                          cypher_link = """
                          MATCH (e:UptimeMonitor {key: $key})
                          MATCH (s:Service)
                          WHERE toLower(s.name) CONTAINS toLower($name) OR toLower($name) CONTAINS toLower(s.name)
                          MERGE (e)-[:MONITORS]->(s)
                          RETURN type(e)
                          """
                          neo4j_query(cypher_link, {"key": key, "name": name})

                  logger.info(f"Synced {count} endpoints from Gatus")
                  return count

              def sync_ha_areas():
                  """Sync area/location data from Home Assistant to Neo4j.

                  Graceful degradation: If HA-MCP fails, log warning and continue.
                  Discovery/graph-sync should not fail due to HA being unavailable.
                  """
                  logger.info("Syncing Home Assistant areas...")

                  # Get entities from HA via consolidated home-mcp
                  try:
                      entities_response = call_mcp_tool("home", "list_entities")
                      if not entities_response:
                          logger.warning("Home-MCP unavailable or returned empty response, skipping area sync")
                          return 0
                  except Exception as e:
                      logger.warning(f"Home-MCP unavailable, skipping area sync: {e}")
                      return 0

                  entities = extract_list(entities_response, "entities", "result")
                  if not entities:
                      logger.info("No entities returned from HA, skipping area sync")
                      return 0

                  synced_count = 0
                  for entity in entities:
                      area = entity.get("area", entity.get("area_id", ""))
                      # Try to extract IP from entity_id or attributes
                      entity_id = entity.get("entity_id", "")
                      attributes = entity.get("attributes", {})
                      ip = attributes.get("ip", attributes.get("ip_address", ""))

                      # Skip if no area or no IP to match
                      if not area or not ip:
                          continue

                      try:
                          # Update Neo4j Host node with location and create Location relationship
                          cypher = """
                          MATCH (h:Host {ip: $ip})
                          SET h.location = $area
                          WITH h
                          MERGE (loc:Location {name: $area})
                          MERGE (h)-[:LOCATED_IN]->(loc)
                          RETURN h.ip
                          """
                          result = neo4j_query(cypher, {"ip": ip, "area": area})

                          if result.get("results") and result["results"][0].get("data"):
                              synced_count += 1
                              logger.debug(f"Synced location '{area}' for {ip}")
                      except Exception as e:
                          logger.warning(f"Failed to sync area for {ip}: {e}")
                          continue

                  logger.info(f"HA area sync complete: {synced_count} entities updated")
                  return synced_count

              def _extract_count(result):
                  """Extract count from Neo4j query result."""
                  try:
                      return result["results"][0]["data"][0]["row"][0]
                  except (KeyError, IndexError, TypeError):
                      return 0

              def run_lifecycle_management():
                  """Update entity lifecycle status for ALL node types."""
                  logger.info("Running lifecycle management...")

                  # Node types and their stale/archive/delete thresholds
                  lifecycle_config = {
                      "Host": {"stale": "PT8H", "offline": "P2D", "archive": "P14D"},
                      "VM": {"stale": "PT8H", "offline": "P2D", "archive": "P14D"},
                      "Pod": {"delete_after": "P1D"},
                      "Service": {"stale": "PT12H", "offline": "P3D", "delete_after": "P7D"},
                      "Alert": {"delete_after": "P7D"},
                      "UptimeMonitor": {"stale": "PT12H", "delete_after": "P7D"},
                      "RunbookDocument": {"stale": "P1D", "delete_after": "P7D"},
                      "SmartDevice": {"stale": "P1D", "offline": "P7D", "delete_after": "P30D"},
                      "NAS": {"stale": "PT8H", "offline": "P2D"},
                      "Share": {"stale": "P1D", "delete_after": "P14D"},
                      "AccessPoint": {"stale": "PT8H", "offline": "P2D", "archive": "P14D"},
                      "Switch": {"stale": "PT8H", "offline": "P2D", "archive": "P14D"},
                      "Deployment": {"stale": "PT12H", "offline": "P3D", "delete_after": "P7D"},
                      "Ingress": {"stale": "PT12H", "offline": "P3D", "delete_after": "P7D"},
                  }

                  total_stale = 0
                  total_offline = 0
                  total_deleted = 0
                  total_archived = 0

                  for label, thresholds in lifecycle_config.items():
                      # Mark stale
                      if "stale" in thresholds:
                          result = neo4j_query(f"""
                              MATCH (n:{label})
                              WHERE n.last_seen < datetime() - duration('{thresholds["stale"]}')
                                AND (n.status IS NULL OR n.status IN ['online', 'healthy', 'degraded', 'warning', 'unknown', 'running', 'completed', 'pending', 'scaled-down'])
                              SET n.status = 'stale'
                              RETURN count(n) as cnt
                          """)
                          cnt = _extract_count(result)
                          total_stale += cnt

                      # Mark offline
                      if "offline" in thresholds:
                          result = neo4j_query(f"""
                              MATCH (n:{label} {{status: 'stale'}})
                              WHERE n.last_seen < datetime() - duration('{thresholds["offline"]}')
                              SET n.status = 'offline'
                              RETURN count(n) as cnt
                          """)
                          cnt = _extract_count(result)
                          total_offline += cnt

                      # Delete old nodes
                      if "delete_after" in thresholds:
                          result = neo4j_query(f"""
                              MATCH (n:{label})
                              WHERE n.last_seen < datetime() - duration('{thresholds["delete_after"]}')
                              DETACH DELETE n
                              RETURN count(n) as cnt
                          """)
                          cnt = _extract_count(result)
                          total_deleted += cnt
                          if cnt > 0:
                              logger.info(f"  Deleted {cnt} stale {label} nodes")

                      # Archive (relabel) long-offline
                      if "archive" in thresholds:
                          result = neo4j_query(f"""
                              MATCH (n:{label} {{status: 'offline'}})
                              WHERE n.last_seen < datetime() - duration('{thresholds["archive"]}')
                              SET n:Archived{label}
                              REMOVE n:{label}
                              RETURN count(n) as cnt
                          """)
                          cnt = _extract_count(result)
                          total_archived += cnt
                          if cnt > 0:
                              logger.info(f"  Archived {cnt} {label} nodes")

                  # Clean up orphan nodes with no relationships
                  for label in ["Location", "Network"]:
                      result = neo4j_query(f"""
                          MATCH (n:{label})
                          WHERE NOT (n)--()
                          DELETE n
                          RETURN count(n) as cnt
                      """)
                      cnt = _extract_count(result)
                      if cnt > 0:
                          logger.info(f"  Deleted {cnt} orphan {label} nodes")
                          total_deleted += cnt

                  logger.info(f"Lifecycle: {total_stale} stale, {total_offline} offline, {total_deleted} deleted, {total_archived} archived")

              def main():
                  logger.info("Starting graph-sync job")
                  start_time = datetime.now()

                  # Verify Neo4j connection
                  test_result = neo4j_query("RETURN 1 as test")
                  if test_result.get("errors"):
                      logger.error(f"Neo4j connection failed: {test_result}")
                      return 1

                  logger.info("Neo4j connection verified")

                  # Sync from each source
                  results = {}
                  deploy_status = {}
                  anomalous_services = []

                  try:
                      results["proxmox_vms"] = sync_proxmox_vms()
                  except Exception as e:
                      logger.error(f"Proxmox sync failed: {e}")
                      results["proxmox_vms"] = 0

                  try:
                      results["unifi_devices"] = sync_unifi_devices()
                  except Exception as e:
                      logger.error(f"UniFi sync failed: {e}")
                      results["unifi_devices"] = 0

                  try:
                      results["truenas_storage"] = sync_truenas_storage()
                  except Exception as e:
                      logger.error(f"TrueNAS sync failed: {e}")
                      results["truenas_storage"] = 0

                  # Deployments MUST run before services (provides deploy_status lookup)
                  try:
                      deploy_status = sync_kubernetes_deployments()
                      results["deployments"] = len(deploy_status)
                  except Exception as e:
                      logger.error(f"Kubernetes deployments sync failed: {e}")
                      results["deployments"] = 0

                  try:
                      results["kubernetes"] = sync_kubernetes_services(deploy_status)
                  except Exception as e:
                      logger.error(f"Kubernetes sync failed: {e}")
                      results["kubernetes"] = 0

                  try:
                      results["ingresses"] = sync_kubernetes_ingresses()
                  except Exception as e:
                      logger.error(f"Kubernetes ingresses sync failed: {e}")
                      results["ingresses"] = 0

                  try:
                      results["k8s_nodes"] = sync_kubernetes_nodes()
                  except Exception as e:
                      logger.error(f"Kubernetes nodes sync failed: {e}")
                      results["k8s_nodes"] = 0

                  try:
                      results["runbooks"] = sync_runbooks()
                  except Exception as e:
                      logger.error(f"Runbooks sync failed: {e}")
                      results["runbooks"] = 0

                  try:
                      coroot_count, anomalous_services = sync_coroot_services()
                      results["coroot_services"] = coroot_count
                  except Exception as e:
                      logger.error(f"Coroot sync failed: {e}")
                      results["coroot_services"] = 0

                  try:
                      results["coroot_deps"] = sync_coroot_dependencies(anomalous_services)
                  except Exception as e:
                      logger.error(f"Coroot dependencies sync failed: {e}")
                      results["coroot_deps"] = 0

                  try:
                      results["gatus_health"] = sync_gatus_health()
                  except Exception as e:
                      logger.error(f"Gatus sync failed: {e}")
                      results["gatus_health"] = 0

                  try:
                      results["ha_areas"] = sync_ha_areas()
                  except Exception as e:
                      logger.error(f"HA area sync failed: {e}")
                      results["ha_areas"] = 0

                  # Run lifecycle management
                  try:
                      run_lifecycle_management()
                  except Exception as e:
                      logger.error(f"Lifecycle management failed: {e}")

                  elapsed = (datetime.now() - start_time).total_seconds()
                  logger.info(f"Graph sync completed in {elapsed:.1f}s: {results}")
                  return 0

              if __name__ == "__main__":
                  exit(main())
