---
apiVersion: v1
kind: ConfigMap
metadata:
  name: gemini-agent-code
  namespace: ai-platform
data:
  # API wrapper that exposes Gemini CLI capabilities as HTTP endpoints
  main.py: |
    #!/usr/bin/env python3
    """
    Gemini Agent API Wrapper

    Exposes Gemini CLI capabilities via HTTP API for the LangGraph orchestrator.
    Uses Google OAuth subscription authentication.
    """
    import asyncio
    import json
    import os
    import base64
    import subprocess
    import uuid
    from datetime import datetime
    from pathlib import Path
    from typing import Optional, List, Dict, Any
    from contextlib import asynccontextmanager

    from fastapi import FastAPI, HTTPException, BackgroundTasks, Response
    from pydantic import BaseModel
    import httpx
    import redis.asyncio as redis
    from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST

    # ============================================================================
    # Prometheus Metrics
    # ============================================================================

    TASKS_TOTAL = Counter(
        'gemini_agent_tasks_total',
        'Total number of tasks processed',
        ['status', 'model']
    )
    TASK_DURATION = Histogram(
        'gemini_agent_task_duration_seconds',
        'Task execution duration in seconds',
        ['model'],
        buckets=[1, 5, 10, 30, 60, 120, 300, 600]
    )
    QUEUE_SIZE = Gauge(
        'gemini_agent_queue_size',
        'Current number of tasks in queue'
    )
    ACTIVE_WORKERS = Gauge(
        'gemini_agent_active_workers',
        'Number of active worker instances'
    )
    EVENTS_LOGGED = Counter(
        'gemini_agent_events_logged_total',
        'Total events logged to knowledge system',
        ['event_type', 'success']
    )

    # Redis configuration
    REDIS_URL = os.environ.get("REDIS_URL", "redis://redis:6379")
    TASK_QUEUE_KEY = "gemini:tasks:queue"  # Sorted set with priority
    TASK_RESULTS_PREFIX = "gemini:task:"   # Hash for each task
    TASK_TTL = 3600  # 1 hour TTL for results
    WORKER_ID = os.environ.get("HOSTNAME", str(uuid.uuid4())[:8])

    # Concurrency configuration
    MAX_CONCURRENT_WORKERS = int(os.environ.get("MAX_CONCURRENT_WORKERS", "3"))

    # Redis connection pool
    redis_pool: Optional[redis.Redis] = None

    # ============================================================================
    # Configuration
    # ============================================================================

    GEMINI_HOME = Path(os.environ.get("HOME", "/home/agent")) / ".gemini"
    CREDENTIALS_FILE = GEMINI_HOME / "oauth_creds.json"
    SETTINGS_FILE = GEMINI_HOME / "settings.json"

    # MCP Server endpoints - dynamically loaded from environment
    def load_mcp_servers() -> Dict[str, str]:
        """Load all MCP server URLs from environment variables."""
        servers = {}
        mcp_names = [
            "knowledge", "infrastructure", "coroot", "proxmox", "opnsense",
            "adguard", "cloudflare", "unifi", "truenas", "home_assistant",
            "arr_suite", "homepage", "web_search", "browser_automation",
            "plex", "vikunja", "neo4j", "tasmota", "monitoring", "keep", "infisical"
        ]
        for name in mcp_names:
            env_key = f"{name.upper()}_MCP_URL"
            url = os.getenv(env_key)
            if url:
                display_name = name.replace("_", "-")
                servers[display_name] = url
        return servers

    MCP_SERVERS = load_mcp_servers()
    print(f"[Config] Loaded {len(MCP_SERVERS)} MCP servers from environment")

    # Knowledge MCP URL for event logging
    KNOWLEDGE_MCP_URL = os.getenv("KNOWLEDGE_MCP_URL", "http://knowledge-mcp:8000")

    # Priority levels (lower score = higher priority)
    PRIORITY_USER = 1
    PRIORITY_CRITICAL = 2
    PRIORITY_WARNING = 3
    PRIORITY_LOW = 4

    # ============================================================================
    # Event Logging (Forever Learning System)
    # ============================================================================

    async def log_to_knowledge(
        event_type: str,
        description: str,
        task_id: Optional[str] = None,
        task_data: Optional[dict] = None,
        result: Optional[str] = None,
        success: bool = True,
        latency_ms: Optional[float] = None
    ):
        """Log execution event to knowledge-mcp for the Forever Learning System."""
        try:
            metadata = {
                "worker_id": WORKER_ID,
                "source": "gemini-agent",
            }
            if task_id:
                metadata["task_id"] = task_id
            if task_data:
                metadata["model"] = task_data.get("model", "unknown")
                metadata["prompt_length"] = len(task_data.get("prompt", ""))
                metadata["timeout"] = task_data.get("timeout", 600)
            if result:
                metadata["response_length"] = len(result)
            if latency_ms:
                metadata["latency_ms"] = latency_ms

            async with httpx.AsyncClient(timeout=10.0) as client:
                resp = await client.post(
                    f"{KNOWLEDGE_MCP_URL}/api/log_event",
                    json={
                        "event_type": event_type,
                        "description": description[:500],
                        "source_agent": "gemini-agent",
                        "metadata": metadata,
                        "resolution": "completed" if success else "failed"
                    }
                )
                if resp.status_code == 200:
                    data = resp.json()
                    print(f"[Learning] Logged event {data.get('event_id', 'unknown')}: {event_type}")
                    EVENTS_LOGGED.labels(event_type=event_type, success="true").inc()
                else:
                    print(f"[Learning] Failed to log event: {resp.status_code}")
                    EVENTS_LOGGED.labels(event_type=event_type, success="false").inc()
        except Exception as e:
            print(f"[Learning] Error logging event: {e}")
            EVENTS_LOGGED.labels(event_type=event_type, success="false").inc()

    # ============================================================================
    # Redis Task Queue Functions
    # ============================================================================

    async def get_redis() -> redis.Redis:
        """Get Redis connection."""
        global redis_pool
        if redis_pool is None:
            redis_pool = redis.from_url(REDIS_URL, decode_responses=True)
        return redis_pool

    async def enqueue_task(task_id: str, task_data: dict, priority: int = PRIORITY_LOW) -> bool:
        """Add task to priority queue."""
        r = await get_redis()
        task_key = f"{TASK_RESULTS_PREFIX}{task_id}"
        task_data["status"] = "pending"
        task_data["created_at"] = datetime.utcnow().isoformat()
        task_data["worker"] = None
        await r.hset(task_key, mapping={k: json.dumps(v) if isinstance(v, (dict, list)) else str(v) for k, v in task_data.items()})
        await r.expire(task_key, TASK_TTL)
        await r.zadd(TASK_QUEUE_KEY, {task_id: priority})
        return True

    async def dequeue_task() -> Optional[tuple]:
        """Get highest priority task from queue."""
        r = await get_redis()
        result = await r.zpopmin(TASK_QUEUE_KEY, count=1)
        if not result:
            return None
        task_id, priority = result[0]
        task_key = f"{TASK_RESULTS_PREFIX}{task_id}"
        task_data = await r.hgetall(task_key)
        if not task_data:
            return None
        await r.hset(task_key, "status", "running")
        await r.hset(task_key, "worker", WORKER_ID)
        await r.hset(task_key, "started_at", datetime.utcnow().isoformat())
        for k in ["context", "allowed_tools"]:
            if k in task_data and task_data[k]:
                try:
                    task_data[k] = json.loads(task_data[k])
                except:
                    pass
        return task_id, task_data

    async def update_task_result(task_id: str, status: str, result: str = None, error: str = None):
        """Update task with result."""
        r = await get_redis()
        task_key = f"{TASK_RESULTS_PREFIX}{task_id}"
        updates = {
            "status": status,
            "completed_at": datetime.utcnow().isoformat()
        }
        if result is not None:
            updates["result"] = result
        if error is not None:
            updates["error"] = error
        await r.hset(task_key, mapping=updates)
        await r.expire(task_key, TASK_TTL)

    async def get_task_from_redis(task_id: str) -> Optional[dict]:
        """Get task status from Redis."""
        r = await get_redis()
        task_key = f"{TASK_RESULTS_PREFIX}{task_id}"
        data = await r.hgetall(task_key)
        return data if data else None

    async def get_queue_stats() -> dict:
        """Get queue statistics."""
        r = await get_redis()
        queue_length = await r.zcard(TASK_QUEUE_KEY)
        keys = await r.keys(f"{TASK_RESULTS_PREFIX}*")
        stats = {"pending": 0, "running": 0, "completed": 0, "failed": 0}
        for key in keys[:100]:
            status = await r.hget(key, "status")
            if status in stats:
                stats[status] += 1
        return {"queue_length": queue_length, "tasks": stats, "worker_id": WORKER_ID}

    # ============================================================================
    # Models
    # ============================================================================

    class AgentRequest(BaseModel):
        prompt: str
        context: Optional[Dict[str, Any]] = None
        allowed_tools: Optional[List[str]] = None
        max_turns: int = 10
        working_directory: str = "/workspace"
        model: str = "gemini-2.0-flash"  # Default Gemini model
        async_mode: bool = False
        timeout: int = 600
        output_format: str = "text"  # text, json, stream-json

    class AgentResponse(BaseModel):
        success: bool
        result: Optional[str] = None
        error: Optional[str] = None
        tool_calls: List[Dict[str, Any]] = []
        tokens_used: Optional[int] = None
        task_id: Optional[str] = None

    class TaskStatus(BaseModel):
        task_id: str
        status: str
        created_at: str
        completed_at: Optional[str] = None
        result: Optional[str] = None
        error: Optional[str] = None

    class HealthResponse(BaseModel):
        status: str
        gemini_authenticated: bool
        mcp_servers: Dict[str, bool]

    # ============================================================================
    # Startup
    # ============================================================================

    async def setup_credentials():
        """Decode and write credentials from Infisical secret."""
        GEMINI_HOME.mkdir(parents=True, exist_ok=True)

        # Read OAuth credentials from mounted secret
        creds_b64_file = Path("/secrets/gemini/OAUTH_CREDS_B64")
        if creds_b64_file.exists():
            creds_b64 = creds_b64_file.read_text().strip()
            creds_json = base64.b64decode(creds_b64).decode('utf-8')
            CREDENTIALS_FILE.write_text(creds_json)
            os.chmod(CREDENTIALS_FILE, 0o600)
            print("[Startup] Gemini OAuth credentials configured")
        else:
            print("[Startup] Warning: No credentials file at /secrets/gemini/OAUTH_CREDS_B64")

        # Read settings from mounted secret or environment
        settings_b64_file = Path("/secrets/gemini/SETTINGS_B64")
        if settings_b64_file.exists():
            settings_b64 = settings_b64_file.read_text().strip()
            settings_json = base64.b64decode(settings_b64).decode('utf-8')
            SETTINGS_FILE.write_text(settings_json)
            os.chmod(SETTINGS_FILE, 0o644)
            print("[Startup] Gemini settings configured")
        else:
            print("[Startup] Warning: No settings file at /secrets/gemini/SETTINGS_B64")

    async def check_mcp_health() -> Dict[str, bool]:
        """Check connectivity to MCP servers."""
        results = {}
        async with httpx.AsyncClient(timeout=5.0) as client:
            for name, url in MCP_SERVERS.items():
                try:
                    resp = await client.get(f"{url}/health")
                    results[name] = resp.status_code == 200
                except Exception:
                    results[name] = False
        return results

    @asynccontextmanager
    async def lifespan(app: FastAPI):
        global worker_running, worker_tasks
        await setup_credentials()
        worker_running = True
        print(f"[Startup] Starting {MAX_CONCURRENT_WORKERS} worker(s) per pod")
        for i in range(MAX_CONCURRENT_WORKERS):
            task = asyncio.create_task(worker_loop(i))
            worker_tasks.append(task)
        yield
        worker_running = False
        for task in worker_tasks:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
        worker_tasks.clear()
        if redis_pool:
            await redis_pool.close()

    app = FastAPI(
        title="Gemini Agent API",
        description="HTTP API wrapper for Gemini CLI with OAuth subscription auth",
        version="1.0.0",
        lifespan=lifespan
    )

    # ============================================================================
    # Endpoints
    # ============================================================================

    @app.get("/health", response_model=HealthResponse)
    async def health_check():
        """Check service health and dependencies."""
        gemini_auth = CREDENTIALS_FILE.exists()
        mcp_health = await check_mcp_health()

        return HealthResponse(
            status="healthy" if gemini_auth else "degraded",
            gemini_authenticated=gemini_auth,
            mcp_servers=mcp_health
        )

    @app.get("/metrics")
    async def metrics():
        """Prometheus metrics endpoint."""
        try:
            stats = await get_queue_stats()
            QUEUE_SIZE.set(stats.get("queue_length", 0))
        except Exception:
            pass
        return Response(content=generate_latest(), media_type=CONTENT_TYPE_LATEST)

    def _run_gemini_sync(cmd: List[str], cwd: str, env: dict, timeout: int) -> tuple:
        """Run Gemini CLI synchronously (called from thread pool)."""
        try:
            result = subprocess.run(
                cmd,
                cwd=cwd,
                env=env,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            return (result.returncode, result.stdout, result.stderr)
        except subprocess.TimeoutExpired:
            return (-1, "", f"Agent execution timed out ({timeout}s limit)")
        except Exception as e:
            return (-1, "", str(e))

    async def execute_task(task_id: str, task_data: dict):
        """Execute a task from the queue."""
        prompt = task_data.get("prompt", "")
        model = task_data.get("model", "gemini-2.0-flash")
        working_dir = task_data.get("working_directory", "/workspace")
        timeout = int(task_data.get("timeout", 600))
        output_format = task_data.get("output_format", "text")
        allowed_tools = task_data.get("allowed_tools")
        if isinstance(allowed_tools, str):
            try:
                allowed_tools = json.loads(allowed_tools)
            except:
                allowed_tools = None

        # Build gemini command
        cmd = [
            "gemini",
            prompt,
            "--yolo",  # Auto-approve all tools (like --dangerously-skip-permissions)
            "-o", output_format,
        ]
        if model:
            cmd.extend(["-m", model])
        if allowed_tools:
            cmd.extend(["--allowed-tools"] + allowed_tools)

        env = os.environ.copy()
        env["HOME"] = os.environ.get("HOME", "/home/agent")

        start_time = datetime.utcnow()

        try:
            returncode, stdout, stderr = await asyncio.to_thread(
                _run_gemini_sync, cmd, working_dir, env, timeout
            )

            latency_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            latency_sec = latency_ms / 1000.0

            TASK_DURATION.labels(model=model).observe(latency_sec)

            if returncode == 0:
                TASKS_TOTAL.labels(status="completed", model=model).inc()
                await update_task_result(task_id, "completed", result=stdout)
                await log_to_knowledge(
                    event_type="gemini.chat.complete",
                    description=f"Task {task_id}: {prompt[:200]}",
                    task_id=task_id,
                    task_data=task_data,
                    result=stdout,
                    success=True,
                    latency_ms=latency_ms
                )
            else:
                TASKS_TOTAL.labels(status="failed", model=model).inc()
                error_msg = stderr or stdout or "Unknown error"
                if "error" in error_msg.lower():
                    error_msg = error_msg.split('\n')[0][:500]
                await update_task_result(task_id, "failed", result=stdout, error=error_msg)
                await log_to_knowledge(
                    event_type="gemini.error",
                    description=f"Task {task_id} failed: {error_msg[:200]}",
                    task_id=task_id,
                    task_data=task_data,
                    result=stdout,
                    success=False,
                    latency_ms=latency_ms
                )
        except Exception as e:
            latency_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            TASKS_TOTAL.labels(status="error", model=model).inc()
            TASK_DURATION.labels(model=model).observe(latency_ms / 1000.0)
            await update_task_result(task_id, "failed", error=str(e))
            await log_to_knowledge(
                event_type="gemini.error",
                description=f"Task {task_id} exception: {str(e)[:200]}",
                task_id=task_id,
                task_data=task_data,
                success=False,
                latency_ms=latency_ms
            )

    # Worker state
    worker_running = False
    worker_tasks: List[asyncio.Task] = []

    async def worker_loop(worker_num: int):
        """Background worker that processes tasks from Redis queue."""
        global worker_running
        worker_name = f"{WORKER_ID}-{worker_num}"
        print(f"[Worker {worker_name}] Starting worker loop...")
        ACTIVE_WORKERS.inc()
        try:
            while worker_running:
                try:
                    if worker_num == 0:
                        stats = await get_queue_stats()
                        QUEUE_SIZE.set(stats.get("queue_length", 0))

                    task = await dequeue_task()
                    if task:
                        task_id, task_data = task
                        print(f"[Worker {worker_name}] Processing task {task_id}")
                        await execute_task(task_id, task_data)
                        print(f"[Worker {worker_name}] Completed task {task_id}")
                    else:
                        await asyncio.sleep(1 + worker_num * 0.1)
                except Exception as e:
                    print(f"[Worker {worker_name}] Error in worker loop: {e}")
                    await asyncio.sleep(5)
        finally:
            ACTIVE_WORKERS.dec()
            print(f"[Worker {worker_name}] Worker loop stopped")

    @app.post("/agent/run", response_model=AgentResponse)
    async def run_agent(request: AgentRequest, background_tasks: BackgroundTasks):
        """
        Execute a Gemini agent task.

        This invokes Gemini CLI as a subprocess with the given prompt.
        The agent has access to MCP tools and can perform agentic tasks.
        """
        try:
            if request.async_mode:
                task_id = str(uuid.uuid4())
                task_data = {
                    "prompt": request.prompt,
                    "model": request.model,
                    "working_directory": request.working_directory,
                    "timeout": request.timeout,
                    "output_format": request.output_format,
                    "allowed_tools": json.dumps(request.allowed_tools) if request.allowed_tools else "",
                    "context": json.dumps(request.context) if request.context else "",
                }
                await enqueue_task(task_id, task_data, priority=PRIORITY_LOW)
                return AgentResponse(
                    success=True,
                    task_id=task_id,
                    result=f"Task queued - poll /task/{task_id} for status"
                )

            # Sync mode - execute directly
            sync_task_id = str(uuid.uuid4())[:8]
            cmd = [
                "gemini",
                request.prompt,
                "--yolo",
                "-o", request.output_format,
            ]
            if request.model:
                cmd.extend(["-m", request.model])
            if request.allowed_tools:
                cmd.extend(["--allowed-tools"] + request.allowed_tools)

            env = os.environ.copy()
            env["HOME"] = os.environ.get("HOME", "/home/agent")

            start_time = datetime.utcnow()
            task_data = {
                "prompt": request.prompt,
                "model": request.model,
                "timeout": request.timeout,
            }

            returncode, stdout, stderr = await asyncio.to_thread(
                _run_gemini_sync, cmd, request.working_directory, env, request.timeout
            )

            latency_ms = (datetime.utcnow() - start_time).total_seconds() * 1000

            if returncode == 0:
                asyncio.create_task(log_to_knowledge(
                    event_type="gemini.chat.complete",
                    description=f"Sync task {sync_task_id}: {request.prompt[:200]}",
                    task_id=sync_task_id,
                    task_data=task_data,
                    result=stdout,
                    success=True,
                    latency_ms=latency_ms
                ))
                return AgentResponse(
                    success=True,
                    result=stdout,
                    tool_calls=[]
                )
            else:
                asyncio.create_task(log_to_knowledge(
                    event_type="gemini.error",
                    description=f"Sync task {sync_task_id} failed: {stderr[:200] if stderr else 'Unknown error'}",
                    task_id=sync_task_id,
                    task_data=task_data,
                    result=stdout,
                    success=False,
                    latency_ms=latency_ms
                ))
                return AgentResponse(
                    success=False,
                    error=stderr or "Unknown error",
                    result=stdout
                )

        except Exception as e:
            asyncio.create_task(log_to_knowledge(
                event_type="gemini.error",
                description=f"Sync task exception: {str(e)[:200]}",
                success=False
            ))
            return AgentResponse(
                success=False,
                error=str(e)
            )

    @app.get("/task/{task_id}", response_model=TaskStatus)
    async def get_task_status_endpoint(task_id: str):
        """Get status and result of an async task from Redis."""
        task = await get_task_from_redis(task_id)
        if not task:
            raise HTTPException(status_code=404, detail="Task not found")
        return TaskStatus(
            task_id=task_id,
            status=task.get("status", "unknown"),
            created_at=task.get("created_at", ""),
            completed_at=task.get("completed_at"),
            result=task.get("result"),
            error=task.get("error")
        )

    @app.get("/tasks")
    async def list_tasks():
        """List recent tasks from Redis (for debugging)."""
        return await get_queue_stats()

    class QueueRequest(BaseModel):
        """Request to queue a task with priority."""
        prompt: str
        priority: int = PRIORITY_LOW
        model: str = "gemini-2.0-flash"
        working_directory: str = "/workspace"
        timeout: int = 600
        output_format: str = "text"
        allowed_tools: Optional[List[str]] = None
        context: Optional[Dict[str, Any]] = None

    @app.post("/queue/submit")
    async def submit_to_queue(request: QueueRequest):
        """Submit a task to the priority queue."""
        task_id = str(uuid.uuid4())
        task_data = {
            "prompt": request.prompt,
            "model": request.model,
            "working_directory": request.working_directory,
            "timeout": request.timeout,
            "output_format": request.output_format,
            "allowed_tools": json.dumps(request.allowed_tools) if request.allowed_tools else "",
            "context": json.dumps(request.context) if request.context else "",
        }
        await enqueue_task(task_id, task_data, priority=request.priority)
        stats = await get_queue_stats()
        return {
            "task_id": task_id,
            "priority": request.priority,
            "queue_position": stats["queue_length"],
            "message": f"Task queued - poll /task/{task_id} for status"
        }

    @app.get("/queue/stats")
    async def queue_statistics():
        """Get current queue statistics."""
        return await get_queue_stats()

    @app.post("/agent/query")
    async def query_agent(prompt: str, background_tasks: BackgroundTasks, context: Optional[Dict[str, Any]] = None):
        """Simple query endpoint for quick questions."""
        request = AgentRequest(
            prompt=prompt,
            context=context,
            max_turns=3,
            allowed_tools=["Read", "Glob", "Grep", "WebSearch", "WebFetch"]
        )
        return await run_agent(request, background_tasks)

    @app.get("/mcp/servers")
    async def list_mcp_servers():
        """List available MCP servers and their status."""
        return {
            "servers": MCP_SERVERS,
            "health": await check_mcp_health()
        }

    # ============================================================================
    # Reports API - Shared document storage via Redis for agent collaboration
    # ============================================================================

    REPORTS_KEY_PREFIX = "reports:"
    REPORTS_INDEX_KEY = "reports:index"
    REPORTS_TTL = 60 * 60 * 24 * 30  # 30 days TTL for reports

    class ReportSave(BaseModel):
        """Save a report document."""
        filename: str
        content: str
        category: str = "general"  # assessments, recommendations, reviews, general

    @app.post("/reports/save")
    async def save_report(report: ReportSave):
        """Save a report document to Redis-backed storage."""
        try:
            r = await get_redis()

            # Sanitize filename
            safe_name = "".join(c for c in report.filename if c.isalnum() or c in "._-")
            if not safe_name.endswith(".md"):
                safe_name += ".md"

            report_key = f"{REPORTS_KEY_PREFIX}{report.category}:{safe_name}"
            now = datetime.utcnow().isoformat()

            # Store report content and metadata
            report_data = {
                "filename": safe_name,
                "category": report.category,
                "content": report.content,
                "size": len(report.content),
                "created": now,
                "modified": now
            }

            # Check if exists (to preserve created date)
            existing = await r.hgetall(report_key)
            if existing and "created" in existing:
                report_data["created"] = existing["created"]

            await r.hset(report_key, mapping=report_data)
            await r.expire(report_key, REPORTS_TTL)

            # Add to index for listing
            await r.sadd(f"{REPORTS_INDEX_KEY}:{report.category}", safe_name)
            await r.sadd(REPORTS_INDEX_KEY, report.category)

            return {
                "success": True,
                "path": f"{report.category}/{safe_name}",
                "category": report.category,
                "filename": safe_name
            }
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    @app.get("/reports/list")
    async def list_reports(category: Optional[str] = None):
        """List all reports, optionally filtered by category."""
        try:
            r = await get_redis()
            reports = []

            # Get categories to search
            if category:
                categories = [category]
            else:
                categories = await r.smembers(REPORTS_INDEX_KEY)

            for cat in categories:
                filenames = await r.smembers(f"{REPORTS_INDEX_KEY}:{cat}")
                for fname in filenames:
                    report_key = f"{REPORTS_KEY_PREFIX}{cat}:{fname}"
                    data = await r.hgetall(report_key)
                    if data:
                        reports.append({
                            "filename": data.get("filename", fname),
                            "category": cat,
                            "size": int(data.get("size", 0)),
                            "modified": data.get("modified", ""),
                            "created": data.get("created", ""),
                            "path": f"{cat}/{fname}"
                        })

            return {"reports": sorted(reports, key=lambda x: x.get("modified", ""), reverse=True)}
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    @app.get("/reports/read/{category}/{filename}")
    async def read_report(category: str, filename: str):
        """Read a specific report."""
        try:
            r = await get_redis()
            report_key = f"{REPORTS_KEY_PREFIX}{category}:{filename}"
            data = await r.hgetall(report_key)

            if not data:
                raise HTTPException(status_code=404, detail="Report not found")

            return {
                "filename": data.get("filename", filename),
                "category": category,
                "content": data.get("content", ""),
                "size": int(data.get("size", 0)),
                "created": data.get("created", ""),
                "modified": data.get("modified", "")
            }
        except HTTPException:
            raise
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    @app.delete("/reports/delete/{category}/{filename}")
    async def delete_report(category: str, filename: str):
        """Delete a report."""
        try:
            r = await get_redis()
            report_key = f"{REPORTS_KEY_PREFIX}{category}:{filename}"

            if not await r.exists(report_key):
                raise HTTPException(status_code=404, detail="Report not found")

            await r.delete(report_key)
            await r.srem(f"{REPORTS_INDEX_KEY}:{category}", filename)

            # Clean up empty category
            if await r.scard(f"{REPORTS_INDEX_KEY}:{category}") == 0:
                await r.srem(REPORTS_INDEX_KEY, category)

            return {"success": True, "deleted": f"{category}/{filename}"}
        except HTTPException:
            raise
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    @app.get("/reports/categories")
    async def list_categories():
        """List all report categories with counts."""
        try:
            r = await get_redis()
            categories = {}
            cats = await r.smembers(REPORTS_INDEX_KEY)
            for cat in cats:
                count = await r.scard(f"{REPORTS_INDEX_KEY}:{cat}")
                categories[cat] = count
            return {"categories": categories}
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

  init.sh: |
    #!/bin/bash
    set -e

    echo "=== Gemini Agent Initialization ==="

    # Create .gemini directory
    mkdir -p /root/.gemini

    # Decode OAuth credentials from secret
    if [ -f /secrets/gemini/OAUTH_CREDS_B64 ]; then
        echo "Decoding Gemini OAuth credentials..."
        base64 -d /secrets/gemini/OAUTH_CREDS_B64 > /root/.gemini/oauth_creds.json
        chmod 600 /root/.gemini/oauth_creds.json
        echo "[Init] OAuth credentials configured"
    else
        echo "[Init] Warning: No OAuth credentials found"
    fi

    # Decode settings from secret
    if [ -f /secrets/gemini/SETTINGS_B64 ]; then
        echo "Decoding Gemini settings..."
        base64 -d /secrets/gemini/SETTINGS_B64 > /root/.gemini/settings.json
        chmod 644 /root/.gemini/settings.json
        echo "[Init] Settings configured"
    else
        echo "[Init] Warning: No settings found"
    fi

    # Verify Gemini CLI is installed
    if command -v gemini &> /dev/null; then
        echo "[Init] Gemini CLI available"
        gemini --version || true
    else
        echo "[Init] Gemini CLI not found - installing..."
        npm install -g @anthropic-ai/gemini-cli || npm install -g @anthropic/gemini-cli || echo "Failed to install Gemini CLI"
    fi

    echo "=== Starting API Server ==="
    exec uvicorn main:app --host 0.0.0.0 --port 8000

  requirements.txt: |
    fastapi>=0.109.0
    uvicorn[standard]>=0.27.0
    httpx>=0.26.0
    pydantic>=2.5.0
    redis>=5.0.0
    prometheus-client>=0.19.0
