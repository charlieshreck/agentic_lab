---
# Network Discovery Agent
# Combines: nmap, K8s API, OPNsense, AdGuard to discover and sync to NetBox
apiVersion: v1
kind: ConfigMap
metadata:
  name: network-discovery-code
  namespace: ai-platform
data:
  discovery.py: |
    #!/usr/bin/env python3
    """
    Network Discovery Agent for NetBox

    Sources:
    - nmap: Active network scanning with service detection
    - Kubernetes: Service discovery from cluster APIs
    - OPNsense: DHCP leases, ARP table
    - AdGuard: DNS query statistics

    Syncs discovered data to NetBox IPAM.
    """
    import os
    import json
    import subprocess
    import logging
    import re
    from typing import Dict, List, Any, Optional
    from dataclasses import dataclass, field, asdict
    from datetime import datetime
    import urllib.request
    import urllib.error
    import ssl

    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    logger = logging.getLogger(__name__)

    # Configuration
    NETBOX_URL = os.environ.get("NETBOX_URL", "http://netbox:8080")
    NETBOX_TOKEN = os.environ.get("NETBOX_TOKEN", "")
    OPNSENSE_URL = os.environ.get("OPNSENSE_URL", "https://10.10.0.1")
    OPNSENSE_KEY = os.environ.get("OPNSENSE_KEY", "")
    OPNSENSE_SECRET = os.environ.get("OPNSENSE_SECRET", "")
    ADGUARD_URL = os.environ.get("ADGUARD_URL", "http://10.10.0.1:3000")
    ADGUARD_USER = os.environ.get("ADGUARD_USER", "")
    ADGUARD_PASS = os.environ.get("ADGUARD_PASS", "")

    # Networks to scan
    NETWORKS = [
        {"name": "prod", "cidr": "10.10.0.0/24", "site": "prod-cluster"},
        {"name": "agentic", "cidr": "10.20.0.0/24", "site": "agentic-cluster"},
        {"name": "monit", "cidr": "10.30.0.0/24", "site": "monit-cluster"},
    ]

    @dataclass
    class DiscoveredHost:
        ip: str
        hostname: str = ""
        mac: str = ""
        vendor: str = ""
        os_guess: str = ""
        services: List[Dict] = field(default_factory=list)
        source: str = ""  # nmap, dhcp, arp, dns, k8s
        last_seen: str = field(default_factory=lambda: datetime.utcnow().isoformat())
        network: str = ""
        device_type: str = ""  # server, router, switch, iot, workstation, unknown

    class DiscoveryAgent:
        def __init__(self):
            self.hosts: Dict[str, DiscoveredHost] = {}
            # Create SSL context for OPNsense - use TLS 1.2 with permissive settings
            self.ssl_ctx = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
            self.ssl_ctx.minimum_version = ssl.TLSVersion.TLSv1_2
            self.ssl_ctx.maximum_version = ssl.TLSVersion.TLSv1_2
            self.ssl_ctx.check_hostname = False
            self.ssl_ctx.verify_mode = ssl.CERT_NONE
            # Allow older ciphers for OPNsense compatibility
            try:
                self.ssl_ctx.set_ciphers('DEFAULT:@SECLEVEL=0')
            except ssl.SSLError:
                self.ssl_ctx.set_ciphers('ALL')

        # ==========================================
        # NMAP SCANNING
        # ==========================================
        def scan_network_nmap(self, cidr: str, network_name: str) -> List[DiscoveredHost]:
            """Scan network with nmap - service detection and OS fingerprinting."""
            logger.info(f"Scanning {cidr} with nmap...")
            hosts = []

            try:
                # Run nmap with service detection (-sV), OS detection (-O), and XML output
                # Using -T4 for faster scanning, --min-rate for speed
                cmd = [
                    "nmap", "-sn",  # Ping scan first (fast)
                    "-T4", "--min-rate", "100",
                    cidr, "-oG", "-"
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)

                # Parse grep-able output for live hosts
                live_ips = []
                for line in result.stdout.split('\n'):
                    if 'Up' in line and 'Host:' in line:
                        match = re.search(r'Host: (\d+\.\d+\.\d+\.\d+)', line)
                        if match:
                            live_ips.append(match.group(1))

                logger.info(f"Found {len(live_ips)} live hosts in {cidr}")

                # Now do service scan on live hosts (in batches)
                if live_ips:
                    for ip in live_ips[:50]:  # Limit to 50 hosts per scan
                        host = self._scan_host_services(ip, network_name)
                        if host:
                            hosts.append(host)

            except subprocess.TimeoutExpired:
                logger.warning(f"nmap scan timed out for {cidr}")
            except Exception as e:
                logger.error(f"nmap scan error: {e}")

            return hosts

        def _scan_host_services(self, ip: str, network_name: str) -> Optional[DiscoveredHost]:
            """Scan a single host for services."""
            try:
                # Quick service scan on common ports
                cmd = [
                    "nmap", "-sV", "--version-light",
                    "-p", "22,80,443,8080,8443,3000,5432,6379,9090,9100,11434,6333",
                    "-T4", "--host-timeout", "30s",
                    ip, "-oX", "-"
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)

                host = DiscoveredHost(ip=ip, source="nmap", network=network_name)

                # Parse XML output
                xml = result.stdout

                # Extract hostname
                hostname_match = re.search(r'<hostname name="([^"]+)"', xml)
                if hostname_match:
                    host.hostname = hostname_match.group(1)

                # Extract MAC and vendor
                mac_match = re.search(r'<address addr="([0-9A-F:]+)" addrtype="mac"', xml, re.I)
                if mac_match:
                    host.mac = mac_match.group(1)
                vendor_match = re.search(r'<address.*vendor="([^"]+)"', xml)
                if vendor_match:
                    host.vendor = vendor_match.group(1)

                # Extract OS guess
                os_match = re.search(r'<osmatch name="([^"]+)"', xml)
                if os_match:
                    host.os_guess = os_match.group(1)

                # Extract services
                for port_match in re.finditer(
                    r'<port protocol="(\w+)" portid="(\d+)".*?<state state="open".*?'
                    r'<service name="([^"]*)"(?:.*?product="([^"]*)")?(?:.*?version="([^"]*)")?',
                    xml, re.DOTALL
                ):
                    host.services.append({
                        "protocol": port_match.group(1),
                        "port": int(port_match.group(2)),
                        "service": port_match.group(3),
                        "product": port_match.group(4) or "",
                        "version": port_match.group(5) or ""
                    })

                # Guess device type based on services and OS
                host.device_type = self._guess_device_type(host)

                return host

            except Exception as e:
                logger.warning(f"Service scan failed for {ip}: {e}")
                return DiscoveredHost(ip=ip, source="nmap", network=network_name, device_type="unknown")

        def _guess_device_type(self, host: DiscoveredHost) -> str:
            """Guess device type based on discovered info."""
            os_lower = host.os_guess.lower()
            services = [s.get("service", "").lower() for s in host.services]
            products = [s.get("product", "").lower() for s in host.services]

            # Check OS first
            if "router" in os_lower or "opnsense" in os_lower or "pfsense" in os_lower:
                return "router"
            if "switch" in os_lower:
                return "switch"
            if "talos" in os_lower or "kubernetes" in ' '.join(products):
                return "server"
            if "proxmox" in os_lower or "proxmox" in ' '.join(products):
                return "hypervisor"
            if "truenas" in os_lower or "freenas" in os_lower:
                return "storage"

            # Check services
            if any(s in services for s in ["kubernetes", "kubelet"]):
                return "server"
            if "http" in services or "https" in services:
                if any(p in ' '.join(products) for p in ["nginx", "apache", "traefik"]):
                    return "server"
            if "ssh" in services and len(host.services) <= 2:
                return "server"
            if any(s in services for s in ["mqtt", "homeassistant"]):
                return "iot-hub"
            if "printer" in os_lower or "print" in services:
                return "printer"

            # Check vendor
            vendor_lower = host.vendor.lower() if host.vendor else ""
            if any(v in vendor_lower for v in ["ubiquiti", "unifi", "cisco", "netgear"]):
                return "network"
            if any(v in vendor_lower for v in ["raspberry", "espressif", "tuya"]):
                return "iot"
            if any(v in vendor_lower for v in ["dell", "hp", "lenovo", "supermicro"]):
                return "server"
            if any(v in vendor_lower for v in ["apple", "samsung", "google"]):
                return "workstation"

            return "unknown"

        # ==========================================
        # OPNSENSE - DHCP & ARP
        # ==========================================
        def _opnsense_api_call(self, endpoint: str) -> Optional[dict]:
            """Make OPNsense API call using curl (handles TLS better)."""
            url = f"{OPNSENSE_URL}{endpoint}"
            try:
                result = subprocess.run(
                    ["curl", "-s", "-k", "-u", f"{OPNSENSE_KEY}:{OPNSENSE_SECRET}", url],
                    capture_output=True, text=True, timeout=30
                )
                if result.returncode == 0 and result.stdout:
                    return json.loads(result.stdout)
            except Exception as e:
                logger.warning(f"OPNsense curl error: {e}")
            return None

        def get_opnsense_dhcp_leases(self) -> List[DiscoveredHost]:
            """Get DHCP leases from OPNsense."""
            logger.info("Fetching DHCP leases from OPNsense...")
            hosts = []

            if not OPNSENSE_KEY or not OPNSENSE_SECRET:
                logger.warning("OPNsense credentials not configured")
                return hosts

            try:
                data = self._opnsense_api_call("/api/dhcpv4/leases/searchLease")
                if not data:
                    logger.warning("OPNsense DHCP returned no data")
                    return hosts

                for lease in data.get("rows", []):
                    host = DiscoveredHost(
                        ip=lease.get("address", ""),
                        hostname=lease.get("hostname", ""),
                        mac=lease.get("mac", ""),
                        source="dhcp",
                        device_type="unknown"
                    )
                    # Determine network
                    if host.ip.startswith("10.10."):
                        host.network = "prod"
                    elif host.ip.startswith("10.20."):
                        host.network = "agentic"
                    elif host.ip.startswith("10.30."):
                        host.network = "monit"
                    hosts.append(host)

                logger.info(f"Found {len(hosts)} DHCP leases")

            except Exception as e:
                logger.error(f"OPNsense DHCP error: {e}")

            return hosts

        def get_opnsense_arp_table(self) -> List[DiscoveredHost]:
            """Get ARP table from OPNsense."""
            logger.info("Fetching ARP table from OPNsense...")
            hosts = []

            if not OPNSENSE_KEY or not OPNSENSE_SECRET:
                return hosts

            try:
                data = self._opnsense_api_call("/api/diagnostics/interface/getArp")
                if not data:
                    logger.warning("OPNsense ARP returned no data")
                    return hosts

                for entry in data.get("rows", data if isinstance(data, list) else []):
                    if isinstance(entry, dict):
                        ip = entry.get("ip", "")
                        if ip and not ip.startswith("224.") and not ip.startswith("239."):
                            host = DiscoveredHost(
                                ip=ip,
                                mac=entry.get("mac", ""),
                                hostname=entry.get("hostname", ""),
                                source="arp"
                            )
                            hosts.append(host)

                logger.info(f"Found {len(hosts)} ARP entries")

            except Exception as e:
                logger.error(f"OPNsense ARP error: {e}")

            return hosts

        # ==========================================
        # ADGUARD - DNS QUERIES
        # ==========================================
        def get_adguard_clients(self) -> Dict[str, str]:
            """Get client info from AdGuard - maps IPs to hostnames."""
            logger.info("Fetching AdGuard client data...")
            clients = {}

            if not ADGUARD_USER or not ADGUARD_PASS:
                logger.warning("AdGuard credentials not configured")
                return clients

            try:
                url = f"{ADGUARD_URL}/control/clients"

                import base64
                auth = base64.b64encode(f"{ADGUARD_USER}:{ADGUARD_PASS}".encode()).decode()

                req = urllib.request.Request(url, method="GET")
                req.add_header("Authorization", f"Basic {auth}")

                with urllib.request.urlopen(req, timeout=30) as resp:
                    data = json.loads(resp.read())

                if not isinstance(data, dict):
                    logger.warning(f"AdGuard returned unexpected format: {type(data)}")
                    return clients

                # Get configured clients
                configured = data.get("clients") or []
                for client in configured:
                    if not isinstance(client, dict):
                        continue
                    name = client.get("name", "")
                    ids = client.get("ids") or []
                    for ip in ids:
                        if isinstance(ip, str) and re.match(r'\d+\.\d+\.\d+\.\d+', ip):
                            clients[ip] = name

                # Get auto-discovered clients
                auto = data.get("auto_clients") or []
                for client in auto:
                    if not isinstance(client, dict):
                        continue
                    ip = client.get("ip", "")
                    whois = client.get("whois_info") or {}
                    name = client.get("name", "") or whois.get("orgname", "")
                    if ip and name:
                        clients[ip] = name

                logger.info(f"Found {len(clients)} AdGuard clients")

            except Exception as e:
                logger.error(f"AdGuard error: {e}")

            return clients

        # ==========================================
        # KUBERNETES SERVICE DISCOVERY
        # ==========================================
        def get_k8s_services(self) -> List[DiscoveredHost]:
            """Discover services from local Kubernetes cluster."""
            logger.info("Discovering Kubernetes services...")
            hosts = []

            # Check if running in-cluster
            token_path = "/var/run/secrets/kubernetes.io/serviceaccount/token"
            ca_path = "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"

            if not os.path.exists(token_path):
                logger.warning("Not running in Kubernetes - skipping K8s discovery")
                return hosts

            try:
                with open(token_path) as f:
                    token = f.read().strip()

                # Create SSL context for K8s API
                k8s_ctx = ssl.create_default_context()
                k8s_ctx.load_verify_locations(ca_path)

                k8s_host = os.environ.get("KUBERNETES_SERVICE_HOST", "kubernetes.default.svc")
                k8s_port = os.environ.get("KUBERNETES_SERVICE_PORT", "443")
                base_url = f"https://{k8s_host}:{k8s_port}"

                # Get services from ai-platform namespace
                for namespace in ["ai-platform", "default", "kube-system"]:
                    url = f"{base_url}/api/v1/namespaces/{namespace}/services"
                    req = urllib.request.Request(url)
                    req.add_header("Authorization", f"Bearer {token}")

                    try:
                        with urllib.request.urlopen(req, context=k8s_ctx, timeout=10) as resp:
                            data = json.loads(resp.read())

                        for svc in data.get("items", []):
                            spec = svc.get("spec", {})
                            cluster_ip = spec.get("clusterIP")
                            name = svc.get("metadata", {}).get("name", "")

                            # Skip headless services and kubernetes service
                            if not cluster_ip or cluster_ip == "None" or name == "kubernetes":
                                continue

                            # Get ports
                            services = []
                            for port in spec.get("ports", []):
                                services.append({
                                    "protocol": port.get("protocol", "tcp").lower(),
                                    "port": port.get("port"),
                                    "service": port.get("name", ""),
                                    "product": f"k8s-{namespace}",
                                    "version": ""
                                })

                            host = DiscoveredHost(
                                ip=cluster_ip,
                                hostname=f"{name}.{namespace}.svc.cluster.local",
                                source="k8s",
                                network="agentic",  # Local cluster
                                device_type="server",
                                services=services
                            )
                            hosts.append(host)

                    except Exception as e:
                        logger.warning(f"Failed to get services from {namespace}: {e}")

                # Get pods with IPs
                url = f"{base_url}/api/v1/namespaces/ai-platform/pods"
                req = urllib.request.Request(url)
                req.add_header("Authorization", f"Bearer {token}")

                try:
                    with urllib.request.urlopen(req, context=k8s_ctx, timeout=10) as resp:
                        data = json.loads(resp.read())

                    for pod in data.get("items", []):
                        status = pod.get("status", {})
                        pod_ip = status.get("podIP")
                        name = pod.get("metadata", {}).get("name", "")
                        phase = status.get("phase", "")

                        if not pod_ip or phase != "Running":
                            continue

                        # Get container ports
                        services = []
                        for container in pod.get("spec", {}).get("containers", []):
                            for port in container.get("ports", []):
                                services.append({
                                    "protocol": port.get("protocol", "tcp").lower(),
                                    "port": port.get("containerPort"),
                                    "service": container.get("name", ""),
                                    "product": "k8s-pod",
                                    "version": ""
                                })

                        host = DiscoveredHost(
                            ip=pod_ip,
                            hostname=name,
                            source="k8s-pod",
                            network="agentic",
                            device_type="server",
                            services=services
                        )
                        hosts.append(host)

                except Exception as e:
                    logger.warning(f"Failed to get pods: {e}")

                logger.info(f"Found {len(hosts)} Kubernetes services/pods")

            except Exception as e:
                logger.error(f"Kubernetes discovery error: {e}")

            return hosts

        # ==========================================
        # MERGE & CORRELATE
        # ==========================================
        def merge_host(self, host: DiscoveredHost):
            """Merge discovered host into our database."""
            ip = host.ip
            if ip in self.hosts:
                existing = self.hosts[ip]
                # Merge data, preferring more detailed info
                if host.hostname and not existing.hostname:
                    existing.hostname = host.hostname
                if host.mac and not existing.mac:
                    existing.mac = host.mac
                if host.vendor and not existing.vendor:
                    existing.vendor = host.vendor
                if host.os_guess and not existing.os_guess:
                    existing.os_guess = host.os_guess
                if host.services:
                    # Merge services
                    existing_ports = {s["port"] for s in existing.services}
                    for svc in host.services:
                        if svc["port"] not in existing_ports:
                            existing.services.append(svc)
                if host.device_type != "unknown" and existing.device_type == "unknown":
                    existing.device_type = host.device_type
                existing.source = f"{existing.source},{host.source}"
                existing.last_seen = datetime.utcnow().isoformat()
            else:
                self.hosts[ip] = host

        def enrich_with_dns(self, dns_clients: Dict[str, str]):
            """Enrich hosts with DNS/AdGuard data."""
            for ip, name in dns_clients.items():
                if ip in self.hosts:
                    if not self.hosts[ip].hostname:
                        self.hosts[ip].hostname = name
                else:
                    self.hosts[ip] = DiscoveredHost(
                        ip=ip,
                        hostname=name,
                        source="dns"
                    )

        # ==========================================
        # NETBOX SYNC - DEVICE CREATION
        # ==========================================

        # Device type and role mapping based on discovered device_type
        DEVICE_TYPE_MAP = {
            "hypervisor": "proxmox-ve-host",
            "server": "talos-worker",
            "router": "opnsense-firewall",
            "storage": "truenas-scale",
            "network": "unifi-access-point",
            "iot": "unknown-device",
            "iot-hub": "unknown-device",
            "workstation": "unknown-device",
            "printer": "unknown-device",
            "unknown": "unknown-device"
        }

        DEVICE_ROLE_MAP = {
            "hypervisor": "hypervisor",
            "server": "infrastructure",
            "router": "router-firewall",
            "storage": "storage",
            "network": "access-point",
            "iot": "iot-device",
            "iot-hub": "iot-device",
            "workstation": "workstation",
            "printer": "infrastructure",
            "unknown": "infrastructure"
        }

        def _get_id_by_slug(self, endpoint: str, slug: str) -> Optional[int]:
            """Get object ID by slug."""
            result = self._netbox_api(f"{endpoint}?slug={slug}")
            if result and result.get("results"):
                return result["results"][0]["id"]
            return None

        def _get_device_by_ip(self, ip: str) -> Optional[dict]:
            """Find device by its primary IP."""
            result = self._netbox_api(f"/ipam/ip-addresses/?address={ip}")
            if result and result.get("results"):
                ip_obj = result["results"][0]
                if ip_obj.get("assigned_object") and ip_obj["assigned_object"].get("device"):
                    device_id = ip_obj["assigned_object"]["device"]["id"]
                    device = self._netbox_api(f"/dcim/devices/{device_id}/")
                    return device
            return None

        def _get_device_by_name(self, name: str) -> Optional[dict]:
            """Find device by name."""
            result = self._netbox_api(f"/dcim/devices/?name={name}")
            if result and result.get("results"):
                return result["results"][0]
            return None

        def sync_to_netbox(self):
            """Sync discovered hosts to NetBox as proper Device objects."""
            logger.info(f"Syncing {len(self.hosts)} hosts to NetBox as Devices...")

            # Cache lookups for performance
            site_cache = {}
            sites = self._netbox_api("/dcim/sites/")
            if sites and sites.get("results"):
                for s in sites["results"]:
                    site_cache[s["slug"]] = s["id"]

            device_type_cache = {}
            device_types = self._netbox_api("/dcim/device-types/")
            if device_types and device_types.get("results"):
                for dt in device_types["results"]:
                    device_type_cache[dt["slug"]] = dt["id"]

            device_role_cache = {}
            device_roles = self._netbox_api("/dcim/device-roles/")
            if device_roles and device_roles.get("results"):
                for dr in device_roles["results"]:
                    device_role_cache[dr["slug"]] = dr["id"]

            # Network to site mapping
            network_site_map = {net["name"]: net["site"] for net in NETWORKS}

            synced = 0
            skipped = 0
            for ip, host in self.hosts.items():
                try:
                    # Skip if device already exists (by IP or hostname)
                    existing_device = self._get_device_by_ip(ip)
                    if not existing_device and host.hostname:
                        existing_device = self._get_device_by_name(host.hostname)

                    if existing_device:
                        # Update last_discovered timestamp
                        self._netbox_api(f"/dcim/devices/{existing_device['id']}/", "PATCH", {
                            "custom_fields": {
                                "last_discovered": host.last_seen,
                                "discovery_source": f"{existing_device.get('custom_fields', {}).get('discovery_source', '')},{host.source}".strip(",")
                            }
                        })
                        skipped += 1
                        continue

                    # Get site ID from network
                    site_slug = network_site_map.get(host.network)
                    site_id = site_cache.get(site_slug) if site_slug else None
                    if not site_id:
                        logger.warning(f"No site for {ip} (network: {host.network})")
                        continue

                    # Map device type and role
                    dt_slug = self.DEVICE_TYPE_MAP.get(host.device_type, "unknown-device")
                    role_slug = self.DEVICE_ROLE_MAP.get(host.device_type, "infrastructure")

                    device_type_id = device_type_cache.get(dt_slug)
                    role_id = device_role_cache.get(role_slug)

                    if not device_type_id or not role_id:
                        logger.warning(f"Missing type/role for {ip}: {dt_slug}/{role_slug}")
                        continue

                    # Generate device name
                    device_name = host.hostname if host.hostname else f"discovered-{ip.replace('.', '-')}"

                    # Create device
                    device_data = {
                        "name": device_name,
                        "site": site_id,
                        "device_type": device_type_id,
                        "role": role_id,
                        "status": "active",
                        "custom_fields": {
                            "mac_address": host.mac or "",
                            "discovery_source": host.source,
                            "last_discovered": host.last_seen
                        }
                    }

                    device = self._netbox_api("/dcim/devices/", "POST", device_data)
                    if not device:
                        logger.warning(f"Failed to create device for {ip}")
                        continue

                    logger.info(f"Created device: {device_name} (ID: {device['id']})")

                    # Create interface
                    iface_data = {
                        "device": device["id"],
                        "name": "eth0",
                        "type": "1000base-t",
                        "mac_address": host.mac if host.mac else None
                    }
                    if not host.mac:
                        del iface_data["mac_address"]

                    iface = self._netbox_api("/dcim/interfaces/", "POST", iface_data)
                    if not iface:
                        logger.warning(f"Failed to create interface for {device_name}")
                        continue

                    # Assign IP to interface
                    ip_data = {
                        "address": f"{ip}/24",
                        "status": "active",
                        "dns_name": host.hostname or "",
                        "assigned_object_type": "dcim.interface",
                        "assigned_object_id": iface["id"]
                    }
                    ip_obj = self._netbox_api("/ipam/ip-addresses/", "POST", ip_data)

                    # Set as primary IP
                    if ip_obj:
                        self._netbox_api(f"/dcim/devices/{device['id']}/", "PATCH", {
                            "primary_ip4": ip_obj["id"]
                        })

                    synced += 1

                except Exception as e:
                    logger.warning(f"Failed to sync {ip}: {e}")

            logger.info(f"Synced {synced} new devices, updated {skipped} existing to NetBox")

            # Cleanup stale devices
            self._cleanup_stale_devices()

        def _cleanup_stale_devices(self, days_threshold: int = 7):
            """Mark devices not seen recently as offline, delete very old ones."""
            logger.info("Checking for stale devices...")
            from datetime import datetime, timedelta

            threshold = datetime.utcnow() - timedelta(days=days_threshold)
            delete_threshold = datetime.utcnow() - timedelta(days=30)

            # Get discovered devices (not seeded ones)
            devices = self._netbox_api("/dcim/devices/?limit=500")
            if not devices or not devices.get("results"):
                return

            stale_count = 0
            deleted_count = 0

            for device in devices["results"]:
                cf = device.get("custom_fields", {})
                source = cf.get("discovery_source", "")
                last_seen = cf.get("last_discovered")

                # Skip seed devices
                if "seed" in source:
                    continue

                if last_seen:
                    try:
                        last_seen_dt = datetime.fromisoformat(last_seen.replace("Z", "+00:00").replace("+00:00", ""))
                        if last_seen_dt < delete_threshold:
                            # Delete very old devices
                            self._netbox_api(f"/dcim/devices/{device['id']}/", "DELETE")
                            logger.info(f"Deleted stale device: {device['name']}")
                            deleted_count += 1
                        elif last_seen_dt < threshold and device.get("status", {}).get("value") != "offline":
                            # Mark as offline
                            self._netbox_api(f"/dcim/devices/{device['id']}/", "PATCH", {"status": "offline"})
                            logger.info(f"Marked offline: {device['name']}")
                            stale_count += 1
                    except Exception as e:
                        logger.warning(f"Error processing {device['name']}: {e}")

            logger.info(f"Cleanup: {stale_count} marked offline, {deleted_count} deleted")

        def _netbox_api(self, endpoint: str, method: str = "GET", data: dict = None):
            """Make NetBox API call."""
            url = f"{NETBOX_URL}/api{endpoint}"
            headers = {
                "Authorization": f"Token {NETBOX_TOKEN}",
                "Content-Type": "application/json",
                "Accept": "application/json"
            }

            req = urllib.request.Request(url, headers=headers, method=method)
            if data:
                req.data = json.dumps(data).encode()

            try:
                with urllib.request.urlopen(req, timeout=30) as resp:
                    return json.loads(resp.read())
            except urllib.error.HTTPError as e:
                logger.warning(f"NetBox API error: {e.code} - {e.read().decode()[:200]}")
                return None
            except Exception as e:
                logger.error(f"NetBox API error: {e}")
                return None

        def _get_site_id(self, slug: str) -> Optional[int]:
            """Get site ID by slug."""
            result = self._netbox_api(f"/dcim/sites/?slug={slug}")
            if result and result.get("results"):
                return result["results"][0]["id"]
            return None

        # ==========================================
        # MAIN DISCOVERY
        # ==========================================
        def run_discovery(self):
            """Run full discovery from all sources."""
            logger.info("=" * 60)
            logger.info("Starting network discovery...")
            logger.info("=" * 60)

            # 1. nmap scans
            for net in NETWORKS:
                hosts = self.scan_network_nmap(net["cidr"], net["name"])
                for host in hosts:
                    self.merge_host(host)

            # 2. OPNsense DHCP
            dhcp_hosts = self.get_opnsense_dhcp_leases()
            for host in dhcp_hosts:
                self.merge_host(host)

            # 3. OPNsense ARP
            arp_hosts = self.get_opnsense_arp_table()
            for host in arp_hosts:
                self.merge_host(host)

            # 4. AdGuard DNS
            dns_clients = self.get_adguard_clients()
            self.enrich_with_dns(dns_clients)

            # 5. Kubernetes services
            k8s_hosts = self.get_k8s_services()
            for host in k8s_hosts:
                self.merge_host(host)

            # 6. Sync to NetBox
            self.sync_to_netbox()

            # Summary
            logger.info("=" * 60)
            logger.info(f"Discovery complete. Found {len(self.hosts)} hosts:")
            def sort_ip(ip):
                """Sort key for IPs - handles both IPv4 and IPv6."""
                try:
                    if ':' in ip:  # IPv6
                        return (1, ip)  # Sort IPv6 after IPv4
                    return (0, [int(p) for p in ip.split('.')])
                except ValueError:
                    return (2, ip)  # Unknown format last
            for ip in sorted(self.hosts.keys(), key=sort_ip):
                host = self.hosts[ip]
                services = ", ".join([f"{s['port']}/{s['service']}" for s in host.services[:3]])
                logger.info(f"  {ip:15} {host.hostname:25} {host.device_type:12} {services}")
            logger.info("=" * 60)

    if __name__ == "__main__":
        agent = DiscoveryAgent()
        agent.run_discovery()
---
# ServiceAccount for K8s API access
apiVersion: v1
kind: ServiceAccount
metadata:
  name: network-discovery
  namespace: ai-platform
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: network-discovery
rules:
- apiGroups: [""]
  resources: ["services", "pods", "endpoints"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["namespaces"]
  verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: network-discovery
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: network-discovery
subjects:
- kind: ServiceAccount
  name: network-discovery
  namespace: ai-platform
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: network-discovery
  namespace: ai-platform
spec:
  schedule: "0 */6 * * *"  # Every 6 hours
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: network-discovery
          restartPolicy: OnFailure
          containers:
          - name: discovery
            image: python:3.11-slim
            command: ["sh", "-c"]
            args:
              - |
                apt-get update && apt-get install -y nmap curl > /dev/null 2>&1
                python /app/discovery.py
            env:
            - name: NETBOX_URL
              value: "http://netbox:8080"
            - name: NETBOX_TOKEN
              valueFrom:
                secretKeyRef:
                  name: netbox-credentials
                  key: API_TOKEN
            - name: OPNSENSE_URL
              value: "https://10.10.0.1"
            - name: OPNSENSE_KEY
              valueFrom:
                secretKeyRef:
                  name: mcp-opnsense
                  key: key
            - name: OPNSENSE_SECRET
              valueFrom:
                secretKeyRef:
                  name: mcp-opnsense
                  key: secret
            - name: ADGUARD_URL
              value: "http://10.10.0.1:3000"
            - name: ADGUARD_USER
              valueFrom:
                secretKeyRef:
                  name: mcp-adguard
                  key: username
            - name: ADGUARD_PASS
              valueFrom:
                secretKeyRef:
                  name: mcp-adguard
                  key: password
            volumeMounts:
            - name: code
              mountPath: /app
            resources:
              requests:
                memory: "256Mi"
                cpu: "200m"
              limits:
                memory: "512Mi"
                cpu: "1000m"
          volumes:
          - name: code
            configMap:
              name: network-discovery-code
