---
# Network Discovery Agent
# Combines: nmap, K8s API, OPNsense, AdGuard to discover and sync to NetBox
apiVersion: v1
kind: ConfigMap
metadata:
  name: network-discovery-code
  namespace: ai-platform
data:
  discovery.py: |
    #!/usr/bin/env python3
    """
    Network Discovery Agent for NetBox

    Sources:
    - nmap: Active network scanning with service detection
    - Kubernetes: Service discovery from cluster APIs
    - OPNsense: DHCP leases, ARP table
    - AdGuard: DNS query statistics

    Syncs discovered data to NetBox IPAM.
    """
    import os
    import json
    import subprocess
    import logging
    import re
    from typing import Dict, List, Any, Optional
    from dataclasses import dataclass, field, asdict
    from datetime import datetime
    import urllib.request
    import urllib.error
    import ssl

    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    logger = logging.getLogger(__name__)

    # Configuration
    NETBOX_URL = os.environ.get("NETBOX_URL", "http://netbox:8080")
    NETBOX_TOKEN = os.environ.get("NETBOX_TOKEN", "")
    OPNSENSE_URL = os.environ.get("OPNSENSE_URL", "https://10.10.0.1")
    OPNSENSE_KEY = os.environ.get("OPNSENSE_KEY", "")
    OPNSENSE_SECRET = os.environ.get("OPNSENSE_SECRET", "")
    ADGUARD_URL = os.environ.get("ADGUARD_URL", "http://10.10.0.1:3000")
    ADGUARD_USER = os.environ.get("ADGUARD_USER", "")
    ADGUARD_PASS = os.environ.get("ADGUARD_PASS", "")

    # Networks to scan
    NETWORKS = [
        {"name": "prod", "cidr": "10.10.0.0/24", "site": "prod-cluster"},
        {"name": "agentic", "cidr": "10.20.0.0/24", "site": "agentic-cluster"},
        {"name": "monit", "cidr": "10.30.0.0/24", "site": "monit-cluster"},
    ]

    @dataclass
    class DiscoveredHost:
        ip: str
        hostname: str = ""
        mac: str = ""
        vendor: str = ""
        os_guess: str = ""
        services: List[Dict] = field(default_factory=list)
        source: str = ""  # nmap, dhcp, arp, dns, k8s
        last_seen: str = field(default_factory=lambda: datetime.utcnow().isoformat())
        network: str = ""
        device_type: str = ""  # server, router, switch, iot, workstation, unknown

    class DiscoveryAgent:
        def __init__(self):
            self.hosts: Dict[str, DiscoveredHost] = {}
            # Create SSL context for OPNsense - use TLS 1.2 with permissive settings
            self.ssl_ctx = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
            self.ssl_ctx.minimum_version = ssl.TLSVersion.TLSv1_2
            self.ssl_ctx.maximum_version = ssl.TLSVersion.TLSv1_2
            self.ssl_ctx.check_hostname = False
            self.ssl_ctx.verify_mode = ssl.CERT_NONE
            # Allow older ciphers for OPNsense compatibility
            try:
                self.ssl_ctx.set_ciphers('DEFAULT:@SECLEVEL=0')
            except ssl.SSLError:
                self.ssl_ctx.set_ciphers('ALL')

        # ==========================================
        # NMAP SCANNING
        # ==========================================
        def scan_network_nmap(self, cidr: str, network_name: str) -> List[DiscoveredHost]:
            """Scan network with nmap - service detection and OS fingerprinting."""
            logger.info(f"Scanning {cidr} with nmap...")
            hosts = []

            try:
                # Run nmap with service detection (-sV), OS detection (-O), and XML output
                # Using -T4 for faster scanning, --min-rate for speed
                cmd = [
                    "nmap", "-sn",  # Ping scan first (fast)
                    "-T4", "--min-rate", "100",
                    cidr, "-oG", "-"
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)

                # Parse grep-able output for live hosts
                live_ips = []
                for line in result.stdout.split('\n'):
                    if 'Up' in line and 'Host:' in line:
                        match = re.search(r'Host: (\d+\.\d+\.\d+\.\d+)', line)
                        if match:
                            live_ips.append(match.group(1))

                logger.info(f"Found {len(live_ips)} live hosts in {cidr}")

                # Now do service scan on live hosts (in batches)
                if live_ips:
                    for ip in live_ips[:50]:  # Limit to 50 hosts per scan
                        host = self._scan_host_services(ip, network_name)
                        if host:
                            hosts.append(host)

            except subprocess.TimeoutExpired:
                logger.warning(f"nmap scan timed out for {cidr}")
            except Exception as e:
                logger.error(f"nmap scan error: {e}")

            return hosts

        def _scan_host_services(self, ip: str, network_name: str) -> Optional[DiscoveredHost]:
            """Scan a single host for services."""
            try:
                # Quick service scan on common ports
                cmd = [
                    "nmap", "-sV", "--version-light",
                    "-p", "22,80,443,8080,8443,3000,5432,6379,9090,9100,11434,6333",
                    "-T4", "--host-timeout", "30s",
                    ip, "-oX", "-"
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)

                host = DiscoveredHost(ip=ip, source="nmap", network=network_name)

                # Parse XML output
                xml = result.stdout

                # Extract hostname
                hostname_match = re.search(r'<hostname name="([^"]+)"', xml)
                if hostname_match:
                    host.hostname = hostname_match.group(1)

                # Extract MAC and vendor
                mac_match = re.search(r'<address addr="([0-9A-F:]+)" addrtype="mac"', xml, re.I)
                if mac_match:
                    host.mac = mac_match.group(1)
                vendor_match = re.search(r'<address.*vendor="([^"]+)"', xml)
                if vendor_match:
                    host.vendor = vendor_match.group(1)

                # Extract OS guess
                os_match = re.search(r'<osmatch name="([^"]+)"', xml)
                if os_match:
                    host.os_guess = os_match.group(1)

                # Extract services
                for port_match in re.finditer(
                    r'<port protocol="(\w+)" portid="(\d+)".*?<state state="open".*?'
                    r'<service name="([^"]*)"(?:.*?product="([^"]*)")?(?:.*?version="([^"]*)")?',
                    xml, re.DOTALL
                ):
                    host.services.append({
                        "protocol": port_match.group(1),
                        "port": int(port_match.group(2)),
                        "service": port_match.group(3),
                        "product": port_match.group(4) or "",
                        "version": port_match.group(5) or ""
                    })

                # Guess device type based on services and OS
                host.device_type = self._guess_device_type(host)

                return host

            except Exception as e:
                logger.warning(f"Service scan failed for {ip}: {e}")
                return DiscoveredHost(ip=ip, source="nmap", network=network_name, device_type="unknown")

        def _guess_device_type(self, host: DiscoveredHost) -> str:
            """Guess device type based on discovered info."""
            os_lower = host.os_guess.lower()
            services = [s.get("service", "").lower() for s in host.services]
            products = [s.get("product", "").lower() for s in host.services]

            # Check OS first
            if "router" in os_lower or "opnsense" in os_lower or "pfsense" in os_lower:
                return "router"
            if "switch" in os_lower:
                return "switch"
            if "talos" in os_lower or "kubernetes" in ' '.join(products):
                return "server"
            if "proxmox" in os_lower or "proxmox" in ' '.join(products):
                return "hypervisor"
            if "truenas" in os_lower or "freenas" in os_lower:
                return "storage"

            # Check services
            if any(s in services for s in ["kubernetes", "kubelet"]):
                return "server"
            if "http" in services or "https" in services:
                if any(p in ' '.join(products) for p in ["nginx", "apache", "traefik"]):
                    return "server"
            if "ssh" in services and len(host.services) <= 2:
                return "server"
            if any(s in services for s in ["mqtt", "homeassistant"]):
                return "iot-hub"
            if "printer" in os_lower or "print" in services:
                return "printer"

            # Check vendor
            vendor_lower = host.vendor.lower() if host.vendor else ""
            if any(v in vendor_lower for v in ["ubiquiti", "unifi", "cisco", "netgear"]):
                return "network"
            if any(v in vendor_lower for v in ["raspberry", "espressif", "tuya"]):
                return "iot"
            if any(v in vendor_lower for v in ["dell", "hp", "lenovo", "supermicro"]):
                return "server"
            if any(v in vendor_lower for v in ["apple", "samsung", "google"]):
                return "workstation"

            return "unknown"

        # ==========================================
        # OPNSENSE - DHCP & ARP
        # ==========================================
        def _opnsense_api_call(self, endpoint: str) -> Optional[dict]:
            """Make OPNsense API call using curl (handles TLS better)."""
            url = f"{OPNSENSE_URL}{endpoint}"
            try:
                result = subprocess.run(
                    ["curl", "-s", "-k", "-u", f"{OPNSENSE_KEY}:{OPNSENSE_SECRET}", url],
                    capture_output=True, text=True, timeout=30
                )
                if result.returncode == 0 and result.stdout:
                    return json.loads(result.stdout)
            except Exception as e:
                logger.warning(f"OPNsense curl error: {e}")
            return None

        def get_opnsense_dhcp_leases(self) -> List[DiscoveredHost]:
            """Get DHCP leases from OPNsense."""
            logger.info("Fetching DHCP leases from OPNsense...")
            hosts = []

            if not OPNSENSE_KEY or not OPNSENSE_SECRET:
                logger.warning("OPNsense credentials not configured")
                return hosts

            try:
                data = self._opnsense_api_call("/api/dhcpv4/leases/searchLease")
                if not data:
                    logger.warning("OPNsense DHCP returned no data")
                    return hosts

                for lease in data.get("rows", []):
                    host = DiscoveredHost(
                        ip=lease.get("address", ""),
                        hostname=lease.get("hostname", ""),
                        mac=lease.get("mac", ""),
                        source="dhcp",
                        device_type="unknown"
                    )
                    # Determine network
                    if host.ip.startswith("10.10."):
                        host.network = "prod"
                    elif host.ip.startswith("10.20."):
                        host.network = "agentic"
                    elif host.ip.startswith("10.30."):
                        host.network = "monit"
                    hosts.append(host)

                logger.info(f"Found {len(hosts)} DHCP leases")

            except Exception as e:
                logger.error(f"OPNsense DHCP error: {e}")

            return hosts

        def get_opnsense_arp_table(self) -> List[DiscoveredHost]:
            """Get ARP table from OPNsense."""
            logger.info("Fetching ARP table from OPNsense...")
            hosts = []

            if not OPNSENSE_KEY or not OPNSENSE_SECRET:
                return hosts

            try:
                data = self._opnsense_api_call("/api/diagnostics/interface/getArp")
                if not data:
                    logger.warning("OPNsense ARP returned no data")
                    return hosts

                for entry in data.get("rows", data if isinstance(data, list) else []):
                    if isinstance(entry, dict):
                        ip = entry.get("ip", "")
                        if ip and not ip.startswith("224.") and not ip.startswith("239."):
                            host = DiscoveredHost(
                                ip=ip,
                                mac=entry.get("mac", ""),
                                hostname=entry.get("hostname", ""),
                                source="arp"
                            )
                            hosts.append(host)

                logger.info(f"Found {len(hosts)} ARP entries")

            except Exception as e:
                logger.error(f"OPNsense ARP error: {e}")

            return hosts

        # ==========================================
        # ADGUARD - DNS QUERIES
        # ==========================================
        def get_adguard_clients(self) -> Dict[str, str]:
            """Get client info from AdGuard - maps IPs to hostnames."""
            logger.info("Fetching AdGuard client data...")
            clients = {}

            if not ADGUARD_USER or not ADGUARD_PASS:
                logger.warning("AdGuard credentials not configured")
                return clients

            try:
                url = f"{ADGUARD_URL}/control/clients"

                import base64
                auth = base64.b64encode(f"{ADGUARD_USER}:{ADGUARD_PASS}".encode()).decode()

                req = urllib.request.Request(url, method="GET")
                req.add_header("Authorization", f"Basic {auth}")

                with urllib.request.urlopen(req, timeout=30) as resp:
                    data = json.loads(resp.read())

                if not isinstance(data, dict):
                    logger.warning(f"AdGuard returned unexpected format: {type(data)}")
                    return clients

                # Get configured clients
                configured = data.get("clients") or []
                for client in configured:
                    if not isinstance(client, dict):
                        continue
                    name = client.get("name", "")
                    ids = client.get("ids") or []
                    for ip in ids:
                        if isinstance(ip, str) and re.match(r'\d+\.\d+\.\d+\.\d+', ip):
                            clients[ip] = name

                # Get auto-discovered clients
                auto = data.get("auto_clients") or []
                for client in auto:
                    if not isinstance(client, dict):
                        continue
                    ip = client.get("ip", "")
                    whois = client.get("whois_info") or {}
                    name = client.get("name", "") or whois.get("orgname", "")
                    if ip and name:
                        clients[ip] = name

                logger.info(f"Found {len(clients)} AdGuard clients")

            except Exception as e:
                logger.error(f"AdGuard error: {e}")

            return clients

        # ==========================================
        # KUBERNETES SERVICE DISCOVERY
        # ==========================================
        def get_k8s_services(self) -> List[DiscoveredHost]:
            """Discover services from local Kubernetes cluster."""
            logger.info("Discovering Kubernetes services...")
            hosts = []

            # Check if running in-cluster
            token_path = "/var/run/secrets/kubernetes.io/serviceaccount/token"
            ca_path = "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"

            if not os.path.exists(token_path):
                logger.warning("Not running in Kubernetes - skipping K8s discovery")
                return hosts

            try:
                with open(token_path) as f:
                    token = f.read().strip()

                # Create SSL context for K8s API
                k8s_ctx = ssl.create_default_context()
                k8s_ctx.load_verify_locations(ca_path)

                k8s_host = os.environ.get("KUBERNETES_SERVICE_HOST", "kubernetes.default.svc")
                k8s_port = os.environ.get("KUBERNETES_SERVICE_PORT", "443")
                base_url = f"https://{k8s_host}:{k8s_port}"

                # Get services from ai-platform namespace
                for namespace in ["ai-platform", "default", "kube-system"]:
                    url = f"{base_url}/api/v1/namespaces/{namespace}/services"
                    req = urllib.request.Request(url)
                    req.add_header("Authorization", f"Bearer {token}")

                    try:
                        with urllib.request.urlopen(req, context=k8s_ctx, timeout=10) as resp:
                            data = json.loads(resp.read())

                        for svc in data.get("items", []):
                            spec = svc.get("spec", {})
                            cluster_ip = spec.get("clusterIP")
                            name = svc.get("metadata", {}).get("name", "")

                            # Skip headless services and kubernetes service
                            if not cluster_ip or cluster_ip == "None" or name == "kubernetes":
                                continue

                            # Get ports
                            services = []
                            for port in spec.get("ports", []):
                                services.append({
                                    "protocol": port.get("protocol", "tcp").lower(),
                                    "port": port.get("port"),
                                    "service": port.get("name", ""),
                                    "product": f"k8s-{namespace}",
                                    "version": ""
                                })

                            host = DiscoveredHost(
                                ip=cluster_ip,
                                hostname=f"{name}.{namespace}.svc.cluster.local",
                                source="k8s",
                                network="agentic",  # Local cluster
                                device_type="server",
                                services=services
                            )
                            hosts.append(host)

                    except Exception as e:
                        logger.warning(f"Failed to get services from {namespace}: {e}")

                # Get pods with IPs
                url = f"{base_url}/api/v1/namespaces/ai-platform/pods"
                req = urllib.request.Request(url)
                req.add_header("Authorization", f"Bearer {token}")

                try:
                    with urllib.request.urlopen(req, context=k8s_ctx, timeout=10) as resp:
                        data = json.loads(resp.read())

                    for pod in data.get("items", []):
                        status = pod.get("status", {})
                        pod_ip = status.get("podIP")
                        name = pod.get("metadata", {}).get("name", "")
                        phase = status.get("phase", "")

                        if not pod_ip or phase != "Running":
                            continue

                        # Get container ports
                        services = []
                        for container in pod.get("spec", {}).get("containers", []):
                            for port in container.get("ports", []):
                                services.append({
                                    "protocol": port.get("protocol", "tcp").lower(),
                                    "port": port.get("containerPort"),
                                    "service": container.get("name", ""),
                                    "product": "k8s-pod",
                                    "version": ""
                                })

                        host = DiscoveredHost(
                            ip=pod_ip,
                            hostname=name,
                            source="k8s-pod",
                            network="agentic",
                            device_type="server",
                            services=services
                        )
                        hosts.append(host)

                except Exception as e:
                    logger.warning(f"Failed to get pods: {e}")

                logger.info(f"Found {len(hosts)} Kubernetes services/pods")

            except Exception as e:
                logger.error(f"Kubernetes discovery error: {e}")

            return hosts

        # ==========================================
        # MERGE & CORRELATE
        # ==========================================
        def merge_host(self, host: DiscoveredHost):
            """Merge discovered host into our database."""
            ip = host.ip
            if ip in self.hosts:
                existing = self.hosts[ip]
                # Merge data, preferring more detailed info
                if host.hostname and not existing.hostname:
                    existing.hostname = host.hostname
                if host.mac and not existing.mac:
                    existing.mac = host.mac
                if host.vendor and not existing.vendor:
                    existing.vendor = host.vendor
                if host.os_guess and not existing.os_guess:
                    existing.os_guess = host.os_guess
                if host.services:
                    # Merge services
                    existing_ports = {s["port"] for s in existing.services}
                    for svc in host.services:
                        if svc["port"] not in existing_ports:
                            existing.services.append(svc)
                if host.device_type != "unknown" and existing.device_type == "unknown":
                    existing.device_type = host.device_type
                existing.source = f"{existing.source},{host.source}"
                existing.last_seen = datetime.utcnow().isoformat()
            else:
                self.hosts[ip] = host

        def enrich_with_dns(self, dns_clients: Dict[str, str]):
            """Enrich hosts with DNS/AdGuard data."""
            for ip, name in dns_clients.items():
                if ip in self.hosts:
                    if not self.hosts[ip].hostname:
                        self.hosts[ip].hostname = name
                else:
                    self.hosts[ip] = DiscoveredHost(
                        ip=ip,
                        hostname=name,
                        source="dns"
                    )

        # ==========================================
        # NETBOX SYNC
        # ==========================================
        def sync_to_netbox(self):
            """Sync discovered hosts to NetBox IPAM."""
            logger.info(f"Syncing {len(self.hosts)} hosts to NetBox...")

            # Get existing prefixes
            prefixes = self._netbox_api("/ipam/prefixes/")
            prefix_map = {}
            for p in prefixes.get("results", []):
                prefix_map[p["prefix"]] = p["id"]

            # Create prefixes if needed
            for net in NETWORKS:
                if net["cidr"] not in prefix_map:
                    site_id = self._get_site_id(net["site"])
                    result = self._netbox_api("/ipam/prefixes/", "POST", {
                        "prefix": net["cidr"],
                        "site": site_id,
                        "status": "active",
                        "description": f"{net['name']} network"
                    })
                    if result:
                        prefix_map[net["cidr"]] = result["id"]
                        logger.info(f"Created prefix: {net['cidr']}")

            # Sync each host as IP address
            synced = 0
            for ip, host in self.hosts.items():
                try:
                    # Determine prefix
                    prefix_id = None
                    for net in NETWORKS:
                        if ip.startswith(net["cidr"].rsplit(".", 1)[0]):
                            prefix_id = prefix_map.get(net["cidr"])
                            break

                    # Check if IP exists
                    existing = self._netbox_api(f"/ipam/ip-addresses/?address={ip}")

                    ip_data = {
                        "address": f"{ip}/24",
                        "status": "active",
                        "dns_name": host.hostname,
                        "description": f"{host.device_type} | {host.vendor or ''} | {host.os_guess or ''}".strip(" |"),
                        "custom_fields": {
                            "mac_address": host.mac,
                            "discovered_services": json.dumps(host.services[:5]) if host.services else "",
                            "last_discovered": host.last_seen,
                            "discovery_source": host.source
                        }
                    }

                    if existing and existing.get("results"):
                        # Update existing
                        ip_id = existing["results"][0]["id"]
                        self._netbox_api(f"/ipam/ip-addresses/{ip_id}/", "PATCH", ip_data)
                    else:
                        # Create new
                        self._netbox_api("/ipam/ip-addresses/", "POST", ip_data)

                    synced += 1

                except Exception as e:
                    logger.warning(f"Failed to sync {ip}: {e}")

            logger.info(f"Synced {synced}/{len(self.hosts)} hosts to NetBox")

        def _netbox_api(self, endpoint: str, method: str = "GET", data: dict = None):
            """Make NetBox API call."""
            url = f"{NETBOX_URL}/api{endpoint}"
            headers = {
                "Authorization": f"Token {NETBOX_TOKEN}",
                "Content-Type": "application/json",
                "Accept": "application/json"
            }

            req = urllib.request.Request(url, headers=headers, method=method)
            if data:
                req.data = json.dumps(data).encode()

            try:
                with urllib.request.urlopen(req, timeout=30) as resp:
                    return json.loads(resp.read())
            except urllib.error.HTTPError as e:
                logger.warning(f"NetBox API error: {e.code} - {e.read().decode()[:200]}")
                return None
            except Exception as e:
                logger.error(f"NetBox API error: {e}")
                return None

        def _get_site_id(self, slug: str) -> Optional[int]:
            """Get site ID by slug."""
            result = self._netbox_api(f"/dcim/sites/?slug={slug}")
            if result and result.get("results"):
                return result["results"][0]["id"]
            return None

        # ==========================================
        # MAIN DISCOVERY
        # ==========================================
        def run_discovery(self):
            """Run full discovery from all sources."""
            logger.info("=" * 60)
            logger.info("Starting network discovery...")
            logger.info("=" * 60)

            # 1. nmap scans
            for net in NETWORKS:
                hosts = self.scan_network_nmap(net["cidr"], net["name"])
                for host in hosts:
                    self.merge_host(host)

            # 2. OPNsense DHCP
            dhcp_hosts = self.get_opnsense_dhcp_leases()
            for host in dhcp_hosts:
                self.merge_host(host)

            # 3. OPNsense ARP
            arp_hosts = self.get_opnsense_arp_table()
            for host in arp_hosts:
                self.merge_host(host)

            # 4. AdGuard DNS
            dns_clients = self.get_adguard_clients()
            self.enrich_with_dns(dns_clients)

            # 5. Kubernetes services
            k8s_hosts = self.get_k8s_services()
            for host in k8s_hosts:
                self.merge_host(host)

            # 6. Sync to NetBox
            self.sync_to_netbox()

            # Summary
            logger.info("=" * 60)
            logger.info(f"Discovery complete. Found {len(self.hosts)} hosts:")
            for ip in sorted(self.hosts.keys(), key=lambda x: [int(p) for p in x.split('.')]):
                host = self.hosts[ip]
                services = ", ".join([f"{s['port']}/{s['service']}" for s in host.services[:3]])
                logger.info(f"  {ip:15} {host.hostname:25} {host.device_type:12} {services}")
            logger.info("=" * 60)

    if __name__ == "__main__":
        agent = DiscoveryAgent()
        agent.run_discovery()
---
# ServiceAccount for K8s API access
apiVersion: v1
kind: ServiceAccount
metadata:
  name: network-discovery
  namespace: ai-platform
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: network-discovery
rules:
- apiGroups: [""]
  resources: ["services", "pods", "endpoints"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["namespaces"]
  verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: network-discovery
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: network-discovery
subjects:
- kind: ServiceAccount
  name: network-discovery
  namespace: ai-platform
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: network-discovery
  namespace: ai-platform
spec:
  schedule: "0 */6 * * *"  # Every 6 hours
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: network-discovery
          restartPolicy: OnFailure
          containers:
          - name: discovery
            image: python:3.11-slim
            command: ["sh", "-c"]
            args:
              - |
                apt-get update && apt-get install -y nmap curl > /dev/null 2>&1
                python /app/discovery.py
            env:
            - name: NETBOX_URL
              value: "http://netbox:8080"
            - name: NETBOX_TOKEN
              valueFrom:
                secretKeyRef:
                  name: netbox-credentials
                  key: API_TOKEN
            - name: OPNSENSE_URL
              value: "https://10.10.0.1"
            - name: OPNSENSE_KEY
              valueFrom:
                secretKeyRef:
                  name: mcp-opnsense
                  key: key
            - name: OPNSENSE_SECRET
              valueFrom:
                secretKeyRef:
                  name: mcp-opnsense
                  key: secret
            - name: ADGUARD_URL
              value: "http://10.10.0.1:3000"
            - name: ADGUARD_USER
              valueFrom:
                secretKeyRef:
                  name: mcp-adguard
                  key: username
            - name: ADGUARD_PASS
              valueFrom:
                secretKeyRef:
                  name: mcp-adguard
                  key: password
            volumeMounts:
            - name: code
              mountPath: /app
            resources:
              requests:
                memory: "256Mi"
                cpu: "200m"
              limits:
                memory: "512Mi"
                cpu: "1000m"
          volumes:
          - name: code
            configMap:
              name: network-discovery-code
---
# Job to run discovery manually
apiVersion: batch/v1
kind: Job
metadata:
  name: network-discovery-now
  namespace: ai-platform
spec:
  ttlSecondsAfterFinished: 3600
  template:
    spec:
      serviceAccountName: network-discovery
      restartPolicy: Never
      containers:
      - name: discovery
        image: python:3.11-slim
        command: ["sh", "-c"]
        args:
          - |
            apt-get update && apt-get install -y nmap curl > /dev/null 2>&1
            python /app/discovery.py
        env:
        - name: NETBOX_URL
          value: "http://netbox:8080"
        - name: NETBOX_TOKEN
          valueFrom:
            secretKeyRef:
              name: netbox-credentials
              key: API_TOKEN
        - name: OPNSENSE_URL
          value: "https://10.10.0.1"
        - name: OPNSENSE_KEY
          valueFrom:
            secretKeyRef:
              name: mcp-opnsense
              key: key
        - name: OPNSENSE_SECRET
          valueFrom:
            secretKeyRef:
              name: mcp-opnsense
              key: secret
        - name: ADGUARD_URL
          value: "http://10.10.0.1:3000"
        - name: ADGUARD_USER
          valueFrom:
            secretKeyRef:
              name: mcp-adguard
              key: username
        - name: ADGUARD_PASS
          valueFrom:
            secretKeyRef:
              name: mcp-adguard
              key: password
        volumeMounts:
        - name: code
          mountPath: /app
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "512Mi"
            cpu: "1000m"
      volumes:
      - name: code
        configMap:
          name: network-discovery-code
